{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminecjwchen/Documents/GitHub/COMS4995-AML-Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kaggle_survey_2020_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = df.drop(columns = [\"time_from_start_to_finish_seconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(col_name: str, order_rules: list, data):\n",
    "    data[col_name] = pd.Categorical(data[col_name], order_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category_no_specified_order(col_name, data):\n",
    "    if sum(data[col_name].isna().astype(int)) > 0:\n",
    "        data[col_name].fillna(\"No response\", inplace = True)\n",
    "    \n",
    "    order = list(set(data[col_name]))\n",
    "    convert_to_category(col_name, order, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category_to_code(col_name: str, data, inplace = False):\n",
    "    if inplace:\n",
    "        data[col_name] = data[col_name].cat.codes + 1 # because NaN automatically becomes -1\n",
    "    else:\n",
    "        return data[col_name].cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(col_name: str, order_rules = None, data = salary_data, num_data = salary_data_as_num):\n",
    "    if order_rules:\n",
    "        convert_to_category(col_name, order_rules, data)\n",
    "    else:\n",
    "        convert_to_category_no_specified_order(col_name, data)\n",
    "    num_data[col_name] = convert_category_to_code(col_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_column_to_binary(col_name, data = salary_data):\n",
    "    data[col_name].fillna(0, inplace = True)\n",
    "    data[col_name].mask(data[col_name] != 0, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_hot_encoded_columns(columns, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col in columns:\n",
    "        one_hot_column_to_binary(col, data)\n",
    "        num_data[col] = data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_text_to_binary(col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    data[col_name] = data[col_name].notna().astype(int)\n",
    "    num_data[col_name] = data[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multiple_columns_into_one_binary(columns, new_col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col_name in columns:\n",
    "        one_hot_column_to_binary(col_name)\n",
    "        \n",
    "    data[new_col_name] = data[columns].sum(axis = 1)\n",
    "    data[new_col_name] = data[new_col_name].astype(int)\n",
    "    \n",
    "    data[new_col_name].mask(data[new_col_name] > 0, 1, inplace = True)\n",
    "    num_data[new_col_name] = data[new_col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q24 Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1: original bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q24_order = [\"$0-999\",\n",
    "             '1,000-1,999',\n",
    "             '2,000-2,999',\n",
    "             '3,000-3,999',\n",
    "             '4,000-4,999',\n",
    "             '5,000-7,499',\n",
    "             '7,500-9,999',\n",
    "             '10,000-14,999',\n",
    "             '15,000-19,999',\n",
    "             '20,000-24,999',\n",
    "             '25,000-29,999',\n",
    "             '30,000-39,999',\n",
    "             '40,000-49,999',\n",
    "             '50,000-59,999',\n",
    "              '60,000-69,999',\n",
    "              '70,000-79,999',\n",
    "              '80,000-89,999',\n",
    "              '90,000-99,999',\n",
    "            '100,000-124,999',\n",
    "            '125,000-149,999',\n",
    "            '150,000-199,999',\n",
    "             '200,000-249,999',\n",
    "             '250,000-299,999',\n",
    "              '300,000-500,000',\n",
    "              '> $500,000'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q24\", q24_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "25-29    4011\n",
       "22-24    3786\n",
       "18-21    3469\n",
       "30-34    2811\n",
       "35-39    1991\n",
       "40-44    1397\n",
       "45-49     988\n",
       "50-54     698\n",
       "55-59     411\n",
       "60-69     398\n",
       "70         76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_order = [\n",
    "    \"18-21\",\n",
    "    \"22-24\",\n",
    "    \"25-29\",\n",
    "    \"30-34\",\n",
    "    \"35-39\",\n",
    "    \"40-44\",\n",
    "    \"45-49\",\n",
    "    \"50-54\",\n",
    "    \"55-59\",\n",
    "    \"60-69\",\n",
    "    \"70\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q1\", q1_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20031</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20036 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1\n",
       "0        0   5\n",
       "1       19   4\n",
       "2        9   5\n",
       "3       20   4\n",
       "4        0   4\n",
       "...    ...  ..\n",
       "20031    0   1\n",
       "20032    0   9\n",
       "20033    1   4\n",
       "20034    1   2\n",
       "20035    1   2\n",
       "\n",
       "[20036 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"] = convert_category_to_code(\"q1\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "3     4011\n",
       "2     3786\n",
       "1     3469\n",
       "4     2811\n",
       "5     1991\n",
       "6     1397\n",
       "7      988\n",
       "8      698\n",
       "9      411\n",
       "10     398\n",
       "11      76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "Man                        15789\n",
       "Woman                       3878\n",
       "Prefer not to say            263\n",
       "Prefer to self-describe       54\n",
       "Nonbinary                     52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_order = ['Man', \"Woman\", \"Nonbinary\", 'Prefer to self-describe', 'Prefer not to say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q2\", q2_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20031</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20036 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1  q2\n",
       "0        0   5   1\n",
       "1       19   4   1\n",
       "2        9   5   1\n",
       "3       20   4   1\n",
       "4        0   4   1\n",
       "...    ...  ..  ..\n",
       "20031    0   1   1\n",
       "20032    0   9   2\n",
       "20033    1   4   1\n",
       "20034    1   2   1\n",
       "20035    1   2   1\n",
       "\n",
       "[20036 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"] = convert_category_to_code(\"q2\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "1    15789\n",
       "2     3878\n",
       "5      263\n",
       "4       54\n",
       "3       52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q3\"] = convert_category_to_code(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "Master’s degree                                                      7859\n",
       "Bachelor’s degree                                                    6978\n",
       "Doctoral degree                                                      2302\n",
       "Some college/university study without earning a bachelor’s degree    1092\n",
       "Professional degree                                                   699\n",
       "I prefer not to answer                                                399\n",
       "No formal education past high school                                  240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_order = [\"No formal education past high school\",\n",
    "            \"Some college/university study without earning a bachelor’s degree\",\n",
    "            \"Professional degree\",\n",
    "            \"Bachelor’s degree\",\n",
    "            \"Master’s degree\",\n",
    "            \"Doctoral degree\",\n",
    "            \"I prefer not to answer\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q4\", q4_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q4\"] = convert_category_to_code(\"q4\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "5    7859\n",
       "4    6978\n",
       "6    2302\n",
       "2    1092\n",
       "3     699\n",
       "0     467\n",
       "7     399\n",
       "1     240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q5\n",
       "Student                      5171\n",
       "Data Scientist               2676\n",
       "Software Engineer            1968\n",
       "Other                        1737\n",
       "Currently not employed       1652\n",
       "Data Analyst                 1475\n",
       "Research Scientist           1174\n",
       "Machine Learning Engineer    1082\n",
       "Business Analyst              798\n",
       "Product/Project Manager       692\n",
       "Data Engineer                 437\n",
       "Statistician                  290\n",
       "DBA/Database Engineer         125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q5\"] = convert_category_to_code(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Years Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_order = [\n",
    " 'I have never written code',\n",
    " '< 1 years',\n",
    " '1-2 years',\n",
    " '3-5 years',\n",
    " '5-10 years',\n",
    " '10-20 years',\n",
    " '20+ years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q6\", q6_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_columns = [\n",
    "     'q7_part_1',\n",
    " 'q7_part_2',\n",
    " 'q7_part_3',\n",
    " 'q7_part_4',\n",
    " 'q7_part_5',\n",
    " 'q7_part_6',\n",
    " 'q7_part_7',\n",
    " 'q7_part_8',\n",
    " 'q7_part_9',\n",
    " 'q7_part_10',\n",
    " 'q7_part_11',\n",
    " 'q7_part_12',\n",
    " 'q7_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q7_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11 Computing Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12 Specialized Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q12_columns = [\n",
    "    'q12_part_1',\n",
    " 'q12_part_2',\n",
    " 'q12_part_3',\n",
    " 'q12_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q12_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14_columns = [\n",
    "    'q14_part_1',\n",
    " 'q14_part_2',\n",
    " 'q14_part_3',\n",
    " 'q14_part_4',\n",
    " 'q14_part_5',\n",
    " 'q14_part_6',\n",
    " 'q14_part_7',\n",
    " 'q14_part_8',\n",
    " 'q14_part_9',\n",
    " 'q14_part_10',\n",
    " 'q14_part_11',\n",
    " 'q14_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q14_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15 Years ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15_order = [\n",
    "    'I do not use machine learning methods',\n",
    "    'Under 1 year',\n",
    "    '1-2 years',\n",
    "    '2-3 years',\n",
    "    '3-4 years',\n",
    "    '4-5 years',\n",
    "    '5-10 years',\n",
    "    '10-20 years',\n",
    "    '20 or more years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q15\", q15_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17 ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17_columns = [\n",
    "    'q17_part_1',\n",
    " 'q17_part_2',\n",
    " 'q17_part_3',\n",
    " 'q17_part_4',\n",
    " 'q17_part_5',\n",
    " 'q17_part_6',\n",
    " 'q17_part_7',\n",
    " 'q17_part_8',\n",
    " 'q17_part_9',\n",
    " 'q17_part_10',\n",
    " 'q17_part_11',\n",
    " 'q17_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q17_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q20 Company Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20_order = [\n",
    "    '0-49 employees',\n",
    "    '50-249 employees',\n",
    "    '250-999 employees',\n",
    "    '1000-9,999 employees',\n",
    "    '10,000 or more employees'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q20\", q20_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q21 Datascience Workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "q21_order = [\n",
    "    '0',\n",
    "    '1-2',\n",
    "    '3-4',\n",
    "    '5-9',\n",
    "    '10-14',\n",
    "    '15-19',\n",
    "    '20'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q21\", q21_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q22 Incorporating ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'm not super sure about the proper \"order\" for this question. Feel free to change this if you find it more appropriate. Just please let the chat know in case it affects others' encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "q22_order = [\n",
    "    'I do not know',\n",
    "    'No (we do not use ML methods)',\n",
    "    'We are exploring ML methods (and may one day put a model into production)',\n",
    "    'We use ML methods for generating insights (but do not put working models into production)',\n",
    "    'We recently started using ML methods (i.e., models in production for less than 2 years)',\n",
    "    'We have well established ML methods (i.e., models in production for more than 2 years)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q22\", q22_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q30 Big Data Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q32 Business Intelligence Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q33 Automated ML Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "q33_columns = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_multiple_columns_into_one_binary(q33_columns, \"q33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q37 Data Science Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "q37_columns = [\n",
    "    'q37_part_1',\n",
    " 'q37_part_2',\n",
    " 'q37_part_3',\n",
    " 'q37_part_4',\n",
    " 'q37_part_5',\n",
    " 'q37_part_6',\n",
    " 'q37_part_7',\n",
    " 'q37_part_8',\n",
    " 'q37_part_9',\n",
    " 'q37_part_10',\n",
    " 'q37_part_11',\n",
    " 'q37_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q37_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q38 Primary Data Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q39 Media Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "q39_columns = [\n",
    "    'q39_part_1',\n",
    " 'q39_part_2',\n",
    " 'q39_part_3',\n",
    " 'q39_part_4',\n",
    " 'q39_part_5',\n",
    " 'q39_part_6',\n",
    " 'q39_part_7',\n",
    " 'q39_part_8',\n",
    " 'q39_part_9',\n",
    " 'q39_part_10',\n",
    " 'q39_part_11',\n",
    " 'q39_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q39_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropped Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dropped = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_questions = [\n",
    "    \"q8\",\n",
    "    'q9_part_1',\n",
    " 'q9_part_2',\n",
    " 'q9_part_3',\n",
    " 'q9_part_4',\n",
    " 'q9_part_5',\n",
    " 'q9_part_6',\n",
    " 'q9_part_7',\n",
    " 'q9_part_8',\n",
    " 'q9_part_9',\n",
    " 'q9_part_10',\n",
    " 'q9_part_11',\n",
    " 'q9_other',\n",
    " 'q10_part_1',\n",
    " 'q10_part_2',\n",
    " 'q10_part_3',\n",
    " 'q10_part_4',\n",
    " 'q10_part_5',\n",
    " 'q10_part_6',\n",
    " 'q10_part_7',\n",
    " 'q10_part_8',\n",
    " 'q10_part_9',\n",
    " 'q10_part_10',\n",
    " 'q10_part_11',\n",
    " 'q10_part_12',\n",
    " 'q10_part_13',\n",
    " 'q10_other',\n",
    " \"q13\",\n",
    " 'q16_part_1',\n",
    " 'q16_part_2',\n",
    " 'q16_part_3',\n",
    " 'q16_part_4',\n",
    " 'q16_part_5',\n",
    " 'q16_part_6',\n",
    " 'q16_part_7',\n",
    " 'q16_part_8',\n",
    " 'q16_part_9',\n",
    " 'q16_part_10',\n",
    " 'q16_part_11',\n",
    " 'q16_part_12',\n",
    " 'q16_part_13',\n",
    " 'q16_part_14',\n",
    " 'q16_part_15',\n",
    " 'q16_other',\n",
    " 'q18_part_1',\n",
    " 'q18_part_2',\n",
    " 'q18_part_3',\n",
    " 'q18_part_4',\n",
    " 'q18_part_5',\n",
    " 'q18_part_6',\n",
    " 'q18_other',\n",
    " 'q19_part_1',\n",
    " 'q19_part_2',\n",
    " 'q19_part_3',\n",
    " 'q19_part_4',\n",
    " 'q19_part_5',\n",
    " 'q19_other',\n",
    " 'q23_part_1',\n",
    " 'q23_part_2',\n",
    " 'q23_part_3',\n",
    " 'q23_part_4',\n",
    " 'q23_part_5',\n",
    " 'q23_part_6',\n",
    " 'q23_part_7',\n",
    " 'q23_other',\n",
    " 'q25',\n",
    " 'q26_a_part_1',\n",
    " 'q26_a_part_2',\n",
    " 'q26_a_part_3',\n",
    " 'q26_a_part_4',\n",
    " 'q26_a_part_5',\n",
    " 'q26_a_part_6',\n",
    " 'q26_a_part_7',\n",
    " 'q26_a_part_8',\n",
    " 'q26_a_part_9',\n",
    " 'q26_a_part_10',\n",
    " 'q26_a_part_11',\n",
    " 'q26_a_other',\n",
    " 'q27_a_part_1',\n",
    " 'q27_a_part_2',\n",
    " 'q27_a_part_3',\n",
    " 'q27_a_part_4',\n",
    " 'q27_a_part_5',\n",
    " 'q27_a_part_6',\n",
    " 'q27_a_part_7',\n",
    " 'q27_a_part_8',\n",
    " 'q27_a_part_9',\n",
    " 'q27_a_part_10',\n",
    " 'q27_a_part_11',\n",
    " 'q27_a_other',\n",
    " 'q28_a_part_1',\n",
    " 'q28_a_part_2',\n",
    " 'q28_a_part_3',\n",
    " 'q28_a_part_4',\n",
    " 'q28_a_part_5',\n",
    " 'q28_a_part_6',\n",
    " 'q28_a_part_7',\n",
    " 'q28_a_part_8',\n",
    " 'q28_a_part_9',\n",
    " 'q28_a_part_10',\n",
    " 'q28_a_other',\n",
    " 'q29_a_part_1',\n",
    " 'q29_a_part_2',\n",
    " 'q29_a_part_3',\n",
    " 'q29_a_part_4',\n",
    " 'q29_a_part_5',\n",
    " 'q29_a_part_6',\n",
    " 'q29_a_part_7',\n",
    " 'q29_a_part_8',\n",
    " 'q29_a_part_9',\n",
    " 'q29_a_part_10',\n",
    " 'q29_a_part_11',\n",
    " 'q29_a_part_12',\n",
    " 'q29_a_part_13',\n",
    " 'q29_a_part_14',\n",
    " 'q29_a_part_15',\n",
    " 'q29_a_part_16',\n",
    " 'q29_a_part_17',\n",
    " 'q29_a_other',\n",
    " 'q31_a_part_1',\n",
    " 'q31_a_part_2',\n",
    " 'q31_a_part_3',\n",
    " 'q31_a_part_4',\n",
    " 'q31_a_part_5',\n",
    " 'q31_a_part_6',\n",
    " 'q31_a_part_7',\n",
    " 'q31_a_part_8',\n",
    " 'q31_a_part_9',\n",
    " 'q31_a_part_10',\n",
    " 'q31_a_part_11',\n",
    " 'q31_a_part_12',\n",
    " 'q31_a_part_13',\n",
    " 'q31_a_part_14',\n",
    " 'q31_a_other',\n",
    " 'q34_a_part_1',\n",
    " 'q34_a_part_2',\n",
    " 'q34_a_part_3',\n",
    " 'q34_a_part_4',\n",
    " 'q34_a_part_5',\n",
    " 'q34_a_part_6',\n",
    " 'q34_a_part_7',\n",
    " 'q34_a_part_8',\n",
    " 'q34_a_part_9',\n",
    " 'q34_a_part_10',\n",
    " 'q34_a_part_11',\n",
    " 'q34_a_other',\n",
    " 'q35_a_part_1',\n",
    " 'q35_a_part_2',\n",
    " 'q35_a_part_3',\n",
    " 'q35_a_part_4',\n",
    " 'q35_a_part_5',\n",
    " 'q35_a_part_6',\n",
    " 'q35_a_part_7',\n",
    " 'q35_a_part_8',\n",
    " 'q35_a_part_9',\n",
    " 'q35_a_part_10',\n",
    " 'q35_a_other',\n",
    " 'q36_part_1',\n",
    " 'q36_part_2',\n",
    " 'q36_part_3',\n",
    " 'q36_part_4',\n",
    " 'q36_part_5',\n",
    " 'q36_part_6',\n",
    " 'q36_part_7',\n",
    " 'q36_part_8',\n",
    " 'q36_part_9',\n",
    " 'q36_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_b_dropped = [\n",
    "    'q26_b_part_1',\n",
    " 'q26_b_part_2',\n",
    " 'q26_b_part_3',\n",
    " 'q26_b_part_4',\n",
    " 'q26_b_part_5',\n",
    " 'q26_b_part_6',\n",
    " 'q26_b_part_7',\n",
    " 'q26_b_part_8',\n",
    " 'q26_b_part_9',\n",
    " 'q26_b_part_10',\n",
    " 'q26_b_part_11',\n",
    " 'q26_b_other',\n",
    " 'q27_b_part_1',\n",
    " 'q27_b_part_2',\n",
    " 'q27_b_part_3',\n",
    " 'q27_b_part_4',\n",
    " 'q27_b_part_5',\n",
    " 'q27_b_part_6',\n",
    " 'q27_b_part_7',\n",
    " 'q27_b_part_8',\n",
    " 'q27_b_part_9',\n",
    " 'q27_b_part_10',\n",
    " 'q27_b_part_11',\n",
    " 'q27_b_other',\n",
    " 'q28_b_part_1',\n",
    " 'q28_b_part_2',\n",
    " 'q28_b_part_3',\n",
    " 'q28_b_part_4',\n",
    " 'q28_b_part_5',\n",
    " 'q28_b_part_6',\n",
    " 'q28_b_part_7',\n",
    " 'q28_b_part_8',\n",
    " 'q28_b_part_9',\n",
    " 'q28_b_part_10',\n",
    " 'q28_b_other',\n",
    " 'q29_b_part_1',\n",
    " 'q29_b_part_2',\n",
    " 'q29_b_part_3',\n",
    " 'q29_b_part_4',\n",
    " 'q29_b_part_5',\n",
    " 'q29_b_part_6',\n",
    " 'q29_b_part_7',\n",
    " 'q29_b_part_8',\n",
    " 'q29_b_part_9',\n",
    " 'q29_b_part_10',\n",
    " 'q29_b_part_11',\n",
    " 'q29_b_part_12',\n",
    " 'q29_b_part_13',\n",
    " 'q29_b_part_14',\n",
    " 'q29_b_part_15',\n",
    " 'q29_b_part_16',\n",
    " 'q29_b_part_17',\n",
    " 'q29_b_other',\n",
    " 'q31_b_part_1',\n",
    " 'q31_b_part_2',\n",
    " 'q31_b_part_3',\n",
    " 'q31_b_part_4',\n",
    " 'q31_b_part_5',\n",
    " 'q31_b_part_6',\n",
    " 'q31_b_part_7',\n",
    " 'q31_b_part_8',\n",
    " 'q31_b_part_9',\n",
    " 'q31_b_part_10',\n",
    " 'q31_b_part_11',\n",
    " 'q31_b_part_12',\n",
    " 'q31_b_part_13',\n",
    " 'q31_b_part_14',\n",
    " 'q31_b_other',\n",
    " 'q33_b_part_1',\n",
    " 'q33_b_part_2',\n",
    " 'q33_b_part_3',\n",
    " 'q33_b_part_4',\n",
    " 'q33_b_part_5',\n",
    " 'q33_b_part_6',\n",
    " 'q33_b_part_7',\n",
    " 'q33_b_other',\n",
    " 'q34_b_part_1',\n",
    " 'q34_b_part_2',\n",
    " 'q34_b_part_3',\n",
    " 'q34_b_part_4',\n",
    " 'q34_b_part_5',\n",
    " 'q34_b_part_6',\n",
    " 'q34_b_part_7',\n",
    " 'q34_b_part_8',\n",
    " 'q34_b_part_9',\n",
    " 'q34_b_part_10',\n",
    " 'q34_b_part_11',\n",
    " 'q34_b_other',\n",
    " 'q35_b_part_1',\n",
    " 'q35_b_part_2',\n",
    " 'q35_b_part_3',\n",
    " 'q35_b_part_4',\n",
    " 'q35_b_part_5',\n",
    " 'q35_b_part_6',\n",
    " 'q35_b_part_7',\n",
    " 'q35_b_part_8',\n",
    " 'q35_b_part_9',\n",
    " 'q35_b_part_10',\n",
    " 'q35_b_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = one_hot_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = part_b_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_selected_questions = salary_data.drop(columns = dropped_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salary_data_as_num.drop(columns = [\"q24\"])\n",
    "y = salary_data_as_num[\"q24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_test, y_dev, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 16:18:20.577098: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-28 16:18:20.577150: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-11-28 16:18:20.577165: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-11-28 16:18:20.577448: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-28 16:18:20.577832: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x_dev = tf.convert_to_tensor(x_dev.astype(\"int64\"))\n",
    "x_test = tf.convert_to_tensor(x_test.astype(\"int64\"))\n",
    "y_dev = tf.convert_to_tensor(y_dev.astype(\"int64\"))\n",
    "y_test = tf.convert_to_tensor(y_test.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 16:18:21.374123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60/129 [============>.................] - ETA: 0s - loss: 2.8690 - accuracy: 0.3992"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 2s 9ms/step - loss: 2.3547 - accuracy: 0.4574 - val_loss: 1.8070 - val_accuracy: 0.5203\n",
      "Epoch 2/2\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7652 - accuracy: 0.5253 - val_loss: 1.6875 - val_accuracy: 0.5452\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_shape = (80, ), activation = \"relu\"),\n",
    "    Dense(26, activation = \"softmax\")\n",
    "])\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "history_callback = model.fit(x_dev, y_dev, batch_size = 100, epochs = 2, validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7649109363555908, 0.5227046012878418]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    \n",
    "    def __init__(self, x_dev = x_dev, y_dev = y_dev, x_test = x_test, y_test = y_test):\n",
    "        self.x_dev = x_dev\n",
    "        self.y_dev = y_dev\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.layers = [Dense(32, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "        self.optimizer = \"adam\"\n",
    "        self.loss = \"sparse_categorical_crossentropy\"\n",
    "        self.metrics =  [\"accuracy\"]\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.epochs = 50\n",
    "        \n",
    "    def customize_first_layer(self, node_count = 32):\n",
    "        self.layers = [Dense(node_count, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "    def customize_middle_layers(self, layers):\n",
    "        self.layers.extend(layers)\n",
    "    \n",
    "    def customize_compile(self,\n",
    "                          optimizer = \"adam\",\n",
    "                          loss = \"sparse_categorical_crossentropy\",\n",
    "                          metrics = [\"accuracy\"]):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def customize_fit(self,\n",
    "                      batch_size = 100,\n",
    "                      epochs = 50\n",
    "                      ):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def build_compile_and_evaluate(self, metric_to_return = \"accuracy\", selection_criteria = max):\n",
    "        # final layer must be softmax and outputs 26\n",
    "        self.layers.append(Dense(26, activation = \"softmax\"))\n",
    "        \n",
    "        self.model = Sequential(self.layers)\n",
    "        self.model.compile(optimizer = self.optimizer,\n",
    "                      loss = self.loss,\n",
    "                      metrics = self.metrics)\n",
    "        fit_history = self.model.fit(self.x_dev, self.y_dev,\n",
    "                                batch_size = self.batch_size,\n",
    "                                epochs = self.epochs,\n",
    "                                validation_split = 0.2,\n",
    "                                verbose = 1)\n",
    "        self.fit_history = pd.DataFrame(fit_history.history)\n",
    "        return selection_criteria(self.fit_history[metric_to_return])\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    def get_fit_history(self):\n",
    "        return self.fit_history\n",
    "        \n",
    "    def evaluate_model_with_test(self):\n",
    "        return self.model.evaluate(self.x_test, self.y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DNN()\n",
    "d.customize_fit(epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 3.6649 - accuracy: 0.3497 - val_loss: 2.2721 - val_accuracy: 0.4797\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 2.1184 - accuracy: 0.4813 - val_loss: 1.9866 - val_accuracy: 0.5066\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9217 - accuracy: 0.5038 - val_loss: 1.8589 - val_accuracy: 0.5150\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8136 - accuracy: 0.5196 - val_loss: 1.7719 - val_accuracy: 0.5343\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7505 - accuracy: 0.5284 - val_loss: 1.7250 - val_accuracy: 0.5381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5283886790275574"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.build_compile_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               10368     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                3354      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13722 (53.60 KB)\n",
      "Trainable params: 13722 (53.60 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d.get_model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Layer: First Layer Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- building model for layer width of 1\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 11ms/step - loss: 5.2198 - accuracy: 0.0198 - val_loss: 4.4183 - val_accuracy: 0.0262\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 3.6831 - accuracy: 0.1344 - val_loss: 3.0751 - val_accuracy: 0.4729\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.8463 - accuracy: 0.4646 - val_loss: 2.6482 - val_accuracy: 0.4729\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.5709 - accuracy: 0.4639 - val_loss: 2.4750 - val_accuracy: 0.4719\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.4688 - accuracy: 0.4625 - val_loss: 2.4284 - val_accuracy: 0.4704\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.4434 - accuracy: 0.4633 - val_loss: 2.4133 - val_accuracy: 0.4719\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.4320 - accuracy: 0.4643 - val_loss: 2.4040 - val_accuracy: 0.4729\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.4233 - accuracy: 0.4647 - val_loss: 2.3950 - val_accuracy: 0.4726\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.4156 - accuracy: 0.4647 - val_loss: 2.3881 - val_accuracy: 0.4729\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.4072 - accuracy: 0.4647 - val_loss: 2.3811 - val_accuracy: 0.4729\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.3995 - accuracy: 0.4647 - val_loss: 2.3723 - val_accuracy: 0.4729\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.3917 - accuracy: 0.4647 - val_loss: 2.3636 - val_accuracy: 0.4729\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3841 - accuracy: 0.4647 - val_loss: 2.3551 - val_accuracy: 0.4729\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.3763 - accuracy: 0.4647 - val_loss: 2.3477 - val_accuracy: 0.4729\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.3684 - accuracy: 0.4647 - val_loss: 2.3405 - val_accuracy: 0.4729\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.3611 - accuracy: 0.4647 - val_loss: 2.3325 - val_accuracy: 0.4729\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3534 - accuracy: 0.4647 - val_loss: 2.3247 - val_accuracy: 0.4729\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3464 - accuracy: 0.4647 - val_loss: 2.3172 - val_accuracy: 0.4729\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3389 - accuracy: 0.4647 - val_loss: 2.3102 - val_accuracy: 0.4729\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.3321 - accuracy: 0.4647 - val_loss: 2.3036 - val_accuracy: 0.4729\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3256 - accuracy: 0.4647 - val_loss: 2.2965 - val_accuracy: 0.4729\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3191 - accuracy: 0.4647 - val_loss: 2.2902 - val_accuracy: 0.4729\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3127 - accuracy: 0.4647 - val_loss: 2.2849 - val_accuracy: 0.4729\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.3080 - accuracy: 0.4647 - val_loss: 2.2783 - val_accuracy: 0.4729\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3022 - accuracy: 0.4647 - val_loss: 2.2733 - val_accuracy: 0.4729\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2974 - accuracy: 0.4647 - val_loss: 2.2675 - val_accuracy: 0.4729\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2930 - accuracy: 0.4647 - val_loss: 2.2642 - val_accuracy: 0.4729\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2880 - accuracy: 0.4647 - val_loss: 2.2597 - val_accuracy: 0.4729\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2842 - accuracy: 0.4647 - val_loss: 2.2551 - val_accuracy: 0.4729\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2810 - accuracy: 0.4647 - val_loss: 2.2524 - val_accuracy: 0.4729\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2778 - accuracy: 0.4647 - val_loss: 2.2507 - val_accuracy: 0.4729\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2754 - accuracy: 0.4647 - val_loss: 2.2467 - val_accuracy: 0.4729\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2725 - accuracy: 0.4647 - val_loss: 2.2444 - val_accuracy: 0.4729\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2698 - accuracy: 0.4647 - val_loss: 2.2413 - val_accuracy: 0.4729\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2676 - accuracy: 0.4647 - val_loss: 2.2392 - val_accuracy: 0.4729\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2653 - accuracy: 0.4647 - val_loss: 2.2371 - val_accuracy: 0.4729\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2636 - accuracy: 0.4647 - val_loss: 2.2348 - val_accuracy: 0.4729\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2614 - accuracy: 0.4647 - val_loss: 2.2330 - val_accuracy: 0.4729\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.2601 - accuracy: 0.4647 - val_loss: 2.2314 - val_accuracy: 0.4729\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2583 - accuracy: 0.4647 - val_loss: 2.2294 - val_accuracy: 0.4729\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2571 - accuracy: 0.4647 - val_loss: 2.2274 - val_accuracy: 0.4729\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.2557 - accuracy: 0.4647 - val_loss: 2.2267 - val_accuracy: 0.4729\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2542 - accuracy: 0.4647 - val_loss: 2.2251 - val_accuracy: 0.4729\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 3s 20ms/step - loss: 2.2534 - accuracy: 0.4647 - val_loss: 2.2239 - val_accuracy: 0.4729\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.2516 - accuracy: 0.4647 - val_loss: 2.2227 - val_accuracy: 0.4729\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.2504 - accuracy: 0.4647 - val_loss: 2.2206 - val_accuracy: 0.4729\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.2487 - accuracy: 0.4647 - val_loss: 2.2191 - val_accuracy: 0.4729\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.2470 - accuracy: 0.4647 - val_loss: 2.2180 - val_accuracy: 0.4729\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2464 - accuracy: 0.4647 - val_loss: 2.2164 - val_accuracy: 0.4729\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2444 - accuracy: 0.4647 - val_loss: 2.2149 - val_accuracy: 0.4729\n",
      "---- building model for layer width of 2\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 9ms/step - loss: 2.8273 - accuracy: 0.3620 - val_loss: 2.4741 - val_accuracy: 0.4669\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3577 - accuracy: 0.4735 - val_loss: 2.2007 - val_accuracy: 0.4953\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.1330 - accuracy: 0.4998 - val_loss: 2.0217 - val_accuracy: 0.5175\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9802 - accuracy: 0.5096 - val_loss: 1.8986 - val_accuracy: 0.5237\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8853 - accuracy: 0.5145 - val_loss: 1.8198 - val_accuracy: 0.5306\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8235 - accuracy: 0.5200 - val_loss: 1.7683 - val_accuracy: 0.5324\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7820 - accuracy: 0.5253 - val_loss: 1.7344 - val_accuracy: 0.5434\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7523 - accuracy: 0.5285 - val_loss: 1.7058 - val_accuracy: 0.5365\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7295 - accuracy: 0.5311 - val_loss: 1.6866 - val_accuracy: 0.5471\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7118 - accuracy: 0.5335 - val_loss: 1.6684 - val_accuracy: 0.5493\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6979 - accuracy: 0.5366 - val_loss: 1.6545 - val_accuracy: 0.5465\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6864 - accuracy: 0.5377 - val_loss: 1.6430 - val_accuracy: 0.5483\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6779 - accuracy: 0.5377 - val_loss: 1.6334 - val_accuracy: 0.5502\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6691 - accuracy: 0.5406 - val_loss: 1.6257 - val_accuracy: 0.5527\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6629 - accuracy: 0.5397 - val_loss: 1.6192 - val_accuracy: 0.5543\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6566 - accuracy: 0.5406 - val_loss: 1.6145 - val_accuracy: 0.5555\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6520 - accuracy: 0.5406 - val_loss: 1.6105 - val_accuracy: 0.5580\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6469 - accuracy: 0.5428 - val_loss: 1.6042 - val_accuracy: 0.5568\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6427 - accuracy: 0.5435 - val_loss: 1.6013 - val_accuracy: 0.5586\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6396 - accuracy: 0.5423 - val_loss: 1.5995 - val_accuracy: 0.5574\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6363 - accuracy: 0.5457 - val_loss: 1.5942 - val_accuracy: 0.5565\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6331 - accuracy: 0.5449 - val_loss: 1.5941 - val_accuracy: 0.5577\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6314 - accuracy: 0.5472 - val_loss: 1.5913 - val_accuracy: 0.5565\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6288 - accuracy: 0.5471 - val_loss: 1.5903 - val_accuracy: 0.5614\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6266 - accuracy: 0.5458 - val_loss: 1.5902 - val_accuracy: 0.5614\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6259 - accuracy: 0.5473 - val_loss: 1.5865 - val_accuracy: 0.5611\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6248 - accuracy: 0.5482 - val_loss: 1.5845 - val_accuracy: 0.5580\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6242 - accuracy: 0.5480 - val_loss: 1.5835 - val_accuracy: 0.5586\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6234 - accuracy: 0.5473 - val_loss: 1.5880 - val_accuracy: 0.5565\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6238 - accuracy: 0.5482 - val_loss: 1.5835 - val_accuracy: 0.5624\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6236 - accuracy: 0.5479 - val_loss: 1.5849 - val_accuracy: 0.5608\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6248 - accuracy: 0.5492 - val_loss: 1.5858 - val_accuracy: 0.5599\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6248 - accuracy: 0.5491 - val_loss: 1.5852 - val_accuracy: 0.5608\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6241 - accuracy: 0.5490 - val_loss: 1.5875 - val_accuracy: 0.5630\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6241 - accuracy: 0.5489 - val_loss: 1.5856 - val_accuracy: 0.5624\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6256 - accuracy: 0.5488 - val_loss: 1.5867 - val_accuracy: 0.5621\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6257 - accuracy: 0.5473 - val_loss: 1.5858 - val_accuracy: 0.5627\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6257 - accuracy: 0.5475 - val_loss: 1.5866 - val_accuracy: 0.5608\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6236 - accuracy: 0.5473 - val_loss: 1.5876 - val_accuracy: 0.5627\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6246 - accuracy: 0.5463 - val_loss: 1.5872 - val_accuracy: 0.5618\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6241 - accuracy: 0.5471 - val_loss: 1.5887 - val_accuracy: 0.5618\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6248 - accuracy: 0.5459 - val_loss: 1.5880 - val_accuracy: 0.5602\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6242 - accuracy: 0.5465 - val_loss: 1.5877 - val_accuracy: 0.5614\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6236 - accuracy: 0.5461 - val_loss: 1.5876 - val_accuracy: 0.5608\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6232 - accuracy: 0.5467 - val_loss: 1.5881 - val_accuracy: 0.5624\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6239 - accuracy: 0.5470 - val_loss: 1.5895 - val_accuracy: 0.5583\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6233 - accuracy: 0.5451 - val_loss: 1.5891 - val_accuracy: 0.5596\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6239 - accuracy: 0.5451 - val_loss: 1.5907 - val_accuracy: 0.5568\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6244 - accuracy: 0.5455 - val_loss: 1.5881 - val_accuracy: 0.5627\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6232 - accuracy: 0.5459 - val_loss: 1.5893 - val_accuracy: 0.5614\n",
      "---- building model for layer width of 4\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.1654 - accuracy: 0.0262 - val_loss: 3.1975 - val_accuracy: 0.1036\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 2.8593 - accuracy: 0.3016 - val_loss: 2.6842 - val_accuracy: 0.4370\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.6411 - accuracy: 0.4572 - val_loss: 2.5756 - val_accuracy: 0.4710\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.5252 - accuracy: 0.4643 - val_loss: 2.3364 - val_accuracy: 0.4779\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.1593 - accuracy: 0.4779 - val_loss: 1.9837 - val_accuracy: 0.4966\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9261 - accuracy: 0.4942 - val_loss: 1.8387 - val_accuracy: 0.5156\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8389 - accuracy: 0.5071 - val_loss: 1.7780 - val_accuracy: 0.5218\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8005 - accuracy: 0.5125 - val_loss: 1.7502 - val_accuracy: 0.5296\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7821 - accuracy: 0.5196 - val_loss: 1.7349 - val_accuracy: 0.5315\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7702 - accuracy: 0.5215 - val_loss: 1.7235 - val_accuracy: 0.5390\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7626 - accuracy: 0.5241 - val_loss: 1.7180 - val_accuracy: 0.5405\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7575 - accuracy: 0.5239 - val_loss: 1.7110 - val_accuracy: 0.5412\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7536 - accuracy: 0.5270 - val_loss: 1.7086 - val_accuracy: 0.5440\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7511 - accuracy: 0.5263 - val_loss: 1.7046 - val_accuracy: 0.5434\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7497 - accuracy: 0.5262 - val_loss: 1.7026 - val_accuracy: 0.5427\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7483 - accuracy: 0.5278 - val_loss: 1.7013 - val_accuracy: 0.5421\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7460 - accuracy: 0.5268 - val_loss: 1.7016 - val_accuracy: 0.5402\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7450 - accuracy: 0.5271 - val_loss: 1.6996 - val_accuracy: 0.5424\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7439 - accuracy: 0.5261 - val_loss: 1.6989 - val_accuracy: 0.5405\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7421 - accuracy: 0.5264 - val_loss: 1.6993 - val_accuracy: 0.5418\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7402 - accuracy: 0.5283 - val_loss: 1.6963 - val_accuracy: 0.5402\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7399 - accuracy: 0.5275 - val_loss: 1.6929 - val_accuracy: 0.5421\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7386 - accuracy: 0.5284 - val_loss: 1.6935 - val_accuracy: 0.5393\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7372 - accuracy: 0.5271 - val_loss: 1.6917 - val_accuracy: 0.5427\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7365 - accuracy: 0.5279 - val_loss: 1.6915 - val_accuracy: 0.5421\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7357 - accuracy: 0.5285 - val_loss: 1.6881 - val_accuracy: 0.5430\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7339 - accuracy: 0.5292 - val_loss: 1.6905 - val_accuracy: 0.5412\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7331 - accuracy: 0.5287 - val_loss: 1.6865 - val_accuracy: 0.5421\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7321 - accuracy: 0.5285 - val_loss: 1.6841 - val_accuracy: 0.5434\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7312 - accuracy: 0.5288 - val_loss: 1.6854 - val_accuracy: 0.5396\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7299 - accuracy: 0.5303 - val_loss: 1.6850 - val_accuracy: 0.5430\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7288 - accuracy: 0.5278 - val_loss: 1.6818 - val_accuracy: 0.5421\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7285 - accuracy: 0.5280 - val_loss: 1.6821 - val_accuracy: 0.5427\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7272 - accuracy: 0.5275 - val_loss: 1.6817 - val_accuracy: 0.5430\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7262 - accuracy: 0.5301 - val_loss: 1.6809 - val_accuracy: 0.5418\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7249 - accuracy: 0.5287 - val_loss: 1.6805 - val_accuracy: 0.5427\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7243 - accuracy: 0.5297 - val_loss: 1.6780 - val_accuracy: 0.5427\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7240 - accuracy: 0.5296 - val_loss: 1.6785 - val_accuracy: 0.5396\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7220 - accuracy: 0.5284 - val_loss: 1.6773 - val_accuracy: 0.5430\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7237 - accuracy: 0.5284 - val_loss: 1.6880 - val_accuracy: 0.5374\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7237 - accuracy: 0.5291 - val_loss: 1.6830 - val_accuracy: 0.5399\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7230 - accuracy: 0.5279 - val_loss: 1.6891 - val_accuracy: 0.5387\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7246 - accuracy: 0.5260 - val_loss: 1.6840 - val_accuracy: 0.5409\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7220 - accuracy: 0.5268 - val_loss: 1.6814 - val_accuracy: 0.5402\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7194 - accuracy: 0.5279 - val_loss: 1.6747 - val_accuracy: 0.5381\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7177 - accuracy: 0.5285 - val_loss: 1.6730 - val_accuracy: 0.5440\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7146 - accuracy: 0.5288 - val_loss: 1.6719 - val_accuracy: 0.5409\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7107 - accuracy: 0.5274 - val_loss: 1.6701 - val_accuracy: 0.5377\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7087 - accuracy: 0.5282 - val_loss: 1.6639 - val_accuracy: 0.5405\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.7073 - accuracy: 0.5289 - val_loss: 1.6610 - val_accuracy: 0.5421\n",
      "---- building model for layer width of 8\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 3.8764 - accuracy: 0.2052 - val_loss: 2.6063 - val_accuracy: 0.4548\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.3017 - accuracy: 0.4620 - val_loss: 2.0865 - val_accuracy: 0.4910\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.0007 - accuracy: 0.4949 - val_loss: 1.8857 - val_accuracy: 0.5168\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8572 - accuracy: 0.5099 - val_loss: 1.7785 - val_accuracy: 0.5362\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7813 - accuracy: 0.5196 - val_loss: 1.7243 - val_accuracy: 0.5384\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7404 - accuracy: 0.5278 - val_loss: 1.6889 - val_accuracy: 0.5415\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7154 - accuracy: 0.5324 - val_loss: 1.6713 - val_accuracy: 0.5452\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6971 - accuracy: 0.5346 - val_loss: 1.6594 - val_accuracy: 0.5418\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6863 - accuracy: 0.5360 - val_loss: 1.6425 - val_accuracy: 0.5471\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6762 - accuracy: 0.5390 - val_loss: 1.6345 - val_accuracy: 0.5493\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6707 - accuracy: 0.5385 - val_loss: 1.6260 - val_accuracy: 0.5505\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6621 - accuracy: 0.5402 - val_loss: 1.6267 - val_accuracy: 0.5490\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6578 - accuracy: 0.5396 - val_loss: 1.6265 - val_accuracy: 0.5502\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6518 - accuracy: 0.5411 - val_loss: 1.6153 - val_accuracy: 0.5487\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6490 - accuracy: 0.5417 - val_loss: 1.6115 - val_accuracy: 0.5512\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6454 - accuracy: 0.5436 - val_loss: 1.6143 - val_accuracy: 0.5530\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6403 - accuracy: 0.5422 - val_loss: 1.6009 - val_accuracy: 0.5508\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6346 - accuracy: 0.5460 - val_loss: 1.6017 - val_accuracy: 0.5512\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6303 - accuracy: 0.5462 - val_loss: 1.5935 - val_accuracy: 0.5512\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6252 - accuracy: 0.5452 - val_loss: 1.5868 - val_accuracy: 0.5533\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6208 - accuracy: 0.5451 - val_loss: 1.5844 - val_accuracy: 0.5571\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6173 - accuracy: 0.5473 - val_loss: 1.5812 - val_accuracy: 0.5540\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6134 - accuracy: 0.5459 - val_loss: 1.5814 - val_accuracy: 0.5546\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6089 - accuracy: 0.5463 - val_loss: 1.5785 - val_accuracy: 0.5555\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6069 - accuracy: 0.5470 - val_loss: 1.5757 - val_accuracy: 0.5536\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6042 - accuracy: 0.5460 - val_loss: 1.5721 - val_accuracy: 0.5558\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6014 - accuracy: 0.5490 - val_loss: 1.5702 - val_accuracy: 0.5555\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5981 - accuracy: 0.5485 - val_loss: 1.5691 - val_accuracy: 0.5552\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5976 - accuracy: 0.5480 - val_loss: 1.5651 - val_accuracy: 0.5574\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5936 - accuracy: 0.5504 - val_loss: 1.5626 - val_accuracy: 0.5577\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5915 - accuracy: 0.5495 - val_loss: 1.5666 - val_accuracy: 0.5586\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5887 - accuracy: 0.5503 - val_loss: 1.5646 - val_accuracy: 0.5546\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5872 - accuracy: 0.5486 - val_loss: 1.5596 - val_accuracy: 0.5618\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5867 - accuracy: 0.5480 - val_loss: 1.5594 - val_accuracy: 0.5543\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5833 - accuracy: 0.5505 - val_loss: 1.5613 - val_accuracy: 0.5646\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5828 - accuracy: 0.5513 - val_loss: 1.5559 - val_accuracy: 0.5580\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5807 - accuracy: 0.5509 - val_loss: 1.5571 - val_accuracy: 0.5611\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5823 - accuracy: 0.5501 - val_loss: 1.5544 - val_accuracy: 0.5577\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5782 - accuracy: 0.5509 - val_loss: 1.5518 - val_accuracy: 0.5590\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5772 - accuracy: 0.5515 - val_loss: 1.5571 - val_accuracy: 0.5639\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5754 - accuracy: 0.5514 - val_loss: 1.5491 - val_accuracy: 0.5580\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5754 - accuracy: 0.5509 - val_loss: 1.5508 - val_accuracy: 0.5643\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5727 - accuracy: 0.5532 - val_loss: 1.5490 - val_accuracy: 0.5583\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5718 - accuracy: 0.5528 - val_loss: 1.5518 - val_accuracy: 0.5571\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5714 - accuracy: 0.5544 - val_loss: 1.5459 - val_accuracy: 0.5590\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5685 - accuracy: 0.5525 - val_loss: 1.5519 - val_accuracy: 0.5633\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5689 - accuracy: 0.5519 - val_loss: 1.5445 - val_accuracy: 0.5614\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5663 - accuracy: 0.5544 - val_loss: 1.5456 - val_accuracy: 0.5608\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5678 - accuracy: 0.5526 - val_loss: 1.5459 - val_accuracy: 0.5614\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5662 - accuracy: 0.5529 - val_loss: 1.5453 - val_accuracy: 0.5596\n",
      "---- building model for layer width of 16\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 3.2841 - accuracy: 0.3628 - val_loss: 2.4247 - val_accuracy: 0.4548\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2471 - accuracy: 0.4680 - val_loss: 2.0816 - val_accuracy: 0.4888\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.0072 - accuracy: 0.4948 - val_loss: 1.9132 - val_accuracy: 0.5100\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.8758 - accuracy: 0.5104 - val_loss: 1.8152 - val_accuracy: 0.5274\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7993 - accuracy: 0.5216 - val_loss: 1.7491 - val_accuracy: 0.5324\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7542 - accuracy: 0.5287 - val_loss: 1.7125 - val_accuracy: 0.5421\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7268 - accuracy: 0.5329 - val_loss: 1.6892 - val_accuracy: 0.5424\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7061 - accuracy: 0.5359 - val_loss: 1.6741 - val_accuracy: 0.5415\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6874 - accuracy: 0.5376 - val_loss: 1.6564 - val_accuracy: 0.5446\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6742 - accuracy: 0.5406 - val_loss: 1.6458 - val_accuracy: 0.5487\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6638 - accuracy: 0.5432 - val_loss: 1.6437 - val_accuracy: 0.5471\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6545 - accuracy: 0.5433 - val_loss: 1.6295 - val_accuracy: 0.5536\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6462 - accuracy: 0.5467 - val_loss: 1.6215 - val_accuracy: 0.5533\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6372 - accuracy: 0.5481 - val_loss: 1.6189 - val_accuracy: 0.5496\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6314 - accuracy: 0.5485 - val_loss: 1.6123 - val_accuracy: 0.5502\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6240 - accuracy: 0.5504 - val_loss: 1.6122 - val_accuracy: 0.5512\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6198 - accuracy: 0.5501 - val_loss: 1.6075 - val_accuracy: 0.5508\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6141 - accuracy: 0.5519 - val_loss: 1.6073 - val_accuracy: 0.5496\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6103 - accuracy: 0.5506 - val_loss: 1.5991 - val_accuracy: 0.5540\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6088 - accuracy: 0.5504 - val_loss: 1.6050 - val_accuracy: 0.5533\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6033 - accuracy: 0.5511 - val_loss: 1.5893 - val_accuracy: 0.5583\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6006 - accuracy: 0.5519 - val_loss: 1.5895 - val_accuracy: 0.5521\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5974 - accuracy: 0.5523 - val_loss: 1.5885 - val_accuracy: 0.5599\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5936 - accuracy: 0.5526 - val_loss: 1.5931 - val_accuracy: 0.5574\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5925 - accuracy: 0.5528 - val_loss: 1.5884 - val_accuracy: 0.5568\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5899 - accuracy: 0.5522 - val_loss: 1.5898 - val_accuracy: 0.5590\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5888 - accuracy: 0.5544 - val_loss: 1.5796 - val_accuracy: 0.5583\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5862 - accuracy: 0.5541 - val_loss: 1.5808 - val_accuracy: 0.5580\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5881 - accuracy: 0.5537 - val_loss: 1.5793 - val_accuracy: 0.5574\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5849 - accuracy: 0.5510 - val_loss: 1.5782 - val_accuracy: 0.5596\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5833 - accuracy: 0.5542 - val_loss: 1.5811 - val_accuracy: 0.5624\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5808 - accuracy: 0.5537 - val_loss: 1.5805 - val_accuracy: 0.5568\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5792 - accuracy: 0.5534 - val_loss: 1.5790 - val_accuracy: 0.5561\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5773 - accuracy: 0.5525 - val_loss: 1.5817 - val_accuracy: 0.5608\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5775 - accuracy: 0.5528 - val_loss: 1.5764 - val_accuracy: 0.5621\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5756 - accuracy: 0.5532 - val_loss: 1.5716 - val_accuracy: 0.5599\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5746 - accuracy: 0.5543 - val_loss: 1.5778 - val_accuracy: 0.5583\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5737 - accuracy: 0.5536 - val_loss: 1.5749 - val_accuracy: 0.5586\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5750 - accuracy: 0.5525 - val_loss: 1.5681 - val_accuracy: 0.5577\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5705 - accuracy: 0.5538 - val_loss: 1.5761 - val_accuracy: 0.5558\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5737 - accuracy: 0.5534 - val_loss: 1.5671 - val_accuracy: 0.5593\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5687 - accuracy: 0.5537 - val_loss: 1.5715 - val_accuracy: 0.5571\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5676 - accuracy: 0.5557 - val_loss: 1.5760 - val_accuracy: 0.5583\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5682 - accuracy: 0.5523 - val_loss: 1.5736 - val_accuracy: 0.5639\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5684 - accuracy: 0.5536 - val_loss: 1.5669 - val_accuracy: 0.5593\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5662 - accuracy: 0.5548 - val_loss: 1.5742 - val_accuracy: 0.5555\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5663 - accuracy: 0.5518 - val_loss: 1.5695 - val_accuracy: 0.5586\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5665 - accuracy: 0.5524 - val_loss: 1.5657 - val_accuracy: 0.5543\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5662 - accuracy: 0.5537 - val_loss: 1.5660 - val_accuracy: 0.5602\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5642 - accuracy: 0.5533 - val_loss: 1.5717 - val_accuracy: 0.5599\n",
      "---- building model for layer width of 32\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.3294 - accuracy: 0.3545 - val_loss: 2.1674 - val_accuracy: 0.4906\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.0335 - accuracy: 0.4910 - val_loss: 1.8923 - val_accuracy: 0.5178\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8618 - accuracy: 0.5103 - val_loss: 1.7853 - val_accuracy: 0.5331\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7833 - accuracy: 0.5214 - val_loss: 1.7210 - val_accuracy: 0.5331\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7319 - accuracy: 0.5303 - val_loss: 1.6840 - val_accuracy: 0.5387\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7005 - accuracy: 0.5358 - val_loss: 1.6602 - val_accuracy: 0.5405\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6767 - accuracy: 0.5392 - val_loss: 1.6486 - val_accuracy: 0.5468\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6574 - accuracy: 0.5440 - val_loss: 1.6271 - val_accuracy: 0.5477\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6427 - accuracy: 0.5452 - val_loss: 1.6217 - val_accuracy: 0.5512\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6341 - accuracy: 0.5455 - val_loss: 1.6111 - val_accuracy: 0.5487\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6231 - accuracy: 0.5494 - val_loss: 1.6080 - val_accuracy: 0.5546\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6147 - accuracy: 0.5501 - val_loss: 1.6010 - val_accuracy: 0.5602\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6069 - accuracy: 0.5519 - val_loss: 1.6052 - val_accuracy: 0.5496\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6030 - accuracy: 0.5537 - val_loss: 1.5970 - val_accuracy: 0.5568\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5961 - accuracy: 0.5533 - val_loss: 1.5904 - val_accuracy: 0.5602\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5932 - accuracy: 0.5540 - val_loss: 1.5956 - val_accuracy: 0.5627\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5922 - accuracy: 0.5544 - val_loss: 1.5895 - val_accuracy: 0.5611\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5880 - accuracy: 0.5557 - val_loss: 1.5950 - val_accuracy: 0.5574\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5863 - accuracy: 0.5565 - val_loss: 1.5826 - val_accuracy: 0.5593\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5822 - accuracy: 0.5546 - val_loss: 1.5883 - val_accuracy: 0.5602\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5804 - accuracy: 0.5548 - val_loss: 1.5818 - val_accuracy: 0.5643\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5771 - accuracy: 0.5572 - val_loss: 1.5864 - val_accuracy: 0.5630\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5729 - accuracy: 0.5560 - val_loss: 1.5806 - val_accuracy: 0.5596\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5752 - accuracy: 0.5565 - val_loss: 1.5810 - val_accuracy: 0.5649\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5701 - accuracy: 0.5576 - val_loss: 1.5816 - val_accuracy: 0.5574\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5682 - accuracy: 0.5565 - val_loss: 1.5749 - val_accuracy: 0.5627\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5649 - accuracy: 0.5583 - val_loss: 1.5768 - val_accuracy: 0.5533\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5648 - accuracy: 0.5562 - val_loss: 1.5708 - val_accuracy: 0.5658\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5624 - accuracy: 0.5566 - val_loss: 1.5756 - val_accuracy: 0.5618\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5591 - accuracy: 0.5601 - val_loss: 1.5738 - val_accuracy: 0.5590\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5596 - accuracy: 0.5583 - val_loss: 1.5677 - val_accuracy: 0.5618\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5594 - accuracy: 0.5572 - val_loss: 1.5775 - val_accuracy: 0.5540\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5595 - accuracy: 0.5600 - val_loss: 1.5838 - val_accuracy: 0.5590\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5572 - accuracy: 0.5551 - val_loss: 1.5679 - val_accuracy: 0.5586\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5540 - accuracy: 0.5587 - val_loss: 1.5777 - val_accuracy: 0.5667\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5523 - accuracy: 0.5591 - val_loss: 1.5722 - val_accuracy: 0.5586\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5515 - accuracy: 0.5617 - val_loss: 1.5653 - val_accuracy: 0.5568\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5470 - accuracy: 0.5600 - val_loss: 1.5717 - val_accuracy: 0.5602\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5493 - accuracy: 0.5586 - val_loss: 1.5741 - val_accuracy: 0.5643\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5484 - accuracy: 0.5591 - val_loss: 1.5696 - val_accuracy: 0.5618\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5478 - accuracy: 0.5588 - val_loss: 1.5712 - val_accuracy: 0.5614\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5479 - accuracy: 0.5581 - val_loss: 1.5683 - val_accuracy: 0.5549\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5465 - accuracy: 0.5595 - val_loss: 1.5752 - val_accuracy: 0.5661\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5446 - accuracy: 0.5605 - val_loss: 1.5696 - val_accuracy: 0.5540\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5441 - accuracy: 0.5594 - val_loss: 1.5702 - val_accuracy: 0.5599\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5412 - accuracy: 0.5634 - val_loss: 1.5770 - val_accuracy: 0.5621\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5418 - accuracy: 0.5604 - val_loss: 1.5639 - val_accuracy: 0.5636\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5394 - accuracy: 0.5603 - val_loss: 1.5766 - val_accuracy: 0.5608\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5429 - accuracy: 0.5615 - val_loss: 1.5676 - val_accuracy: 0.5602\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5381 - accuracy: 0.5620 - val_loss: 1.5906 - val_accuracy: 0.5571\n",
      "---- building model for layer width of 64\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.0489 - accuracy: 0.4087 - val_loss: 1.9346 - val_accuracy: 0.5209\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8722 - accuracy: 0.5129 - val_loss: 1.7735 - val_accuracy: 0.5328\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7627 - accuracy: 0.5258 - val_loss: 1.7044 - val_accuracy: 0.5396\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7125 - accuracy: 0.5357 - val_loss: 1.6630 - val_accuracy: 0.5546\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6753 - accuracy: 0.5420 - val_loss: 1.6375 - val_accuracy: 0.5524\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6532 - accuracy: 0.5435 - val_loss: 1.6447 - val_accuracy: 0.5530\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6365 - accuracy: 0.5472 - val_loss: 1.6165 - val_accuracy: 0.5546\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6275 - accuracy: 0.5475 - val_loss: 1.6148 - val_accuracy: 0.5596\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6122 - accuracy: 0.5509 - val_loss: 1.6073 - val_accuracy: 0.5565\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6079 - accuracy: 0.5509 - val_loss: 1.6158 - val_accuracy: 0.5443\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6002 - accuracy: 0.5525 - val_loss: 1.6010 - val_accuracy: 0.5571\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5938 - accuracy: 0.5547 - val_loss: 1.5855 - val_accuracy: 0.5593\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5901 - accuracy: 0.5521 - val_loss: 1.6020 - val_accuracy: 0.5596\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5807 - accuracy: 0.5560 - val_loss: 1.6030 - val_accuracy: 0.5596\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5761 - accuracy: 0.5551 - val_loss: 1.5884 - val_accuracy: 0.5630\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5758 - accuracy: 0.5551 - val_loss: 1.5898 - val_accuracy: 0.5590\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5749 - accuracy: 0.5559 - val_loss: 1.5817 - val_accuracy: 0.5611\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5691 - accuracy: 0.5555 - val_loss: 1.5900 - val_accuracy: 0.5630\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5668 - accuracy: 0.5565 - val_loss: 1.5911 - val_accuracy: 0.5586\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5655 - accuracy: 0.5577 - val_loss: 1.5975 - val_accuracy: 0.5574\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5664 - accuracy: 0.5572 - val_loss: 1.5852 - val_accuracy: 0.5602\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5639 - accuracy: 0.5573 - val_loss: 1.5818 - val_accuracy: 0.5611\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5596 - accuracy: 0.5583 - val_loss: 1.5809 - val_accuracy: 0.5602\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5583 - accuracy: 0.5599 - val_loss: 1.5814 - val_accuracy: 0.5658\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5598 - accuracy: 0.5590 - val_loss: 1.5885 - val_accuracy: 0.5649\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5528 - accuracy: 0.5605 - val_loss: 1.5814 - val_accuracy: 0.5624\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5548 - accuracy: 0.5572 - val_loss: 1.5931 - val_accuracy: 0.5646\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5515 - accuracy: 0.5575 - val_loss: 1.5823 - val_accuracy: 0.5624\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5549 - accuracy: 0.5585 - val_loss: 1.6150 - val_accuracy: 0.5568\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5544 - accuracy: 0.5601 - val_loss: 1.5982 - val_accuracy: 0.5639\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5522 - accuracy: 0.5596 - val_loss: 1.5905 - val_accuracy: 0.5636\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5476 - accuracy: 0.5589 - val_loss: 1.6019 - val_accuracy: 0.5590\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5472 - accuracy: 0.5620 - val_loss: 1.5908 - val_accuracy: 0.5633\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5451 - accuracy: 0.5604 - val_loss: 1.5904 - val_accuracy: 0.5565\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5459 - accuracy: 0.5570 - val_loss: 1.6059 - val_accuracy: 0.5596\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5450 - accuracy: 0.5601 - val_loss: 1.5991 - val_accuracy: 0.5621\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5512 - accuracy: 0.5569 - val_loss: 1.5991 - val_accuracy: 0.5627\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5445 - accuracy: 0.5601 - val_loss: 1.6208 - val_accuracy: 0.5580\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5417 - accuracy: 0.5620 - val_loss: 1.5879 - val_accuracy: 0.5561\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5467 - accuracy: 0.5590 - val_loss: 1.5830 - val_accuracy: 0.5618\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5412 - accuracy: 0.5605 - val_loss: 1.5879 - val_accuracy: 0.5636\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5378 - accuracy: 0.5619 - val_loss: 1.5857 - val_accuracy: 0.5577\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5437 - accuracy: 0.5586 - val_loss: 1.6026 - val_accuracy: 0.5580\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5449 - accuracy: 0.5595 - val_loss: 1.5916 - val_accuracy: 0.5618\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5394 - accuracy: 0.5569 - val_loss: 1.6099 - val_accuracy: 0.5549\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5416 - accuracy: 0.5579 - val_loss: 1.6063 - val_accuracy: 0.5577\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5406 - accuracy: 0.5617 - val_loss: 1.5924 - val_accuracy: 0.5599\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5426 - accuracy: 0.5613 - val_loss: 1.5914 - val_accuracy: 0.5602\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5444 - accuracy: 0.5601 - val_loss: 1.5912 - val_accuracy: 0.5524\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5383 - accuracy: 0.5586 - val_loss: 1.5827 - val_accuracy: 0.5621\n",
      "---- building model for layer width of 128\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 3s 20ms/step - loss: 2.5935 - accuracy: 0.4507 - val_loss: 1.8547 - val_accuracy: 0.5396\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7809 - accuracy: 0.5280 - val_loss: 1.6942 - val_accuracy: 0.5474\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7025 - accuracy: 0.5393 - val_loss: 1.6604 - val_accuracy: 0.5527\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6671 - accuracy: 0.5436 - val_loss: 1.6456 - val_accuracy: 0.5462\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6409 - accuracy: 0.5459 - val_loss: 1.6121 - val_accuracy: 0.5499\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6279 - accuracy: 0.5495 - val_loss: 1.6029 - val_accuracy: 0.5574\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6180 - accuracy: 0.5486 - val_loss: 1.6186 - val_accuracy: 0.5571\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6080 - accuracy: 0.5505 - val_loss: 1.6139 - val_accuracy: 0.5571\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5943 - accuracy: 0.5526 - val_loss: 1.6321 - val_accuracy: 0.5596\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5943 - accuracy: 0.5530 - val_loss: 1.6288 - val_accuracy: 0.5362\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5902 - accuracy: 0.5558 - val_loss: 1.6073 - val_accuracy: 0.5533\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5821 - accuracy: 0.5559 - val_loss: 1.6015 - val_accuracy: 0.5590\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5830 - accuracy: 0.5549 - val_loss: 1.5918 - val_accuracy: 0.5543\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5810 - accuracy: 0.5530 - val_loss: 1.6079 - val_accuracy: 0.5515\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5780 - accuracy: 0.5544 - val_loss: 1.5950 - val_accuracy: 0.5530\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5779 - accuracy: 0.5568 - val_loss: 1.6020 - val_accuracy: 0.5596\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5717 - accuracy: 0.5560 - val_loss: 1.6204 - val_accuracy: 0.5680\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5636 - accuracy: 0.5572 - val_loss: 1.5918 - val_accuracy: 0.5624\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5672 - accuracy: 0.5564 - val_loss: 1.5889 - val_accuracy: 0.5593\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5662 - accuracy: 0.5573 - val_loss: 1.6082 - val_accuracy: 0.5658\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5650 - accuracy: 0.5555 - val_loss: 1.5957 - val_accuracy: 0.5639\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5594 - accuracy: 0.5582 - val_loss: 1.6013 - val_accuracy: 0.5530\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5563 - accuracy: 0.5601 - val_loss: 1.6020 - val_accuracy: 0.5577\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5597 - accuracy: 0.5579 - val_loss: 1.6140 - val_accuracy: 0.5611\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5553 - accuracy: 0.5577 - val_loss: 1.6108 - val_accuracy: 0.5639\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5603 - accuracy: 0.5561 - val_loss: 1.6144 - val_accuracy: 0.5518\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5498 - accuracy: 0.5578 - val_loss: 1.6143 - val_accuracy: 0.5618\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5563 - accuracy: 0.5569 - val_loss: 1.5928 - val_accuracy: 0.5608\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5645 - accuracy: 0.5555 - val_loss: 1.6117 - val_accuracy: 0.5596\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5546 - accuracy: 0.5572 - val_loss: 1.6222 - val_accuracy: 0.5699\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5613 - accuracy: 0.5598 - val_loss: 1.5976 - val_accuracy: 0.5574\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5521 - accuracy: 0.5561 - val_loss: 1.6089 - val_accuracy: 0.5639\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5587 - accuracy: 0.5581 - val_loss: 1.5876 - val_accuracy: 0.5590\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.5553 - accuracy: 0.5562 - val_loss: 1.5966 - val_accuracy: 0.5627\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5539 - accuracy: 0.5569 - val_loss: 1.6290 - val_accuracy: 0.5571\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5520 - accuracy: 0.5590 - val_loss: 1.6157 - val_accuracy: 0.5602\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5576 - accuracy: 0.5581 - val_loss: 1.6342 - val_accuracy: 0.5630\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.5512 - accuracy: 0.5573 - val_loss: 1.6014 - val_accuracy: 0.5586\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.5520 - accuracy: 0.5565 - val_loss: 1.6117 - val_accuracy: 0.5577\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5534 - accuracy: 0.5579 - val_loss: 1.6233 - val_accuracy: 0.5621\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5531 - accuracy: 0.5594 - val_loss: 1.6004 - val_accuracy: 0.5574\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5510 - accuracy: 0.5593 - val_loss: 1.6082 - val_accuracy: 0.5530\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5498 - accuracy: 0.5568 - val_loss: 1.6037 - val_accuracy: 0.5574\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5572 - accuracy: 0.5568 - val_loss: 1.6201 - val_accuracy: 0.5614\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5587 - accuracy: 0.5581 - val_loss: 1.6151 - val_accuracy: 0.5611\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5569 - accuracy: 0.5571 - val_loss: 1.6188 - val_accuracy: 0.5496\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5543 - accuracy: 0.5555 - val_loss: 1.6243 - val_accuracy: 0.5664\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5483 - accuracy: 0.5579 - val_loss: 1.6243 - val_accuracy: 0.5558\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5542 - accuracy: 0.5568 - val_loss: 1.6443 - val_accuracy: 0.5565\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5493 - accuracy: 0.5573 - val_loss: 1.6443 - val_accuracy: 0.5639\n",
      "---- building model for layer width of 256\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.1616 - accuracy: 0.4872 - val_loss: 1.7458 - val_accuracy: 0.5427\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7314 - accuracy: 0.5338 - val_loss: 1.6701 - val_accuracy: 0.5471\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6708 - accuracy: 0.5418 - val_loss: 1.6560 - val_accuracy: 0.5521\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6425 - accuracy: 0.5487 - val_loss: 1.7014 - val_accuracy: 0.5599\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6366 - accuracy: 0.5479 - val_loss: 1.6313 - val_accuracy: 0.5480\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6248 - accuracy: 0.5501 - val_loss: 1.6177 - val_accuracy: 0.5565\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6080 - accuracy: 0.5505 - val_loss: 1.6359 - val_accuracy: 0.5583\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6023 - accuracy: 0.5511 - val_loss: 1.6177 - val_accuracy: 0.5602\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6098 - accuracy: 0.5509 - val_loss: 1.6219 - val_accuracy: 0.5649\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5945 - accuracy: 0.5519 - val_loss: 1.6059 - val_accuracy: 0.5583\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5894 - accuracy: 0.5560 - val_loss: 1.6432 - val_accuracy: 0.5643\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5877 - accuracy: 0.5558 - val_loss: 1.6392 - val_accuracy: 0.5530\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5916 - accuracy: 0.5531 - val_loss: 1.6071 - val_accuracy: 0.5571\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5795 - accuracy: 0.5544 - val_loss: 1.6408 - val_accuracy: 0.5602\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5811 - accuracy: 0.5565 - val_loss: 1.6231 - val_accuracy: 0.5527\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5806 - accuracy: 0.5573 - val_loss: 1.6221 - val_accuracy: 0.5565\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5781 - accuracy: 0.5548 - val_loss: 1.6476 - val_accuracy: 0.5549\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5790 - accuracy: 0.5571 - val_loss: 1.6567 - val_accuracy: 0.5540\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5720 - accuracy: 0.5576 - val_loss: 1.6345 - val_accuracy: 0.5502\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5822 - accuracy: 0.5547 - val_loss: 1.6298 - val_accuracy: 0.5568\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5786 - accuracy: 0.5562 - val_loss: 1.6487 - val_accuracy: 0.5611\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5685 - accuracy: 0.5573 - val_loss: 1.6568 - val_accuracy: 0.5480\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5740 - accuracy: 0.5562 - val_loss: 1.6647 - val_accuracy: 0.5490\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5733 - accuracy: 0.5585 - val_loss: 1.6353 - val_accuracy: 0.5502\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5730 - accuracy: 0.5541 - val_loss: 1.6368 - val_accuracy: 0.5443\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5675 - accuracy: 0.5573 - val_loss: 1.6277 - val_accuracy: 0.5633\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5745 - accuracy: 0.5556 - val_loss: 1.6546 - val_accuracy: 0.5577\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5774 - accuracy: 0.5552 - val_loss: 1.6474 - val_accuracy: 0.5590\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5729 - accuracy: 0.5567 - val_loss: 1.6277 - val_accuracy: 0.5555\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5850 - accuracy: 0.5540 - val_loss: 1.6071 - val_accuracy: 0.5580\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5670 - accuracy: 0.5581 - val_loss: 1.6537 - val_accuracy: 0.5611\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5835 - accuracy: 0.5537 - val_loss: 1.6385 - val_accuracy: 0.5558\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5848 - accuracy: 0.5528 - val_loss: 1.6328 - val_accuracy: 0.5549\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5787 - accuracy: 0.5572 - val_loss: 1.6765 - val_accuracy: 0.5571\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5824 - accuracy: 0.5541 - val_loss: 1.6484 - val_accuracy: 0.5655\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5812 - accuracy: 0.5574 - val_loss: 1.6326 - val_accuracy: 0.5552\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5777 - accuracy: 0.5594 - val_loss: 1.6598 - val_accuracy: 0.5543\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5834 - accuracy: 0.5543 - val_loss: 1.6573 - val_accuracy: 0.5636\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5836 - accuracy: 0.5543 - val_loss: 1.6513 - val_accuracy: 0.5555\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5869 - accuracy: 0.5546 - val_loss: 1.6618 - val_accuracy: 0.5574\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5829 - accuracy: 0.5562 - val_loss: 1.6541 - val_accuracy: 0.5540\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5863 - accuracy: 0.5561 - val_loss: 1.6776 - val_accuracy: 0.5543\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5856 - accuracy: 0.5551 - val_loss: 1.6521 - val_accuracy: 0.5412\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5817 - accuracy: 0.5551 - val_loss: 1.6569 - val_accuracy: 0.5530\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5847 - accuracy: 0.5563 - val_loss: 1.6725 - val_accuracy: 0.5577\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.5854 - accuracy: 0.5562 - val_loss: 1.7048 - val_accuracy: 0.5593\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5939 - accuracy: 0.5551 - val_loss: 1.6641 - val_accuracy: 0.5505\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5858 - accuracy: 0.5547 - val_loss: 1.6703 - val_accuracy: 0.5561\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5765 - accuracy: 0.5552 - val_loss: 1.6457 - val_accuracy: 0.5661\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5996 - accuracy: 0.5544 - val_loss: 1.6413 - val_accuracy: 0.5655\n",
      "---- building model for layer width of 512\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.0741 - accuracy: 0.5037 - val_loss: 1.7657 - val_accuracy: 0.5455\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7224 - accuracy: 0.5375 - val_loss: 1.6527 - val_accuracy: 0.5530\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6715 - accuracy: 0.5448 - val_loss: 1.6616 - val_accuracy: 0.5552\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6662 - accuracy: 0.5447 - val_loss: 1.6026 - val_accuracy: 0.5568\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6375 - accuracy: 0.5514 - val_loss: 1.6611 - val_accuracy: 0.5549\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6370 - accuracy: 0.5484 - val_loss: 1.6382 - val_accuracy: 0.5580\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6177 - accuracy: 0.5519 - val_loss: 1.6285 - val_accuracy: 0.5521\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6282 - accuracy: 0.5526 - val_loss: 1.6322 - val_accuracy: 0.5558\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6203 - accuracy: 0.5505 - val_loss: 1.6417 - val_accuracy: 0.5515\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6013 - accuracy: 0.5526 - val_loss: 1.6314 - val_accuracy: 0.5571\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6120 - accuracy: 0.5542 - val_loss: 1.6307 - val_accuracy: 0.5583\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6134 - accuracy: 0.5529 - val_loss: 1.6708 - val_accuracy: 0.5561\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6098 - accuracy: 0.5498 - val_loss: 1.6853 - val_accuracy: 0.5540\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6027 - accuracy: 0.5511 - val_loss: 1.6342 - val_accuracy: 0.5518\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6020 - accuracy: 0.5556 - val_loss: 1.6392 - val_accuracy: 0.5543\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6036 - accuracy: 0.5541 - val_loss: 1.6480 - val_accuracy: 0.5490\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6056 - accuracy: 0.5541 - val_loss: 1.7192 - val_accuracy: 0.5259\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6108 - accuracy: 0.5534 - val_loss: 1.6834 - val_accuracy: 0.5608\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5982 - accuracy: 0.5533 - val_loss: 1.6936 - val_accuracy: 0.5611\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6068 - accuracy: 0.5515 - val_loss: 1.6956 - val_accuracy: 0.5493\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 1.5984 - accuracy: 0.5564 - val_loss: 1.6590 - val_accuracy: 0.5440\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6111 - accuracy: 0.5509 - val_loss: 1.7008 - val_accuracy: 0.5574\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6114 - accuracy: 0.5524 - val_loss: 1.6603 - val_accuracy: 0.5577\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6131 - accuracy: 0.5519 - val_loss: 1.6791 - val_accuracy: 0.5555\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6067 - accuracy: 0.5535 - val_loss: 1.7080 - val_accuracy: 0.5499\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6187 - accuracy: 0.5516 - val_loss: 1.6872 - val_accuracy: 0.5362\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6166 - accuracy: 0.5547 - val_loss: 1.6771 - val_accuracy: 0.5496\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6242 - accuracy: 0.5521 - val_loss: 1.6401 - val_accuracy: 0.5462\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6194 - accuracy: 0.5537 - val_loss: 1.6831 - val_accuracy: 0.5474\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6187 - accuracy: 0.5512 - val_loss: 1.6881 - val_accuracy: 0.5487\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6221 - accuracy: 0.5523 - val_loss: 1.6695 - val_accuracy: 0.5596\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6189 - accuracy: 0.5535 - val_loss: 1.7000 - val_accuracy: 0.5552\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6310 - accuracy: 0.5498 - val_loss: 1.7005 - val_accuracy: 0.5365\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6205 - accuracy: 0.5518 - val_loss: 1.6732 - val_accuracy: 0.5434\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6273 - accuracy: 0.5530 - val_loss: 1.6941 - val_accuracy: 0.5624\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 6ms/step - loss: 1.6299 - accuracy: 0.5511 - val_loss: 1.7173 - val_accuracy: 0.5412\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6270 - accuracy: 0.5547 - val_loss: 1.6961 - val_accuracy: 0.5515\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6299 - accuracy: 0.5484 - val_loss: 1.8023 - val_accuracy: 0.5552\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6403 - accuracy: 0.5503 - val_loss: 1.6906 - val_accuracy: 0.5568\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6368 - accuracy: 0.5480 - val_loss: 1.7202 - val_accuracy: 0.5440\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6625 - accuracy: 0.5503 - val_loss: 1.7080 - val_accuracy: 0.5543\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6445 - accuracy: 0.5540 - val_loss: 1.7371 - val_accuracy: 0.5518\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6473 - accuracy: 0.5487 - val_loss: 1.6895 - val_accuracy: 0.5580\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6374 - accuracy: 0.5512 - val_loss: 1.7202 - val_accuracy: 0.5555\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.6461 - accuracy: 0.5519 - val_loss: 1.7346 - val_accuracy: 0.5499\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6447 - accuracy: 0.5518 - val_loss: 1.7545 - val_accuracy: 0.5434\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.6728 - accuracy: 0.5474 - val_loss: 1.7140 - val_accuracy: 0.5590\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 1.6561 - accuracy: 0.5480 - val_loss: 1.7070 - val_accuracy: 0.5558\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 1.6467 - accuracy: 0.5507 - val_loss: 1.7157 - val_accuracy: 0.5493\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.6417 - accuracy: 0.5511 - val_loss: 1.7043 - val_accuracy: 0.5577\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464670</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.265709</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.457335</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.549212</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.670469</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.538174</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.530338</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1.743232</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.520459</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>1.622619</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>1.643114</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.541417</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>0.563407</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>1.670606</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.534431</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>0.562003</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>1.662184</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.539920</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>0.560131</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128</td>\n",
       "      <td>1.701117</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>0.533932</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>256</td>\n",
       "      <td>0.559351</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>256</td>\n",
       "      <td>1.718507</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>256</td>\n",
       "      <td>0.539671</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>0.556387</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>512</td>\n",
       "      <td>1.794494</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>512</td>\n",
       "      <td>0.540918</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer Width  Metrics Value         Metrics Type\n",
       "0             1       0.464670  Validation Accuracy\n",
       "1             1       2.265709            Test Loss\n",
       "2             1       0.457335        Test Accuracy\n",
       "3             2       0.549212  Validation Accuracy\n",
       "4             2       1.670469            Test Loss\n",
       "5             2       0.538174        Test Accuracy\n",
       "6             4       0.530338  Validation Accuracy\n",
       "7             4       1.743232            Test Loss\n",
       "8             4       0.520459        Test Accuracy\n",
       "9             8       0.554438  Validation Accuracy\n",
       "10            8       1.622619            Test Loss\n",
       "11            8       0.544411        Test Accuracy\n",
       "12           16       0.555686  Validation Accuracy\n",
       "13           16       1.643114            Test Loss\n",
       "14           16       0.541417        Test Accuracy\n",
       "15           32       0.563407  Validation Accuracy\n",
       "16           32       1.670606            Test Loss\n",
       "17           32       0.534431        Test Accuracy\n",
       "18           64       0.562003  Validation Accuracy\n",
       "19           64       1.662184            Test Loss\n",
       "20           64       0.539920        Test Accuracy\n",
       "21          128       0.560131  Validation Accuracy\n",
       "22          128       1.701117            Test Loss\n",
       "23          128       0.533932        Test Accuracy\n",
       "24          256       0.559351  Validation Accuracy\n",
       "25          256       1.718507            Test Loss\n",
       "26          256       0.539671        Test Accuracy\n",
       "27          512       0.556387  Validation Accuracy\n",
       "28          512       1.794494            Test Loss\n",
       "29          512       0.540918        Test Accuracy"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer_width_results = []\n",
    "\n",
    "for i in range(10):\n",
    "    layer_width = 2 ** i\n",
    "    print(\"---- building model for layer width of \" + str(layer_width))\n",
    "    d = DNN()\n",
    "    d.customize_first_layer(layer_width)\n",
    "    \n",
    "    #d.customize_fit(epochs = 2) ## TODO: REMOVE\n",
    "    \n",
    "    val_acc_result = d.build_compile_and_evaluate()\n",
    "    test_loss, test_accuracy = d.evaluate_model_with_test()\n",
    "    \n",
    "    first_layer_width_results.append((layer_width, val_acc_result, \"Validation Accuracy\"))\n",
    "    first_layer_width_results.append((layer_width, test_loss, \"Test Loss\"))\n",
    "    first_layer_width_results.append((layer_width, test_accuracy, \"Test Accuracy\"))\n",
    "    \n",
    "first_layer_width_results = pd.DataFrame(first_layer_width_results)\n",
    "first_layer_width_results = first_layer_width_results.rename(columns = {\n",
    "    0: \"Layer Width\",\n",
    "    1: \"Metrics Value\",\n",
    "    2: \"Metrics Type\"\n",
    "})\n",
    "first_layer_width_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464670</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.457335</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.549212</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.538174</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.530338</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.520459</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>0.554438</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>0.544411</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.555686</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.541417</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>0.563407</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.534431</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>0.562003</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.539920</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>0.560131</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>0.533932</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>256</td>\n",
       "      <td>0.559351</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>256</td>\n",
       "      <td>0.539671</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>0.556387</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>512</td>\n",
       "      <td>0.540918</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer Width  Metrics Value         Metrics Type\n",
       "0             1       0.464670  Validation Accuracy\n",
       "2             1       0.457335        Test Accuracy\n",
       "3             2       0.549212  Validation Accuracy\n",
       "5             2       0.538174        Test Accuracy\n",
       "6             4       0.530338  Validation Accuracy\n",
       "8             4       0.520459        Test Accuracy\n",
       "9             8       0.554438  Validation Accuracy\n",
       "11            8       0.544411        Test Accuracy\n",
       "12           16       0.555686  Validation Accuracy\n",
       "14           16       0.541417        Test Accuracy\n",
       "15           32       0.563407  Validation Accuracy\n",
       "17           32       0.534431        Test Accuracy\n",
       "18           64       0.562003  Validation Accuracy\n",
       "20           64       0.539920        Test Accuracy\n",
       "21          128       0.560131  Validation Accuracy\n",
       "23          128       0.533932        Test Accuracy\n",
       "24          256       0.559351  Validation Accuracy\n",
       "26          256       0.539671        Test Accuracy\n",
       "27          512       0.556387  Validation Accuracy\n",
       "29          512       0.540918        Test Accuracy"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_only = first_layer_width_results[first_layer_width_results[\"Metrics Type\"] != \"Test Loss\"]\n",
    "accuracy_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Layer Width', ylabel='Metrics Value'>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(accuracy_only, \n",
    "             x = \"Layer Width\",\n",
    "             y = \"Metrics Value\",\n",
    "             hue = \"Metrics Type\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
