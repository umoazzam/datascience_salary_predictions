{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kaggle_survey_2020_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = df.drop(columns = [\"time_from_start_to_finish_seconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.dropna(subset = [\"q24\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10729"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(col_name: str, order_rules: list, data):\n",
    "    data[col_name] = pd.Categorical(data[col_name], order_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category_no_specified_order(col_name, data):\n",
    "    if sum(data[col_name].isna().astype(int)) > 0:\n",
    "        data[col_name].fillna(\"No response\", inplace = True)\n",
    "    \n",
    "    order = list(set(data[col_name]))\n",
    "    convert_to_category(col_name, order, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category_to_code(col_name: str, data, inplace = False):\n",
    "    if inplace:\n",
    "        data[col_name] = data[col_name].cat.codes + 1 # because NaN automatically becomes -1\n",
    "    else:\n",
    "        return data[col_name].cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(col_name: str, order_rules = None, data = salary_data, num_data = salary_data_as_num):\n",
    "    if order_rules:\n",
    "        convert_to_category(col_name, order_rules, data)\n",
    "    else:\n",
    "        convert_to_category_no_specified_order(col_name, data)\n",
    "    num_data[col_name] = convert_category_to_code(col_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_column_to_binary(col_name, data = salary_data):\n",
    "    data[col_name].fillna(0, inplace = True)\n",
    "    data[col_name].mask(data[col_name] != 0, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_hot_encoded_columns(columns, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col in columns:\n",
    "        one_hot_column_to_binary(col, data)\n",
    "        num_data[col] = data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_text_to_binary(col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    data[col_name] = data[col_name].notna().astype(int)\n",
    "    num_data[col_name] = data[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multiple_columns_into_one_binary(columns, new_col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col_name in columns:\n",
    "        one_hot_column_to_binary(col_name)\n",
    "        \n",
    "    data[new_col_name] = data[columns].sum(axis = 1)\n",
    "    data[new_col_name] = data[new_col_name].astype(int)\n",
    "    \n",
    "    data[new_col_name].mask(data[new_col_name] > 0, 1, inplace = True)\n",
    "    num_data[new_col_name] = data[new_col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q24 Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1: original bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "q24_order = [\"$0-999\",\n",
    "             '1,000-1,999',\n",
    "             '2,000-2,999',\n",
    "             '3,000-3,999',\n",
    "             '4,000-4,999',\n",
    "             '5,000-7,499',\n",
    "             '7,500-9,999',\n",
    "             '10,000-14,999',\n",
    "             '15,000-19,999',\n",
    "             '20,000-24,999',\n",
    "             '25,000-29,999',\n",
    "             '30,000-39,999',\n",
    "             '40,000-49,999',\n",
    "             '50,000-59,999',\n",
    "              '60,000-69,999',\n",
    "              '70,000-79,999',\n",
    "              '80,000-89,999',\n",
    "              '90,000-99,999',\n",
    "            '100,000-124,999',\n",
    "            '125,000-149,999',\n",
    "            '150,000-199,999',\n",
    "             '200,000-249,999',\n",
    "             '250,000-299,999',\n",
    "              '300,000-500,000',\n",
    "              '> $500,000'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q24\", q24_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "25-29    2350\n",
       "30-34    1979\n",
       "35-39    1467\n",
       "22-24    1424\n",
       "40-44    1042\n",
       "45-49     771\n",
       "50-54     536\n",
       "18-21     498\n",
       "60-69     309\n",
       "55-59     301\n",
       "70         52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_order = [\n",
    "    \"18-21\",\n",
    "    \"22-24\",\n",
    "    \"25-29\",\n",
    "    \"30-34\",\n",
    "    \"35-39\",\n",
    "    \"40-44\",\n",
    "    \"45-49\",\n",
    "    \"50-54\",\n",
    "    \"55-59\",\n",
    "    \"60-69\",\n",
    "    \"70\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q1\", q1_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10729 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1\n",
       "1       19   4\n",
       "2        9   5\n",
       "3       20   4\n",
       "8       16   5\n",
       "11      12   5\n",
       "...    ...  ..\n",
       "20024    3   5\n",
       "20029    9   5\n",
       "20033    1   4\n",
       "20034    1   2\n",
       "20035    1   2\n",
       "\n",
       "[10729 rows x 2 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"] = convert_category_to_code(\"q1\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "3     2350\n",
       "4     1979\n",
       "5     1467\n",
       "2     1424\n",
       "6     1042\n",
       "7      771\n",
       "8      536\n",
       "1      498\n",
       "10     309\n",
       "9      301\n",
       "11      52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "Man                        8872\n",
       "Woman                      1683\n",
       "Prefer not to say           131\n",
       "Prefer to self-describe      23\n",
       "Nonbinary                    20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_order = ['Man', \"Woman\", \"Nonbinary\", 'Prefer to self-describe', 'Prefer not to say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q2\", q2_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1  q2\n",
       "1       19   4   1\n",
       "2        9   5   1\n",
       "3       20   4   1\n",
       "8       16   5   1\n",
       "11      12   5   1\n",
       "...    ...  ..  ..\n",
       "20024    3   5   1\n",
       "20029    9   5   1\n",
       "20033    1   4   1\n",
       "20034    1   2   1\n",
       "20035    1   2   1\n",
       "\n",
       "[10729 rows x 3 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"] = convert_category_to_code(\"q2\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "1    8872\n",
       "2    1683\n",
       "5     131\n",
       "4      23\n",
       "3      20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q3\"] = convert_category_to_code(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "Master’s degree                                                      4879\n",
       "Bachelor’s degree                                                    3013\n",
       "Doctoral degree                                                      1718\n",
       "Professional degree                                                   470\n",
       "Some college/university study without earning a bachelor’s degree     385\n",
       "I prefer not to answer                                                158\n",
       "No formal education past high school                                  106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_order = [\"No formal education past high school\",\n",
    "            \"Some college/university study without earning a bachelor’s degree\",\n",
    "            \"Professional degree\",\n",
    "            \"Bachelor’s degree\",\n",
    "            \"Master’s degree\",\n",
    "            \"Doctoral degree\",\n",
    "            \"I prefer not to answer\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q4\", q4_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q4\"] = convert_category_to_code(\"q4\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "5    4879\n",
       "4    3013\n",
       "6    1718\n",
       "3     470\n",
       "2     385\n",
       "7     158\n",
       "1     106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q5\n",
       "Data Scientist               2398\n",
       "Software Engineer            1620\n",
       "Other                        1508\n",
       "Data Analyst                 1260\n",
       "Research Scientist           1028\n",
       "Machine Learning Engineer     918\n",
       "Business Analyst              678\n",
       "Product/Project Manager       590\n",
       "Data Engineer                 369\n",
       "Statistician                  248\n",
       "DBA/Database Engineer         112\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q5\"] = convert_category_to_code(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Years Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_order = [\n",
    " 'I have never written code',\n",
    " '< 1 years',\n",
    " '1-2 years',\n",
    " '3-5 years',\n",
    " '5-10 years',\n",
    " '10-20 years',\n",
    " '20+ years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q6\", q6_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_columns = [\n",
    "     'q7_part_1',\n",
    " 'q7_part_2',\n",
    " 'q7_part_3',\n",
    " 'q7_part_4',\n",
    " 'q7_part_5',\n",
    " 'q7_part_6',\n",
    " 'q7_part_7',\n",
    " 'q7_part_8',\n",
    " 'q7_part_9',\n",
    " 'q7_part_10',\n",
    " 'q7_part_11',\n",
    " 'q7_part_12',\n",
    " 'q7_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q7_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11 Computing Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12 Specialized Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "q12_columns = [\n",
    "    'q12_part_1',\n",
    " 'q12_part_2',\n",
    " 'q12_part_3',\n",
    " 'q12_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q12_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14_columns = [\n",
    "    'q14_part_1',\n",
    " 'q14_part_2',\n",
    " 'q14_part_3',\n",
    " 'q14_part_4',\n",
    " 'q14_part_5',\n",
    " 'q14_part_6',\n",
    " 'q14_part_7',\n",
    " 'q14_part_8',\n",
    " 'q14_part_9',\n",
    " 'q14_part_10',\n",
    " 'q14_part_11',\n",
    " 'q14_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q14_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15 Years ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15_order = [\n",
    "    'I do not use machine learning methods',\n",
    "    'Under 1 year',\n",
    "    '1-2 years',\n",
    "    '2-3 years',\n",
    "    '3-4 years',\n",
    "    '4-5 years',\n",
    "    '5-10 years',\n",
    "    '10-20 years',\n",
    "    '20 or more years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q15\", q15_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17 ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17_columns = [\n",
    "    'q17_part_1',\n",
    " 'q17_part_2',\n",
    " 'q17_part_3',\n",
    " 'q17_part_4',\n",
    " 'q17_part_5',\n",
    " 'q17_part_6',\n",
    " 'q17_part_7',\n",
    " 'q17_part_8',\n",
    " 'q17_part_9',\n",
    " 'q17_part_10',\n",
    " 'q17_part_11',\n",
    " 'q17_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q17_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q20 Company Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20_order = [\n",
    "    '0-49 employees',\n",
    "    '50-249 employees',\n",
    "    '250-999 employees',\n",
    "    '1000-9,999 employees',\n",
    "    '10,000 or more employees'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q20\", q20_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q21 Datascience Workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "q21_order = [\n",
    "    '0',\n",
    "    '1-2',\n",
    "    '3-4',\n",
    "    '5-9',\n",
    "    '10-14',\n",
    "    '15-19',\n",
    "    '20'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q21\", q21_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q22 Incorporating ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'm not super sure about the proper \"order\" for this question. Feel free to change this if you find it more appropriate. Just please let the chat know in case it affects others' encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "q22_order = [\n",
    "    'I do not know',\n",
    "    'No (we do not use ML methods)',\n",
    "    'We are exploring ML methods (and may one day put a model into production)',\n",
    "    'We use ML methods for generating insights (but do not put working models into production)',\n",
    "    'We recently started using ML methods (i.e., models in production for less than 2 years)',\n",
    "    'We have well established ML methods (i.e., models in production for more than 2 years)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q22\", q22_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q30 Big Data Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q32 Business Intelligence Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q33 Automated ML Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "q33_columns = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_multiple_columns_into_one_binary(q33_columns, \"q33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q37 Data Science Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "q37_columns = [\n",
    "    'q37_part_1',\n",
    " 'q37_part_2',\n",
    " 'q37_part_3',\n",
    " 'q37_part_4',\n",
    " 'q37_part_5',\n",
    " 'q37_part_6',\n",
    " 'q37_part_7',\n",
    " 'q37_part_8',\n",
    " 'q37_part_9',\n",
    " 'q37_part_10',\n",
    " 'q37_part_11',\n",
    " 'q37_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q37_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q38 Primary Data Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q39 Media Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "q39_columns = [\n",
    "    'q39_part_1',\n",
    " 'q39_part_2',\n",
    " 'q39_part_3',\n",
    " 'q39_part_4',\n",
    " 'q39_part_5',\n",
    " 'q39_part_6',\n",
    " 'q39_part_7',\n",
    " 'q39_part_8',\n",
    " 'q39_part_9',\n",
    " 'q39_part_10',\n",
    " 'q39_part_11',\n",
    " 'q39_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q39_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropped Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dropped = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_questions = [\n",
    "    \"q8\",\n",
    "    'q9_part_1',\n",
    " 'q9_part_2',\n",
    " 'q9_part_3',\n",
    " 'q9_part_4',\n",
    " 'q9_part_5',\n",
    " 'q9_part_6',\n",
    " 'q9_part_7',\n",
    " 'q9_part_8',\n",
    " 'q9_part_9',\n",
    " 'q9_part_10',\n",
    " 'q9_part_11',\n",
    " 'q9_other',\n",
    " 'q10_part_1',\n",
    " 'q10_part_2',\n",
    " 'q10_part_3',\n",
    " 'q10_part_4',\n",
    " 'q10_part_5',\n",
    " 'q10_part_6',\n",
    " 'q10_part_7',\n",
    " 'q10_part_8',\n",
    " 'q10_part_9',\n",
    " 'q10_part_10',\n",
    " 'q10_part_11',\n",
    " 'q10_part_12',\n",
    " 'q10_part_13',\n",
    " 'q10_other',\n",
    " \"q13\",\n",
    " 'q16_part_1',\n",
    " 'q16_part_2',\n",
    " 'q16_part_3',\n",
    " 'q16_part_4',\n",
    " 'q16_part_5',\n",
    " 'q16_part_6',\n",
    " 'q16_part_7',\n",
    " 'q16_part_8',\n",
    " 'q16_part_9',\n",
    " 'q16_part_10',\n",
    " 'q16_part_11',\n",
    " 'q16_part_12',\n",
    " 'q16_part_13',\n",
    " 'q16_part_14',\n",
    " 'q16_part_15',\n",
    " 'q16_other',\n",
    " 'q18_part_1',\n",
    " 'q18_part_2',\n",
    " 'q18_part_3',\n",
    " 'q18_part_4',\n",
    " 'q18_part_5',\n",
    " 'q18_part_6',\n",
    " 'q18_other',\n",
    " 'q19_part_1',\n",
    " 'q19_part_2',\n",
    " 'q19_part_3',\n",
    " 'q19_part_4',\n",
    " 'q19_part_5',\n",
    " 'q19_other',\n",
    " 'q23_part_1',\n",
    " 'q23_part_2',\n",
    " 'q23_part_3',\n",
    " 'q23_part_4',\n",
    " 'q23_part_5',\n",
    " 'q23_part_6',\n",
    " 'q23_part_7',\n",
    " 'q23_other',\n",
    " 'q25',\n",
    " 'q26_a_part_1',\n",
    " 'q26_a_part_2',\n",
    " 'q26_a_part_3',\n",
    " 'q26_a_part_4',\n",
    " 'q26_a_part_5',\n",
    " 'q26_a_part_6',\n",
    " 'q26_a_part_7',\n",
    " 'q26_a_part_8',\n",
    " 'q26_a_part_9',\n",
    " 'q26_a_part_10',\n",
    " 'q26_a_part_11',\n",
    " 'q26_a_other',\n",
    " 'q27_a_part_1',\n",
    " 'q27_a_part_2',\n",
    " 'q27_a_part_3',\n",
    " 'q27_a_part_4',\n",
    " 'q27_a_part_5',\n",
    " 'q27_a_part_6',\n",
    " 'q27_a_part_7',\n",
    " 'q27_a_part_8',\n",
    " 'q27_a_part_9',\n",
    " 'q27_a_part_10',\n",
    " 'q27_a_part_11',\n",
    " 'q27_a_other',\n",
    " 'q28_a_part_1',\n",
    " 'q28_a_part_2',\n",
    " 'q28_a_part_3',\n",
    " 'q28_a_part_4',\n",
    " 'q28_a_part_5',\n",
    " 'q28_a_part_6',\n",
    " 'q28_a_part_7',\n",
    " 'q28_a_part_8',\n",
    " 'q28_a_part_9',\n",
    " 'q28_a_part_10',\n",
    " 'q28_a_other',\n",
    " 'q29_a_part_1',\n",
    " 'q29_a_part_2',\n",
    " 'q29_a_part_3',\n",
    " 'q29_a_part_4',\n",
    " 'q29_a_part_5',\n",
    " 'q29_a_part_6',\n",
    " 'q29_a_part_7',\n",
    " 'q29_a_part_8',\n",
    " 'q29_a_part_9',\n",
    " 'q29_a_part_10',\n",
    " 'q29_a_part_11',\n",
    " 'q29_a_part_12',\n",
    " 'q29_a_part_13',\n",
    " 'q29_a_part_14',\n",
    " 'q29_a_part_15',\n",
    " 'q29_a_part_16',\n",
    " 'q29_a_part_17',\n",
    " 'q29_a_other',\n",
    " 'q31_a_part_1',\n",
    " 'q31_a_part_2',\n",
    " 'q31_a_part_3',\n",
    " 'q31_a_part_4',\n",
    " 'q31_a_part_5',\n",
    " 'q31_a_part_6',\n",
    " 'q31_a_part_7',\n",
    " 'q31_a_part_8',\n",
    " 'q31_a_part_9',\n",
    " 'q31_a_part_10',\n",
    " 'q31_a_part_11',\n",
    " 'q31_a_part_12',\n",
    " 'q31_a_part_13',\n",
    " 'q31_a_part_14',\n",
    " 'q31_a_other',\n",
    " 'q34_a_part_1',\n",
    " 'q34_a_part_2',\n",
    " 'q34_a_part_3',\n",
    " 'q34_a_part_4',\n",
    " 'q34_a_part_5',\n",
    " 'q34_a_part_6',\n",
    " 'q34_a_part_7',\n",
    " 'q34_a_part_8',\n",
    " 'q34_a_part_9',\n",
    " 'q34_a_part_10',\n",
    " 'q34_a_part_11',\n",
    " 'q34_a_other',\n",
    " 'q35_a_part_1',\n",
    " 'q35_a_part_2',\n",
    " 'q35_a_part_3',\n",
    " 'q35_a_part_4',\n",
    " 'q35_a_part_5',\n",
    " 'q35_a_part_6',\n",
    " 'q35_a_part_7',\n",
    " 'q35_a_part_8',\n",
    " 'q35_a_part_9',\n",
    " 'q35_a_part_10',\n",
    " 'q35_a_other',\n",
    " 'q36_part_1',\n",
    " 'q36_part_2',\n",
    " 'q36_part_3',\n",
    " 'q36_part_4',\n",
    " 'q36_part_5',\n",
    " 'q36_part_6',\n",
    " 'q36_part_7',\n",
    " 'q36_part_8',\n",
    " 'q36_part_9',\n",
    " 'q36_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_b_dropped = [\n",
    "    'q26_b_part_1',\n",
    " 'q26_b_part_2',\n",
    " 'q26_b_part_3',\n",
    " 'q26_b_part_4',\n",
    " 'q26_b_part_5',\n",
    " 'q26_b_part_6',\n",
    " 'q26_b_part_7',\n",
    " 'q26_b_part_8',\n",
    " 'q26_b_part_9',\n",
    " 'q26_b_part_10',\n",
    " 'q26_b_part_11',\n",
    " 'q26_b_other',\n",
    " 'q27_b_part_1',\n",
    " 'q27_b_part_2',\n",
    " 'q27_b_part_3',\n",
    " 'q27_b_part_4',\n",
    " 'q27_b_part_5',\n",
    " 'q27_b_part_6',\n",
    " 'q27_b_part_7',\n",
    " 'q27_b_part_8',\n",
    " 'q27_b_part_9',\n",
    " 'q27_b_part_10',\n",
    " 'q27_b_part_11',\n",
    " 'q27_b_other',\n",
    " 'q28_b_part_1',\n",
    " 'q28_b_part_2',\n",
    " 'q28_b_part_3',\n",
    " 'q28_b_part_4',\n",
    " 'q28_b_part_5',\n",
    " 'q28_b_part_6',\n",
    " 'q28_b_part_7',\n",
    " 'q28_b_part_8',\n",
    " 'q28_b_part_9',\n",
    " 'q28_b_part_10',\n",
    " 'q28_b_other',\n",
    " 'q29_b_part_1',\n",
    " 'q29_b_part_2',\n",
    " 'q29_b_part_3',\n",
    " 'q29_b_part_4',\n",
    " 'q29_b_part_5',\n",
    " 'q29_b_part_6',\n",
    " 'q29_b_part_7',\n",
    " 'q29_b_part_8',\n",
    " 'q29_b_part_9',\n",
    " 'q29_b_part_10',\n",
    " 'q29_b_part_11',\n",
    " 'q29_b_part_12',\n",
    " 'q29_b_part_13',\n",
    " 'q29_b_part_14',\n",
    " 'q29_b_part_15',\n",
    " 'q29_b_part_16',\n",
    " 'q29_b_part_17',\n",
    " 'q29_b_other',\n",
    " 'q31_b_part_1',\n",
    " 'q31_b_part_2',\n",
    " 'q31_b_part_3',\n",
    " 'q31_b_part_4',\n",
    " 'q31_b_part_5',\n",
    " 'q31_b_part_6',\n",
    " 'q31_b_part_7',\n",
    " 'q31_b_part_8',\n",
    " 'q31_b_part_9',\n",
    " 'q31_b_part_10',\n",
    " 'q31_b_part_11',\n",
    " 'q31_b_part_12',\n",
    " 'q31_b_part_13',\n",
    " 'q31_b_part_14',\n",
    " 'q31_b_other',\n",
    " 'q33_b_part_1',\n",
    " 'q33_b_part_2',\n",
    " 'q33_b_part_3',\n",
    " 'q33_b_part_4',\n",
    " 'q33_b_part_5',\n",
    " 'q33_b_part_6',\n",
    " 'q33_b_part_7',\n",
    " 'q33_b_other',\n",
    " 'q34_b_part_1',\n",
    " 'q34_b_part_2',\n",
    " 'q34_b_part_3',\n",
    " 'q34_b_part_4',\n",
    " 'q34_b_part_5',\n",
    " 'q34_b_part_6',\n",
    " 'q34_b_part_7',\n",
    " 'q34_b_part_8',\n",
    " 'q34_b_part_9',\n",
    " 'q34_b_part_10',\n",
    " 'q34_b_part_11',\n",
    " 'q34_b_other',\n",
    " 'q35_b_part_1',\n",
    " 'q35_b_part_2',\n",
    " 'q35_b_part_3',\n",
    " 'q35_b_part_4',\n",
    " 'q35_b_part_5',\n",
    " 'q35_b_part_6',\n",
    " 'q35_b_part_7',\n",
    " 'q35_b_part_8',\n",
    " 'q35_b_part_9',\n",
    " 'q35_b_part_10',\n",
    " 'q35_b_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = one_hot_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = part_b_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_selected_questions = salary_data.drop(columns = dropped_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salary_data_as_num.drop(columns = [\"q24\"])\n",
    "y = salary_data_as_num[\"q24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_test, y_dev, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = tf.convert_to_tensor(x_dev.astype(\"int64\"))\n",
    "x_test = tf.convert_to_tensor(x_test.astype(\"int64\"))\n",
    "y_dev = tf.convert_to_tensor(y_dev.astype(\"int64\"))\n",
    "y_test = tf.convert_to_tensor(y_test.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    \n",
    "    def __init__(self, x_dev = x_dev, y_dev = y_dev, x_test = x_test, y_test = y_test):\n",
    "        self.x_dev = x_dev\n",
    "        self.y_dev = y_dev\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.layers = [Dense(32, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "        self.optimizer = \"adam\"\n",
    "        self.loss = \"sparse_categorical_crossentropy\"\n",
    "        self.metrics =  [\"accuracy\"]\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.epochs = 50\n",
    "        \n",
    "    def customize_first_layer(self, node_count = 32):\n",
    "        self.layers = [Dense(node_count, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "    def add_one_dense_layer(self, node_count = 32):\n",
    "        self.layers.append(Dense(node_count, activation = \"relu\"))\n",
    "        \n",
    "    def customize_middle_layers(self, layers):\n",
    "        self.layers.extend(layers)\n",
    "    \n",
    "    def customize_compile(self,\n",
    "                          optimizer = \"adam\",\n",
    "                          loss = \"sparse_categorical_crossentropy\",\n",
    "                          metrics = [\"accuracy\"]):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def customize_fit(self,\n",
    "                      batch_size = 100,\n",
    "                      epochs = 50\n",
    "                      ):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def build_compile_and_evaluate(self, metric_to_return = \"accuracy\", selection_criteria = max):\n",
    "        # final layer must be softmax and outputs 26\n",
    "        self.layers.append(Dense(26, activation = \"softmax\"))\n",
    "        \n",
    "        self.model = Sequential(self.layers)\n",
    "        self.model.compile(optimizer = self.optimizer,\n",
    "                      loss = self.loss,\n",
    "                      metrics = self.metrics)\n",
    "        fit_history = self.model.fit(self.x_dev, self.y_dev,\n",
    "                                batch_size = self.batch_size,\n",
    "                                epochs = self.epochs,\n",
    "                                validation_split = 0.2,\n",
    "                                #verbose = 1\n",
    "                                )\n",
    "        self.fit_history = pd.DataFrame(fit_history.history)\n",
    "        return selection_criteria(self.fit_history[metric_to_return])\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    def get_fit_history(self):\n",
    "        return self.fit_history\n",
    "        \n",
    "    def evaluate_model_with_test(self):\n",
    "        return self.model.evaluate(self.x_test, self.y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- building model for layer width of 256 and 256\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 2s 20ms/step - loss: 3.3538 - accuracy: 0.1685 - val_loss: 2.9639 - val_accuracy: 0.1969\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9474 - accuracy: 0.1940 - val_loss: 2.8745 - val_accuracy: 0.1951\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.8698 - accuracy: 0.2073 - val_loss: 2.9300 - val_accuracy: 0.1899\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8773 - accuracy: 0.2065 - val_loss: 3.0066 - val_accuracy: 0.1846\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9801 - accuracy: 0.1990 - val_loss: 3.0228 - val_accuracy: 0.1875\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 3.0067 - accuracy: 0.1973 - val_loss: 3.1533 - val_accuracy: 0.1642\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0624 - accuracy: 0.1933 - val_loss: 3.1330 - val_accuracy: 0.1578\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.2003 - accuracy: 0.1856 - val_loss: 3.3031 - val_accuracy: 0.1095\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4755 - accuracy: 0.1694 - val_loss: 3.6637 - val_accuracy: 0.1340\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.8114 - accuracy: 0.1668 - val_loss: 3.7032 - val_accuracy: 0.1899\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.6191 - accuracy: 0.1503 - val_loss: 5.2623 - val_accuracy: 0.0897\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.4657 - accuracy: 0.1305 - val_loss: 6.3626 - val_accuracy: 0.1386\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 7.2580 - accuracy: 0.1400 - val_loss: 8.0010 - val_accuracy: 0.0606\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 8.4372 - accuracy: 0.1327 - val_loss: 14.2681 - val_accuracy: 0.0612\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 12.5842 - accuracy: 0.1143 - val_loss: 16.7244 - val_accuracy: 0.0810\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 20.8087 - accuracy: 0.0919 - val_loss: 28.7156 - val_accuracy: 0.0763\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 23.3031 - accuracy: 0.0964 - val_loss: 23.4899 - val_accuracy: 0.1147\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 23.8581 - accuracy: 0.1018 - val_loss: 19.4476 - val_accuracy: 0.0827\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 23.4344 - accuracy: 0.0980 - val_loss: 34.5386 - val_accuracy: 0.0565\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 29.9796 - accuracy: 0.0976 - val_loss: 26.8003 - val_accuracy: 0.1101\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 25.6033 - accuracy: 0.1005 - val_loss: 17.9800 - val_accuracy: 0.1299\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 27.7497 - accuracy: 0.1084 - val_loss: 31.8564 - val_accuracy: 0.0716\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 32.8834 - accuracy: 0.0904 - val_loss: 30.7962 - val_accuracy: 0.0839\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 35.7521 - accuracy: 0.0865 - val_loss: 33.8686 - val_accuracy: 0.0839\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 36.4886 - accuracy: 0.1012 - val_loss: 37.5251 - val_accuracy: 0.0798\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 41.3551 - accuracy: 0.0961 - val_loss: 46.3158 - val_accuracy: 0.0623\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 45.1639 - accuracy: 0.0907 - val_loss: 56.0858 - val_accuracy: 0.0652\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 46.0719 - accuracy: 0.0974 - val_loss: 36.0934 - val_accuracy: 0.0530\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 56.5961 - accuracy: 0.0912 - val_loss: 46.8525 - val_accuracy: 0.0885\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 2s 23ms/step - loss: 52.8114 - accuracy: 0.0922 - val_loss: 47.9913 - val_accuracy: 0.0920\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 57.4651 - accuracy: 0.0990 - val_loss: 69.2562 - val_accuracy: 0.0524\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 59.3767 - accuracy: 0.0931 - val_loss: 67.2405 - val_accuracy: 0.0588\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 63.2280 - accuracy: 0.0883 - val_loss: 72.2843 - val_accuracy: 0.0711\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 64.5495 - accuracy: 0.0896 - val_loss: 65.4728 - val_accuracy: 0.0780\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 70.4539 - accuracy: 0.0909 - val_loss: 64.5394 - val_accuracy: 0.0827\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 70.2340 - accuracy: 0.0912 - val_loss: 63.6746 - val_accuracy: 0.0944\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 79.3075 - accuracy: 0.0957 - val_loss: 90.0931 - val_accuracy: 0.0926\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 83.0334 - accuracy: 0.0851 - val_loss: 71.1571 - val_accuracy: 0.1235\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 80.0520 - accuracy: 0.0899 - val_loss: 77.2629 - val_accuracy: 0.1165\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 82.8519 - accuracy: 0.0830 - val_loss: 94.0672 - val_accuracy: 0.0734\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 93.1479 - accuracy: 0.0836 - val_loss: 102.8557 - val_accuracy: 0.1357\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 93.7019 - accuracy: 0.0938 - val_loss: 108.4737 - val_accuracy: 0.0827\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 93.4072 - accuracy: 0.0903 - val_loss: 104.9601 - val_accuracy: 0.0443\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 99.4035 - accuracy: 0.0867 - val_loss: 93.3693 - val_accuracy: 0.0571\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 97.9437 - accuracy: 0.0852 - val_loss: 105.8867 - val_accuracy: 0.1444\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 95.3523 - accuracy: 0.0971 - val_loss: 112.0962 - val_accuracy: 0.1101\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 107.3774 - accuracy: 0.0840 - val_loss: 126.0829 - val_accuracy: 0.0681\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 125.3048 - accuracy: 0.0941 - val_loss: 107.8469 - val_accuracy: 0.0978\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 115.4248 - accuracy: 0.0915 - val_loss: 87.6338 - val_accuracy: 0.0786\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 120.5381 - accuracy: 0.0827 - val_loss: 124.9517 - val_accuracy: 0.0938\n",
      "---- building model for layer width of 16 and 2048\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.9918 - accuracy: 0.1834 - val_loss: 2.8531 - val_accuracy: 0.2062\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8991 - accuracy: 0.1962 - val_loss: 2.8921 - val_accuracy: 0.2021\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8934 - accuracy: 0.1997 - val_loss: 2.9326 - val_accuracy: 0.1957\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9061 - accuracy: 0.1991 - val_loss: 2.9298 - val_accuracy: 0.2085\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9442 - accuracy: 0.1957 - val_loss: 3.0087 - val_accuracy: 0.2021\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.0306 - accuracy: 0.1933 - val_loss: 3.0129 - val_accuracy: 0.1969\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1735 - accuracy: 0.1828 - val_loss: 3.4847 - val_accuracy: 0.1765\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.4460 - accuracy: 0.1695 - val_loss: 3.7034 - val_accuracy: 0.1602\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.3999 - accuracy: 0.1793 - val_loss: 3.6259 - val_accuracy: 0.1520\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.3794 - accuracy: 0.1523 - val_loss: 4.6101 - val_accuracy: 0.1439\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 4.6116 - accuracy: 0.1526 - val_loss: 4.6655 - val_accuracy: 0.1514\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 4.4997 - accuracy: 0.1499 - val_loss: 5.0501 - val_accuracy: 0.1357\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 6.7656 - accuracy: 0.1314 - val_loss: 9.0406 - val_accuracy: 0.1450\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 8.3967 - accuracy: 0.1248 - val_loss: 8.8320 - val_accuracy: 0.1462\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 8.9181 - accuracy: 0.1187 - val_loss: 14.1433 - val_accuracy: 0.1025\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 10.4439 - accuracy: 0.1260 - val_loss: 12.4012 - val_accuracy: 0.0862\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 11.8470 - accuracy: 0.1139 - val_loss: 13.0335 - val_accuracy: 0.1019\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 14.8026 - accuracy: 0.1158 - val_loss: 18.4452 - val_accuracy: 0.0786\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 3s 45ms/step - loss: 20.0160 - accuracy: 0.0996 - val_loss: 23.7034 - val_accuracy: 0.0874\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 22.5634 - accuracy: 0.0998 - val_loss: 17.8150 - val_accuracy: 0.1555\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 2s 33ms/step - loss: 19.5198 - accuracy: 0.1110 - val_loss: 26.2630 - val_accuracy: 0.0961\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 28.1689 - accuracy: 0.1003 - val_loss: 29.4065 - val_accuracy: 0.1025\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 27.5967 - accuracy: 0.1014 - val_loss: 36.6118 - val_accuracy: 0.0775\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 3s 46ms/step - loss: 30.9685 - accuracy: 0.1059 - val_loss: 28.5766 - val_accuracy: 0.0792\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 3s 42ms/step - loss: 33.1213 - accuracy: 0.1006 - val_loss: 35.9215 - val_accuracy: 0.0984\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 3s 36ms/step - loss: 42.1783 - accuracy: 0.0989 - val_loss: 42.1265 - val_accuracy: 0.0862\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 48.7907 - accuracy: 0.0961 - val_loss: 46.3473 - val_accuracy: 0.1165\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 3s 38ms/step - loss: 44.9520 - accuracy: 0.1070 - val_loss: 41.4142 - val_accuracy: 0.0984\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 2s 35ms/step - loss: 43.5474 - accuracy: 0.1060 - val_loss: 42.6768 - val_accuracy: 0.0990\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 3s 39ms/step - loss: 47.9019 - accuracy: 0.0948 - val_loss: 41.5872 - val_accuracy: 0.1136\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 3s 47ms/step - loss: 52.1499 - accuracy: 0.0983 - val_loss: 66.7286 - val_accuracy: 0.1037\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 4s 52ms/step - loss: 56.4863 - accuracy: 0.0963 - val_loss: 38.4161 - val_accuracy: 0.1287\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 57.7668 - accuracy: 0.1017 - val_loss: 50.7884 - val_accuracy: 0.1275\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 59.7509 - accuracy: 0.0960 - val_loss: 62.7847 - val_accuracy: 0.1072\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 5s 74ms/step - loss: 73.0774 - accuracy: 0.0964 - val_loss: 66.4111 - val_accuracy: 0.1235\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 68.0071 - accuracy: 0.1018 - val_loss: 63.9325 - val_accuracy: 0.1188\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 69.4686 - accuracy: 0.0996 - val_loss: 87.8281 - val_accuracy: 0.0874\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 83.3642 - accuracy: 0.1030 - val_loss: 61.5827 - val_accuracy: 0.0536\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 71.1157 - accuracy: 0.1034 - val_loss: 66.4621 - val_accuracy: 0.0944\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 88.6727 - accuracy: 0.0891 - val_loss: 78.6254 - val_accuracy: 0.1479\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 4s 56ms/step - loss: 79.3325 - accuracy: 0.0976 - val_loss: 73.8851 - val_accuracy: 0.0903\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 2s 32ms/step - loss: 85.1887 - accuracy: 0.0957 - val_loss: 103.8937 - val_accuracy: 0.0792\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 2s 22ms/step - loss: 86.9084 - accuracy: 0.0918 - val_loss: 84.7461 - val_accuracy: 0.0681\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 88.3609 - accuracy: 0.0886 - val_loss: 104.3682 - val_accuracy: 0.0716\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 18ms/step - loss: 102.8655 - accuracy: 0.0909 - val_loss: 93.8023 - val_accuracy: 0.0810\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 90.5648 - accuracy: 0.0954 - val_loss: 101.3587 - val_accuracy: 0.0670\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 109.7314 - accuracy: 0.0907 - val_loss: 87.1732 - val_accuracy: 0.0751\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 97.5772 - accuracy: 0.1038 - val_loss: 85.3578 - val_accuracy: 0.0903\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 103.4070 - accuracy: 0.1025 - val_loss: 114.6626 - val_accuracy: 0.1182\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 105.6678 - accuracy: 0.1041 - val_loss: 108.3846 - val_accuracy: 0.0798\n",
      "---- building model for layer width of 4 and 8\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 3s 27ms/step - loss: 3.7118 - accuracy: 0.0867 - val_loss: 3.3881 - val_accuracy: 0.1316\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.2504 - accuracy: 0.1401 - val_loss: 3.1629 - val_accuracy: 0.1573\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.0752 - accuracy: 0.1780 - val_loss: 3.0491 - val_accuracy: 0.1893\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 2.9969 - accuracy: 0.1966 - val_loss: 2.9963 - val_accuracy: 0.1934\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.9631 - accuracy: 0.1972 - val_loss: 2.9694 - val_accuracy: 0.1939\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.9456 - accuracy: 0.1971 - val_loss: 2.9590 - val_accuracy: 0.1934\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 2.9399 - accuracy: 0.1984 - val_loss: 2.9486 - val_accuracy: 0.1928\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.9331 - accuracy: 0.1981 - val_loss: 2.9482 - val_accuracy: 0.1963\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.9244 - accuracy: 0.1979 - val_loss: 2.9368 - val_accuracy: 0.1957\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.9086 - accuracy: 0.1991 - val_loss: 2.9115 - val_accuracy: 0.1974\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8972 - accuracy: 0.2006 - val_loss: 2.8938 - val_accuracy: 0.1963\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8810 - accuracy: 0.1997 - val_loss: 2.8943 - val_accuracy: 0.1957\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8757 - accuracy: 0.2000 - val_loss: 2.8699 - val_accuracy: 0.2003\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8555 - accuracy: 0.2048 - val_loss: 2.8565 - val_accuracy: 0.1998\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.8421 - accuracy: 0.2054 - val_loss: 2.8441 - val_accuracy: 0.1998\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.8267 - accuracy: 0.2080 - val_loss: 2.8318 - val_accuracy: 0.2009\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 2.8111 - accuracy: 0.2105 - val_loss: 2.8091 - val_accuracy: 0.2027\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7973 - accuracy: 0.2116 - val_loss: 2.8036 - val_accuracy: 0.2050\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7842 - accuracy: 0.2135 - val_loss: 2.7885 - val_accuracy: 0.2097\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 2.7733 - accuracy: 0.2138 - val_loss: 2.7782 - val_accuracy: 0.2120\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 2.7604 - accuracy: 0.2144 - val_loss: 2.7763 - val_accuracy: 0.2103\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7563 - accuracy: 0.2151 - val_loss: 2.7625 - val_accuracy: 0.2155\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7442 - accuracy: 0.2201 - val_loss: 2.7578 - val_accuracy: 0.2155\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7391 - accuracy: 0.2204 - val_loss: 2.7545 - val_accuracy: 0.2143\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.7338 - accuracy: 0.2188 - val_loss: 2.7482 - val_accuracy: 0.2132\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.7329 - accuracy: 0.2189 - val_loss: 2.7463 - val_accuracy: 0.2143\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 2.7272 - accuracy: 0.2185 - val_loss: 2.7441 - val_accuracy: 0.2137\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.7238 - accuracy: 0.2204 - val_loss: 2.7415 - val_accuracy: 0.2143\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7195 - accuracy: 0.2208 - val_loss: 2.7508 - val_accuracy: 0.2184\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 2.7193 - accuracy: 0.2217 - val_loss: 2.7449 - val_accuracy: 0.2143\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.7202 - accuracy: 0.2189 - val_loss: 2.7536 - val_accuracy: 0.2202\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7212 - accuracy: 0.2209 - val_loss: 2.7481 - val_accuracy: 0.2161\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7176 - accuracy: 0.2227 - val_loss: 2.7522 - val_accuracy: 0.2132\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7146 - accuracy: 0.2230 - val_loss: 2.7396 - val_accuracy: 0.2172\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7133 - accuracy: 0.2205 - val_loss: 2.7559 - val_accuracy: 0.2178\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7156 - accuracy: 0.2228 - val_loss: 2.7402 - val_accuracy: 0.2132\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7153 - accuracy: 0.2198 - val_loss: 2.7429 - val_accuracy: 0.2172\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7165 - accuracy: 0.2191 - val_loss: 2.7363 - val_accuracy: 0.2149\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7148 - accuracy: 0.2227 - val_loss: 2.7429 - val_accuracy: 0.2114\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7195 - accuracy: 0.2208 - val_loss: 2.7446 - val_accuracy: 0.2172\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7152 - accuracy: 0.2207 - val_loss: 2.7419 - val_accuracy: 0.2155\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7174 - accuracy: 0.2221 - val_loss: 2.7527 - val_accuracy: 0.2161\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7121 - accuracy: 0.2240 - val_loss: 2.7413 - val_accuracy: 0.2161\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7199 - accuracy: 0.2241 - val_loss: 2.7311 - val_accuracy: 0.2167\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7186 - accuracy: 0.2223 - val_loss: 2.7669 - val_accuracy: 0.2132\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7148 - accuracy: 0.2212 - val_loss: 2.7527 - val_accuracy: 0.2103\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7184 - accuracy: 0.2243 - val_loss: 2.7467 - val_accuracy: 0.2155\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7142 - accuracy: 0.2228 - val_loss: 2.7465 - val_accuracy: 0.2108\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7185 - accuracy: 0.2207 - val_loss: 2.7416 - val_accuracy: 0.2155\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7155 - accuracy: 0.2217 - val_loss: 2.7496 - val_accuracy: 0.2114\n",
      "---- building model for layer width of 32 and 2048\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 3.1216 - accuracy: 0.1752 - val_loss: 2.9414 - val_accuracy: 0.1916\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.9153 - accuracy: 0.1982 - val_loss: 2.9527 - val_accuracy: 0.1508\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9349 - accuracy: 0.1933 - val_loss: 3.0299 - val_accuracy: 0.1683\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0379 - accuracy: 0.1858 - val_loss: 3.0993 - val_accuracy: 0.1904\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0706 - accuracy: 0.1899 - val_loss: 3.0120 - val_accuracy: 0.1910\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.2038 - accuracy: 0.1828 - val_loss: 3.3289 - val_accuracy: 0.1893\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 3.7042 - accuracy: 0.1655 - val_loss: 4.0889 - val_accuracy: 0.1474\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.8836 - accuracy: 0.1618 - val_loss: 4.4989 - val_accuracy: 0.1590\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.0160 - accuracy: 0.1465 - val_loss: 5.6868 - val_accuracy: 0.1503\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 7.9197 - accuracy: 0.1280 - val_loss: 9.3218 - val_accuracy: 0.1252\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 9.6138 - accuracy: 0.1175 - val_loss: 9.8990 - val_accuracy: 0.0827\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 10.0770 - accuracy: 0.1219 - val_loss: 11.8539 - val_accuracy: 0.1124\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 14.1659 - accuracy: 0.1151 - val_loss: 17.9736 - val_accuracy: 0.0571\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 17.4442 - accuracy: 0.1101 - val_loss: 19.3136 - val_accuracy: 0.0856\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 20.0749 - accuracy: 0.1054 - val_loss: 26.8592 - val_accuracy: 0.0810\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 23.6773 - accuracy: 0.1097 - val_loss: 24.4825 - val_accuracy: 0.0792\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 21.5881 - accuracy: 0.1110 - val_loss: 25.5152 - val_accuracy: 0.1567\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 32.8423 - accuracy: 0.1025 - val_loss: 39.4619 - val_accuracy: 0.0984\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 33.8132 - accuracy: 0.0985 - val_loss: 44.5159 - val_accuracy: 0.1514\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 35.2898 - accuracy: 0.1044 - val_loss: 49.3279 - val_accuracy: 0.0658\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 36.9359 - accuracy: 0.0970 - val_loss: 39.2583 - val_accuracy: 0.0518\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 45.4078 - accuracy: 0.0980 - val_loss: 46.2580 - val_accuracy: 0.0938\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 49.7234 - accuracy: 0.0970 - val_loss: 55.6678 - val_accuracy: 0.0676\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 46.8743 - accuracy: 0.1076 - val_loss: 45.3534 - val_accuracy: 0.1479\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 50.4972 - accuracy: 0.1054 - val_loss: 37.5864 - val_accuracy: 0.1322\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 54.8580 - accuracy: 0.1101 - val_loss: 57.5259 - val_accuracy: 0.0711\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 55.5982 - accuracy: 0.1040 - val_loss: 54.6416 - val_accuracy: 0.1095\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 58.7117 - accuracy: 0.1003 - val_loss: 54.5377 - val_accuracy: 0.0949\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 59.3648 - accuracy: 0.1049 - val_loss: 69.0578 - val_accuracy: 0.0967\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 65.5713 - accuracy: 0.1081 - val_loss: 54.0066 - val_accuracy: 0.0868\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 71.7584 - accuracy: 0.0976 - val_loss: 57.3459 - val_accuracy: 0.1060\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 78.1149 - accuracy: 0.0999 - val_loss: 74.4624 - val_accuracy: 0.1456\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 70.8178 - accuracy: 0.1062 - val_loss: 81.4768 - val_accuracy: 0.0734\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 84.9655 - accuracy: 0.0938 - val_loss: 62.7473 - val_accuracy: 0.1246\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 86.2023 - accuracy: 0.1057 - val_loss: 90.1671 - val_accuracy: 0.1002\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 91.4336 - accuracy: 0.1009 - val_loss: 100.1059 - val_accuracy: 0.0635\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 97.1105 - accuracy: 0.0992 - val_loss: 92.0716 - val_accuracy: 0.0990\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 95.7113 - accuracy: 0.1075 - val_loss: 103.9676 - val_accuracy: 0.0938\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 92.5730 - accuracy: 0.1036 - val_loss: 86.0270 - val_accuracy: 0.0914\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 111.0091 - accuracy: 0.0999 - val_loss: 110.2767 - val_accuracy: 0.1718\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 109.6825 - accuracy: 0.1014 - val_loss: 112.7688 - val_accuracy: 0.0874\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 107.2692 - accuracy: 0.1033 - val_loss: 102.5422 - val_accuracy: 0.0944\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 110.3081 - accuracy: 0.0998 - val_loss: 119.0494 - val_accuracy: 0.1124\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 121.8117 - accuracy: 0.0980 - val_loss: 123.4095 - val_accuracy: 0.1089\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 119.5881 - accuracy: 0.1075 - val_loss: 110.7791 - val_accuracy: 0.1526\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 118.6418 - accuracy: 0.1091 - val_loss: 139.2713 - val_accuracy: 0.1147\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 21ms/step - loss: 131.3511 - accuracy: 0.1053 - val_loss: 126.6045 - val_accuracy: 0.0903\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 128.7550 - accuracy: 0.1041 - val_loss: 133.7411 - val_accuracy: 0.1025\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 136.8446 - accuracy: 0.1052 - val_loss: 111.7885 - val_accuracy: 0.1666\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 139.2543 - accuracy: 0.1003 - val_loss: 165.0893 - val_accuracy: 0.0478\n",
      "---- building model for layer width of 32 and 64\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 17ms/step - loss: 4.1381 - accuracy: 0.1114 - val_loss: 3.1311 - val_accuracy: 0.1450\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 3.0457 - accuracy: 0.1720 - val_loss: 2.9874 - val_accuracy: 0.1951\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.9457 - accuracy: 0.1911 - val_loss: 2.9222 - val_accuracy: 0.2015\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.8780 - accuracy: 0.1987 - val_loss: 2.8944 - val_accuracy: 0.1986\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8402 - accuracy: 0.2054 - val_loss: 2.8373 - val_accuracy: 0.2149\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8029 - accuracy: 0.2090 - val_loss: 2.8245 - val_accuracy: 0.2126\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.7862 - accuracy: 0.2097 - val_loss: 2.8431 - val_accuracy: 0.1951\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7734 - accuracy: 0.2140 - val_loss: 2.8214 - val_accuracy: 0.2202\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7735 - accuracy: 0.2142 - val_loss: 2.7974 - val_accuracy: 0.2143\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7737 - accuracy: 0.2093 - val_loss: 2.8647 - val_accuracy: 0.2172\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.7610 - accuracy: 0.2173 - val_loss: 2.8002 - val_accuracy: 0.2044\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.7502 - accuracy: 0.2177 - val_loss: 2.8131 - val_accuracy: 0.2038\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7591 - accuracy: 0.2173 - val_loss: 2.8228 - val_accuracy: 0.2079\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7729 - accuracy: 0.2158 - val_loss: 2.8312 - val_accuracy: 0.1904\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7530 - accuracy: 0.2223 - val_loss: 2.8151 - val_accuracy: 0.1963\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7762 - accuracy: 0.2137 - val_loss: 2.8666 - val_accuracy: 0.2079\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.7825 - accuracy: 0.2137 - val_loss: 2.8660 - val_accuracy: 0.2027\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8018 - accuracy: 0.2081 - val_loss: 2.8713 - val_accuracy: 0.2091\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.7935 - accuracy: 0.2089 - val_loss: 2.7912 - val_accuracy: 0.2108\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8139 - accuracy: 0.2107 - val_loss: 2.8733 - val_accuracy: 0.1922\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8542 - accuracy: 0.2065 - val_loss: 2.9727 - val_accuracy: 0.1980\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8130 - accuracy: 0.2122 - val_loss: 2.9262 - val_accuracy: 0.1753\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8670 - accuracy: 0.2059 - val_loss: 2.9088 - val_accuracy: 0.2068\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.8305 - accuracy: 0.2121 - val_loss: 2.8871 - val_accuracy: 0.1753\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8460 - accuracy: 0.2039 - val_loss: 2.9269 - val_accuracy: 0.1910\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.9156 - accuracy: 0.2035 - val_loss: 2.9636 - val_accuracy: 0.1619\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8739 - accuracy: 0.2036 - val_loss: 2.9898 - val_accuracy: 0.1689\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.8748 - accuracy: 0.1973 - val_loss: 3.0021 - val_accuracy: 0.1607\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.9161 - accuracy: 0.2043 - val_loss: 3.0802 - val_accuracy: 0.1771\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9853 - accuracy: 0.1949 - val_loss: 3.0545 - val_accuracy: 0.1829\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.9500 - accuracy: 0.2026 - val_loss: 3.0660 - val_accuracy: 0.1980\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.0007 - accuracy: 0.1941 - val_loss: 3.0210 - val_accuracy: 0.1846\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.0392 - accuracy: 0.1918 - val_loss: 3.4167 - val_accuracy: 0.1456\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.0136 - accuracy: 0.1930 - val_loss: 3.0541 - val_accuracy: 0.1846\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1469 - accuracy: 0.1823 - val_loss: 3.2859 - val_accuracy: 0.1771\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0951 - accuracy: 0.1839 - val_loss: 3.4068 - val_accuracy: 0.1637\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0543 - accuracy: 0.1889 - val_loss: 3.1790 - val_accuracy: 0.1794\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0945 - accuracy: 0.1949 - val_loss: 3.2292 - val_accuracy: 0.1450\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.1815 - accuracy: 0.1845 - val_loss: 3.1700 - val_accuracy: 0.1753\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1761 - accuracy: 0.1806 - val_loss: 3.5208 - val_accuracy: 0.1258\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.1232 - accuracy: 0.1965 - val_loss: 3.4934 - val_accuracy: 0.1642\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.2457 - accuracy: 0.1873 - val_loss: 3.6861 - val_accuracy: 0.1508\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4161 - accuracy: 0.1781 - val_loss: 3.6697 - val_accuracy: 0.1491\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 3.4430 - accuracy: 0.1748 - val_loss: 3.4991 - val_accuracy: 0.1642\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.3243 - accuracy: 0.1857 - val_loss: 3.5663 - val_accuracy: 0.1893\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 3.4108 - accuracy: 0.1869 - val_loss: 3.5154 - val_accuracy: 0.1206\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.5592 - accuracy: 0.1668 - val_loss: 3.7210 - val_accuracy: 0.1450\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.5941 - accuracy: 0.1761 - val_loss: 3.5023 - val_accuracy: 0.1969\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.3552 - accuracy: 0.1799 - val_loss: 3.4400 - val_accuracy: 0.1701\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4888 - accuracy: 0.1791 - val_loss: 4.3705 - val_accuracy: 0.1567\n",
      "---- building model for layer width of 2048 and 64\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 6s 12ms/step - loss: 3.9014 - accuracy: 0.1570 - val_loss: 3.0578 - val_accuracy: 0.1974\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9874 - accuracy: 0.1940 - val_loss: 2.9510 - val_accuracy: 0.1986\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9517 - accuracy: 0.1984 - val_loss: 2.9346 - val_accuracy: 0.1957\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8969 - accuracy: 0.2008 - val_loss: 2.9990 - val_accuracy: 0.1864\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9510 - accuracy: 0.1987 - val_loss: 2.9961 - val_accuracy: 0.1805\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.1584 - accuracy: 0.1867 - val_loss: 3.4972 - val_accuracy: 0.1474\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 2s 27ms/step - loss: 3.4748 - accuracy: 0.1765 - val_loss: 3.9186 - val_accuracy: 0.0984\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 4.6680 - accuracy: 0.1416 - val_loss: 4.7788 - val_accuracy: 0.1701\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 2s 29ms/step - loss: 5.9527 - accuracy: 0.1375 - val_loss: 6.8522 - val_accuracy: 0.1223\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 9.6568 - accuracy: 0.1036 - val_loss: 16.2170 - val_accuracy: 0.1345\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 12.9637 - accuracy: 0.1052 - val_loss: 12.9450 - val_accuracy: 0.0955\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 14.4576 - accuracy: 0.1020 - val_loss: 17.6331 - val_accuracy: 0.0978\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 20.1160 - accuracy: 0.0983 - val_loss: 22.3121 - val_accuracy: 0.1351\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 22.8566 - accuracy: 0.1044 - val_loss: 30.7891 - val_accuracy: 0.0617\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 24.2057 - accuracy: 0.0982 - val_loss: 31.7901 - val_accuracy: 0.1369\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 34.0295 - accuracy: 0.0868 - val_loss: 39.1554 - val_accuracy: 0.0938\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 34.4329 - accuracy: 0.0912 - val_loss: 43.2863 - val_accuracy: 0.0850\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 45.1771 - accuracy: 0.0900 - val_loss: 50.0802 - val_accuracy: 0.1468\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 44.1150 - accuracy: 0.0923 - val_loss: 27.9157 - val_accuracy: 0.1002\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 46.9252 - accuracy: 0.0896 - val_loss: 45.5966 - val_accuracy: 0.1229\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 48.9411 - accuracy: 0.0992 - val_loss: 42.9872 - val_accuracy: 0.0699\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 57.6778 - accuracy: 0.0837 - val_loss: 49.7166 - val_accuracy: 0.0687\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 60.8365 - accuracy: 0.0877 - val_loss: 65.3847 - val_accuracy: 0.0483\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 66.3679 - accuracy: 0.0897 - val_loss: 61.7776 - val_accuracy: 0.1217\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 70.8869 - accuracy: 0.0906 - val_loss: 67.5030 - val_accuracy: 0.1503\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 74.6476 - accuracy: 0.0935 - val_loss: 79.3722 - val_accuracy: 0.0676\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 85.7323 - accuracy: 0.0858 - val_loss: 83.4922 - val_accuracy: 0.0553\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 92.9657 - accuracy: 0.0816 - val_loss: 101.1256 - val_accuracy: 0.0466\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 95.0574 - accuracy: 0.0870 - val_loss: 93.8041 - val_accuracy: 0.0588\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 92.7481 - accuracy: 0.0891 - val_loss: 104.1388 - val_accuracy: 0.0629\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 94.6421 - accuracy: 0.0913 - val_loss: 91.5654 - val_accuracy: 0.0903\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 112.1055 - accuracy: 0.0811 - val_loss: 105.9058 - val_accuracy: 0.0955\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 107.6231 - accuracy: 0.0935 - val_loss: 107.8999 - val_accuracy: 0.1433\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 109.0636 - accuracy: 0.0953 - val_loss: 95.5635 - val_accuracy: 0.0932\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 108.2734 - accuracy: 0.0891 - val_loss: 143.1188 - val_accuracy: 0.0775\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 122.0656 - accuracy: 0.0870 - val_loss: 114.6574 - val_accuracy: 0.0740\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 115.0479 - accuracy: 0.0928 - val_loss: 130.5121 - val_accuracy: 0.0571\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 130.5657 - accuracy: 0.0842 - val_loss: 127.0993 - val_accuracy: 0.0716\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 141.6203 - accuracy: 0.0890 - val_loss: 148.0725 - val_accuracy: 0.0437\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 135.6737 - accuracy: 0.0969 - val_loss: 124.3057 - val_accuracy: 0.0751\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 129.1121 - accuracy: 0.0993 - val_loss: 119.2987 - val_accuracy: 0.0728\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 148.0565 - accuracy: 0.0947 - val_loss: 173.7535 - val_accuracy: 0.0687\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 156.2527 - accuracy: 0.0829 - val_loss: 150.2148 - val_accuracy: 0.1334\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 148.0046 - accuracy: 0.0853 - val_loss: 170.9201 - val_accuracy: 0.0769\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 151.1896 - accuracy: 0.0888 - val_loss: 146.2715 - val_accuracy: 0.0775\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 164.5720 - accuracy: 0.0910 - val_loss: 203.3880 - val_accuracy: 0.0763\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 184.6282 - accuracy: 0.0856 - val_loss: 222.4662 - val_accuracy: 0.0990\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 191.4407 - accuracy: 0.0897 - val_loss: 178.0792 - val_accuracy: 0.1019\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 191.8007 - accuracy: 0.0845 - val_loss: 162.1799 - val_accuracy: 0.1147\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 198.7594 - accuracy: 0.0890 - val_loss: 243.2825 - val_accuracy: 0.0856\n",
      "---- building model for layer width of 2048 and 8\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 5.6365 - accuracy: 0.1382 - val_loss: 4.4344 - val_accuracy: 0.1718\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.8758 - accuracy: 0.1806 - val_loss: 3.4154 - val_accuracy: 0.1881\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.2048 - accuracy: 0.1888 - val_loss: 3.1061 - val_accuracy: 0.1899\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0331 - accuracy: 0.1979 - val_loss: 3.0639 - val_accuracy: 0.1759\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0555 - accuracy: 0.1870 - val_loss: 3.0522 - val_accuracy: 0.1788\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0071 - accuracy: 0.1952 - val_loss: 3.0256 - val_accuracy: 0.1794\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.9778 - accuracy: 0.1975 - val_loss: 2.9934 - val_accuracy: 0.1858\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0033 - accuracy: 0.1947 - val_loss: 2.9979 - val_accuracy: 0.1945\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.5332 - accuracy: 0.1622 - val_loss: 3.8207 - val_accuracy: 0.1730\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.5951 - accuracy: 0.1838 - val_loss: 3.3852 - val_accuracy: 0.1939\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.2557 - accuracy: 0.1909 - val_loss: 3.1431 - val_accuracy: 0.1875\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0555 - accuracy: 0.1918 - val_loss: 3.0888 - val_accuracy: 0.1945\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0091 - accuracy: 0.1952 - val_loss: 2.9655 - val_accuracy: 0.2038\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.9623 - accuracy: 0.2024 - val_loss: 3.0028 - val_accuracy: 0.1881\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.1730 - accuracy: 0.1861 - val_loss: 3.1436 - val_accuracy: 0.1957\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0014 - accuracy: 0.2011 - val_loss: 2.9273 - val_accuracy: 0.1910\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8835 - accuracy: 0.2054 - val_loss: 2.9265 - val_accuracy: 0.1998\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9364 - accuracy: 0.2020 - val_loss: 2.9723 - val_accuracy: 0.1788\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9284 - accuracy: 0.1998 - val_loss: 2.9231 - val_accuracy: 0.1893\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.8780 - accuracy: 0.2046 - val_loss: 2.9178 - val_accuracy: 0.1980\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8864 - accuracy: 0.2064 - val_loss: 2.8670 - val_accuracy: 0.1951\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8394 - accuracy: 0.2070 - val_loss: 2.8463 - val_accuracy: 0.2120\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8242 - accuracy: 0.2087 - val_loss: 2.8220 - val_accuracy: 0.2027\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8980 - accuracy: 0.2010 - val_loss: 2.9680 - val_accuracy: 0.1637\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0050 - accuracy: 0.1888 - val_loss: 3.2201 - val_accuracy: 0.1206\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1734 - accuracy: 0.1770 - val_loss: 3.3274 - val_accuracy: 0.1794\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.9535 - accuracy: 0.1369 - val_loss: 4.8125 - val_accuracy: 0.1299\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.7647 - accuracy: 0.1347 - val_loss: 4.4838 - val_accuracy: 0.1747\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 7.4232 - accuracy: 0.1072 - val_loss: 6.5474 - val_accuracy: 0.0961\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 8.7152 - accuracy: 0.1053 - val_loss: 11.7036 - val_accuracy: 0.0641\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 13.2797 - accuracy: 0.0950 - val_loss: 16.9074 - val_accuracy: 0.0612\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 17.4131 - accuracy: 0.0855 - val_loss: 14.4933 - val_accuracy: 0.0658\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 16.9429 - accuracy: 0.1001 - val_loss: 19.4784 - val_accuracy: 0.0967\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 17.3036 - accuracy: 0.0926 - val_loss: 13.5486 - val_accuracy: 0.0722\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 18.4386 - accuracy: 0.0971 - val_loss: 18.8211 - val_accuracy: 0.1619\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 17.1975 - accuracy: 0.1022 - val_loss: 23.1994 - val_accuracy: 0.0623\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 19.8399 - accuracy: 0.0923 - val_loss: 19.1769 - val_accuracy: 0.0786\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 23.2256 - accuracy: 0.0932 - val_loss: 18.7524 - val_accuracy: 0.0815\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 22.0206 - accuracy: 0.0893 - val_loss: 23.4626 - val_accuracy: 0.0885\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 19ms/step - loss: 25.6724 - accuracy: 0.0957 - val_loss: 22.1694 - val_accuracy: 0.0885\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 29.1280 - accuracy: 0.0845 - val_loss: 39.1055 - val_accuracy: 0.0745\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 30.8991 - accuracy: 0.0896 - val_loss: 33.3846 - val_accuracy: 0.0751\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 29.8336 - accuracy: 0.0910 - val_loss: 35.4478 - val_accuracy: 0.1287\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 35.7611 - accuracy: 0.0827 - val_loss: 30.9230 - val_accuracy: 0.0897\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 34.7249 - accuracy: 0.0859 - val_loss: 41.7652 - val_accuracy: 0.0565\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 42.3820 - accuracy: 0.0856 - val_loss: 50.2417 - val_accuracy: 0.0786\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 39.9333 - accuracy: 0.0904 - val_loss: 41.9222 - val_accuracy: 0.1264\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 42.9708 - accuracy: 0.0902 - val_loss: 56.2427 - val_accuracy: 0.0769\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 41.0865 - accuracy: 0.0941 - val_loss: 34.2948 - val_accuracy: 0.0652\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 40.1634 - accuracy: 0.1040 - val_loss: 32.9906 - val_accuracy: 0.1159\n",
      "---- building model for layer width of 128 and 16\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 13ms/step - loss: 3.9727 - accuracy: 0.0717 - val_loss: 3.1927 - val_accuracy: 0.1369\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.0652 - accuracy: 0.1805 - val_loss: 3.0463 - val_accuracy: 0.1922\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9948 - accuracy: 0.1917 - val_loss: 2.9856 - val_accuracy: 0.1998\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.9427 - accuracy: 0.1943 - val_loss: 2.9648 - val_accuracy: 0.1986\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9347 - accuracy: 0.1968 - val_loss: 2.9599 - val_accuracy: 0.2050\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.9140 - accuracy: 0.2008 - val_loss: 2.9794 - val_accuracy: 0.2079\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8952 - accuracy: 0.2022 - val_loss: 2.9081 - val_accuracy: 0.2021\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.8843 - accuracy: 0.2024 - val_loss: 2.9079 - val_accuracy: 0.1998\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8628 - accuracy: 0.2061 - val_loss: 2.8799 - val_accuracy: 0.1992\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8398 - accuracy: 0.2014 - val_loss: 2.8636 - val_accuracy: 0.1963\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8368 - accuracy: 0.2045 - val_loss: 2.8921 - val_accuracy: 0.1974\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.8155 - accuracy: 0.2083 - val_loss: 2.8437 - val_accuracy: 0.2097\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8213 - accuracy: 0.2091 - val_loss: 2.8699 - val_accuracy: 0.2021\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8320 - accuracy: 0.2038 - val_loss: 2.8473 - val_accuracy: 0.1998\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7999 - accuracy: 0.2090 - val_loss: 2.8420 - val_accuracy: 0.2108\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7871 - accuracy: 0.2169 - val_loss: 2.8442 - val_accuracy: 0.2056\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7944 - accuracy: 0.2144 - val_loss: 2.8325 - val_accuracy: 0.1992\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7826 - accuracy: 0.2142 - val_loss: 2.8120 - val_accuracy: 0.2062\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7979 - accuracy: 0.2135 - val_loss: 2.8390 - val_accuracy: 0.2068\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7838 - accuracy: 0.2186 - val_loss: 2.8326 - val_accuracy: 0.2009\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7810 - accuracy: 0.2141 - val_loss: 2.8104 - val_accuracy: 0.1998\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7808 - accuracy: 0.2135 - val_loss: 2.8110 - val_accuracy: 0.2079\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8108 - accuracy: 0.2157 - val_loss: 2.8186 - val_accuracy: 0.2137\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7901 - accuracy: 0.2132 - val_loss: 2.7927 - val_accuracy: 0.2143\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7943 - accuracy: 0.2097 - val_loss: 2.8591 - val_accuracy: 0.1887\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7805 - accuracy: 0.2112 - val_loss: 2.8297 - val_accuracy: 0.2050\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.8187 - accuracy: 0.2144 - val_loss: 2.8384 - val_accuracy: 0.2003\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8096 - accuracy: 0.2087 - val_loss: 2.8119 - val_accuracy: 0.2097\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7877 - accuracy: 0.2151 - val_loss: 2.8343 - val_accuracy: 0.2068\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8311 - accuracy: 0.2052 - val_loss: 2.8400 - val_accuracy: 0.2015\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8124 - accuracy: 0.2059 - val_loss: 2.8798 - val_accuracy: 0.2003\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.8193 - accuracy: 0.2074 - val_loss: 2.8145 - val_accuracy: 0.2097\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8072 - accuracy: 0.2103 - val_loss: 2.8729 - val_accuracy: 0.2050\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8080 - accuracy: 0.2109 - val_loss: 2.8476 - val_accuracy: 0.1992\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8321 - accuracy: 0.2003 - val_loss: 2.8480 - val_accuracy: 0.2097\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8365 - accuracy: 0.2058 - val_loss: 2.9891 - val_accuracy: 0.2085\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8523 - accuracy: 0.2059 - val_loss: 2.8691 - val_accuracy: 0.1899\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8464 - accuracy: 0.2049 - val_loss: 2.8649 - val_accuracy: 0.1974\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8435 - accuracy: 0.2081 - val_loss: 2.8618 - val_accuracy: 0.1928\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8723 - accuracy: 0.2010 - val_loss: 2.8338 - val_accuracy: 0.2103\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8685 - accuracy: 0.2064 - val_loss: 2.9448 - val_accuracy: 0.1846\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.9126 - accuracy: 0.2046 - val_loss: 2.8970 - val_accuracy: 0.1957\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8816 - accuracy: 0.2035 - val_loss: 2.9027 - val_accuracy: 0.2038\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.9156 - accuracy: 0.2001 - val_loss: 2.9624 - val_accuracy: 0.1980\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.9388 - accuracy: 0.2038 - val_loss: 2.8585 - val_accuracy: 0.1969\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.9499 - accuracy: 0.1979 - val_loss: 3.1704 - val_accuracy: 0.1660\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.9928 - accuracy: 0.1944 - val_loss: 2.9138 - val_accuracy: 0.2114\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.9415 - accuracy: 0.2006 - val_loss: 3.0709 - val_accuracy: 0.1753\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0195 - accuracy: 0.1949 - val_loss: 3.0391 - val_accuracy: 0.1788\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0150 - accuracy: 0.1905 - val_loss: 3.0419 - val_accuracy: 0.1899\n",
      "---- building model for layer width of 32 and 128\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 3.3027 - accuracy: 0.1506 - val_loss: 2.9712 - val_accuracy: 0.1910\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.9317 - accuracy: 0.1872 - val_loss: 2.9016 - val_accuracy: 0.1969\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8560 - accuracy: 0.1998 - val_loss: 2.8529 - val_accuracy: 0.2027\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8175 - accuracy: 0.2061 - val_loss: 2.8388 - val_accuracy: 0.1951\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7924 - accuracy: 0.2071 - val_loss: 2.8347 - val_accuracy: 0.1916\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7795 - accuracy: 0.2102 - val_loss: 2.8024 - val_accuracy: 0.1893\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7693 - accuracy: 0.2121 - val_loss: 2.8002 - val_accuracy: 0.2085\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7572 - accuracy: 0.2161 - val_loss: 2.8318 - val_accuracy: 0.2027\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7711 - accuracy: 0.2148 - val_loss: 2.8182 - val_accuracy: 0.2027\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7718 - accuracy: 0.2113 - val_loss: 2.7893 - val_accuracy: 0.2062\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.7818 - accuracy: 0.2100 - val_loss: 2.8594 - val_accuracy: 0.2056\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7802 - accuracy: 0.2185 - val_loss: 2.8385 - val_accuracy: 0.2033\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8018 - accuracy: 0.2077 - val_loss: 2.9678 - val_accuracy: 0.1846\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 2.8105 - accuracy: 0.2131 - val_loss: 2.9089 - val_accuracy: 0.2079\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8410 - accuracy: 0.2097 - val_loss: 2.8850 - val_accuracy: 0.2050\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.8583 - accuracy: 0.2067 - val_loss: 2.9014 - val_accuracy: 0.1986\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 2s 36ms/step - loss: 2.8434 - accuracy: 0.2049 - val_loss: 2.9527 - val_accuracy: 0.1986\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 2s 31ms/step - loss: 2.9140 - accuracy: 0.2058 - val_loss: 3.0665 - val_accuracy: 0.1858\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 2.9005 - accuracy: 0.2004 - val_loss: 2.9435 - val_accuracy: 0.1969\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 3.0779 - accuracy: 0.1898 - val_loss: 3.0897 - val_accuracy: 0.2050\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.0209 - accuracy: 0.1975 - val_loss: 3.0037 - val_accuracy: 0.1969\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.9981 - accuracy: 0.1990 - val_loss: 3.1019 - val_accuracy: 0.1922\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.0210 - accuracy: 0.1981 - val_loss: 2.9494 - val_accuracy: 0.1945\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.1154 - accuracy: 0.1933 - val_loss: 3.2578 - val_accuracy: 0.1182\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1618 - accuracy: 0.1831 - val_loss: 3.2709 - val_accuracy: 0.1852\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.2756 - accuracy: 0.1844 - val_loss: 3.3888 - val_accuracy: 0.1590\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.2947 - accuracy: 0.1864 - val_loss: 3.0921 - val_accuracy: 0.2056\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.1631 - accuracy: 0.1850 - val_loss: 3.2894 - val_accuracy: 0.2021\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.3579 - accuracy: 0.1807 - val_loss: 3.9411 - val_accuracy: 0.1771\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.5426 - accuracy: 0.1778 - val_loss: 3.3942 - val_accuracy: 0.1736\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.6378 - accuracy: 0.1716 - val_loss: 3.7129 - val_accuracy: 0.1794\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.7477 - accuracy: 0.1681 - val_loss: 3.8234 - val_accuracy: 0.1235\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.6940 - accuracy: 0.1691 - val_loss: 3.8762 - val_accuracy: 0.1415\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 3.7718 - accuracy: 0.1637 - val_loss: 4.1190 - val_accuracy: 0.1334\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.7057 - accuracy: 0.1752 - val_loss: 4.0577 - val_accuracy: 0.1357\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 4.2026 - accuracy: 0.1532 - val_loss: 4.4782 - val_accuracy: 0.1171\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.4633 - accuracy: 0.1612 - val_loss: 3.8716 - val_accuracy: 0.1596\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 4.6208 - accuracy: 0.1561 - val_loss: 5.2164 - val_accuracy: 0.1415\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 4.7321 - accuracy: 0.1569 - val_loss: 4.1089 - val_accuracy: 0.1252\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.0670 - accuracy: 0.1563 - val_loss: 4.4977 - val_accuracy: 0.1677\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.4317 - accuracy: 0.1487 - val_loss: 4.4778 - val_accuracy: 0.1870\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.0682 - accuracy: 0.1525 - val_loss: 5.0793 - val_accuracy: 0.1479\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 5.4799 - accuracy: 0.1371 - val_loss: 5.6825 - val_accuracy: 0.1573\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 5.1777 - accuracy: 0.1499 - val_loss: 4.8477 - val_accuracy: 0.1206\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.9367 - accuracy: 0.1405 - val_loss: 6.2313 - val_accuracy: 0.1054\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 5.8923 - accuracy: 0.1384 - val_loss: 5.7329 - val_accuracy: 0.1660\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 7.0201 - accuracy: 0.1368 - val_loss: 5.7375 - val_accuracy: 0.1613\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.3919 - accuracy: 0.1387 - val_loss: 8.7148 - val_accuracy: 0.0740\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 6.7941 - accuracy: 0.1309 - val_loss: 5.8297 - val_accuracy: 0.1165\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 6.7701 - accuracy: 0.1355 - val_loss: 7.8645 - val_accuracy: 0.1573\n",
      "---- building model for layer width of 512 and 2048\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 4.4797 - accuracy: 0.1416 - val_loss: 3.4208 - val_accuracy: 0.1409\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.2122 - accuracy: 0.1858 - val_loss: 3.1567 - val_accuracy: 0.1794\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 3.3971 - accuracy: 0.1796 - val_loss: 3.4094 - val_accuracy: 0.1963\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.8253 - accuracy: 0.1622 - val_loss: 4.4172 - val_accuracy: 0.1590\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 7.8523 - accuracy: 0.1299 - val_loss: 13.2052 - val_accuracy: 0.1048\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 20.4528 - accuracy: 0.1073 - val_loss: 25.8649 - val_accuracy: 0.1182\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 38.0476 - accuracy: 0.0929 - val_loss: 40.0380 - val_accuracy: 0.0646\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 46.8855 - accuracy: 0.0999 - val_loss: 61.0193 - val_accuracy: 0.1211\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 67.0821 - accuracy: 0.0961 - val_loss: 72.8437 - val_accuracy: 0.1450\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 101.1674 - accuracy: 0.0971 - val_loss: 129.3805 - val_accuracy: 0.0751\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 127.8437 - accuracy: 0.0890 - val_loss: 144.1865 - val_accuracy: 0.0757\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 159.2946 - accuracy: 0.0884 - val_loss: 167.2008 - val_accuracy: 0.0670\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 197.9940 - accuracy: 0.0896 - val_loss: 159.7380 - val_accuracy: 0.1002\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 187.3958 - accuracy: 0.0966 - val_loss: 218.4367 - val_accuracy: 0.0553\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 220.3697 - accuracy: 0.1025 - val_loss: 328.0738 - val_accuracy: 0.0978\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 278.1569 - accuracy: 0.0977 - val_loss: 271.7854 - val_accuracy: 0.0646\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 288.0985 - accuracy: 0.0980 - val_loss: 293.8730 - val_accuracy: 0.1176\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 386.5149 - accuracy: 0.0883 - val_loss: 392.7831 - val_accuracy: 0.0868\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 432.9294 - accuracy: 0.0906 - val_loss: 513.6030 - val_accuracy: 0.0402\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 418.1075 - accuracy: 0.0944 - val_loss: 471.7376 - val_accuracy: 0.0967\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 477.5114 - accuracy: 0.0922 - val_loss: 519.0214 - val_accuracy: 0.1235\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 517.6833 - accuracy: 0.0870 - val_loss: 513.3154 - val_accuracy: 0.0944\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 537.4951 - accuracy: 0.0859 - val_loss: 492.6999 - val_accuracy: 0.1305\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 534.3866 - accuracy: 0.1002 - val_loss: 554.3825 - val_accuracy: 0.0938\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 532.3373 - accuracy: 0.0999 - val_loss: 565.7991 - val_accuracy: 0.0949\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 584.1160 - accuracy: 0.0897 - val_loss: 569.2010 - val_accuracy: 0.0938\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 676.8194 - accuracy: 0.0929 - val_loss: 678.2615 - val_accuracy: 0.0804\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 674.4820 - accuracy: 0.0922 - val_loss: 662.8387 - val_accuracy: 0.1345\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 718.4339 - accuracy: 0.0858 - val_loss: 692.3647 - val_accuracy: 0.0745\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 777.4803 - accuracy: 0.0936 - val_loss: 700.2469 - val_accuracy: 0.1404\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 822.9442 - accuracy: 0.0909 - val_loss: 796.3762 - val_accuracy: 0.1357\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 918.5535 - accuracy: 0.0887 - val_loss: 717.5388 - val_accuracy: 0.0973\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 821.7534 - accuracy: 0.0919 - val_loss: 767.1843 - val_accuracy: 0.1293\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 904.9504 - accuracy: 0.0906 - val_loss: 893.5085 - val_accuracy: 0.0763\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 973.8544 - accuracy: 0.0925 - val_loss: 736.9876 - val_accuracy: 0.1060\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 981.2965 - accuracy: 0.0947 - val_loss: 850.7998 - val_accuracy: 0.0664\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1049.9192 - accuracy: 0.0935 - val_loss: 1043.7720 - val_accuracy: 0.0780\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1088.9948 - accuracy: 0.0977 - val_loss: 910.9246 - val_accuracy: 0.1206\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1150.5562 - accuracy: 0.0957 - val_loss: 1215.8942 - val_accuracy: 0.0751\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1123.5515 - accuracy: 0.0875 - val_loss: 1216.2837 - val_accuracy: 0.1427\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1189.8990 - accuracy: 0.0907 - val_loss: 1180.5814 - val_accuracy: 0.0973\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1370.0271 - accuracy: 0.0875 - val_loss: 1337.1661 - val_accuracy: 0.0961\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1288.3950 - accuracy: 0.0934 - val_loss: 1312.1462 - val_accuracy: 0.0658\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 1318.9934 - accuracy: 0.0963 - val_loss: 1416.0734 - val_accuracy: 0.0874\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1408.5098 - accuracy: 0.0920 - val_loss: 1407.1525 - val_accuracy: 0.0839\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1488.2136 - accuracy: 0.0960 - val_loss: 1661.2173 - val_accuracy: 0.0565\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1610.0232 - accuracy: 0.0878 - val_loss: 1506.0131 - val_accuracy: 0.1089\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1598.8536 - accuracy: 0.0782 - val_loss: 1439.7491 - val_accuracy: 0.1176\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1643.4285 - accuracy: 0.0942 - val_loss: 2063.9409 - val_accuracy: 0.0932\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1851.5286 - accuracy: 0.0865 - val_loss: 1886.9088 - val_accuracy: 0.0978\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 Width</th>\n",
       "      <th>Layer 2 Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.207253</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>125.290993</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.090401</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>110.585281</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.083877</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.224294</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.776402</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.211556</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.198223</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>170.454285</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.053588</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.222255</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>4.491882</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.134669</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.200845</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>234.233826</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.085741</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.208710</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>33.839149</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.107642</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.218613</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>3.106026</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.218468</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>8.191059</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.144455</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>1881.994141</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.096459</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 Width  Layer 2 Width  Metrics Value         Metrics Type\n",
       "0             256            256       0.207253  Validation Accuracy\n",
       "1             256            256     125.290993            Test Loss\n",
       "2             256            256       0.090401        Test Accuracy\n",
       "3              16           2048       0.199680  Validation Accuracy\n",
       "4              16           2048     110.585281            Test Loss\n",
       "5              16           2048       0.083877        Test Accuracy\n",
       "6               4              8       0.224294  Validation Accuracy\n",
       "7               4              8       2.776402            Test Loss\n",
       "8               4              8       0.211556        Test Accuracy\n",
       "9              32           2048       0.198223  Validation Accuracy\n",
       "10             32           2048     170.454285            Test Loss\n",
       "11             32           2048       0.053588        Test Accuracy\n",
       "12             32             64       0.222255  Validation Accuracy\n",
       "13             32             64       4.491882            Test Loss\n",
       "14             32             64       0.134669        Test Accuracy\n",
       "15           2048             64       0.200845  Validation Accuracy\n",
       "16           2048             64     234.233826            Test Loss\n",
       "17           2048             64       0.085741        Test Accuracy\n",
       "18           2048              8       0.208710  Validation Accuracy\n",
       "19           2048              8      33.839149            Test Loss\n",
       "20           2048              8       0.107642        Test Accuracy\n",
       "21            128             16       0.218613  Validation Accuracy\n",
       "22            128             16       3.106026            Test Loss\n",
       "23            128             16       0.189655        Test Accuracy\n",
       "24             32            128       0.218468  Validation Accuracy\n",
       "25             32            128       8.191059            Test Loss\n",
       "26             32            128       0.144455        Test Accuracy\n",
       "27            512           2048       0.185843  Validation Accuracy\n",
       "28            512           2048    1881.994141            Test Loss\n",
       "29            512           2048       0.096459        Test Accuracy"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    r1 = random.randint(2, 12)\n",
    "    r2 = random.randint(2, 12)\n",
    "    \n",
    "    l1 = 2 ** r1\n",
    "    l2 = 2 ** r2\n",
    "    \n",
    "    print(\"---- building model for layer width of \" + str(l1) + \" and \" + str(l2))\n",
    "    d = DNN()\n",
    "    d.customize_first_layer(l1)\n",
    "    d.add_one_dense_layer(l2)\n",
    "    \n",
    "    #d.customize_fit(epochs = 2) ## TODO: REMOVE\n",
    "    \n",
    "    val_acc_result = d.build_compile_and_evaluate()\n",
    "    test_loss, test_accuracy = d.evaluate_model_with_test()\n",
    "    \n",
    "    results.append((l1, l2, val_acc_result, \"Validation Accuracy\"))\n",
    "    results.append((l1, l2, test_loss, \"Test Loss\"))\n",
    "    results.append((l1, l2, test_accuracy, \"Test Accuracy\"))\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results = results.rename(columns = {\n",
    "    0: \"Layer 1 Width\",\n",
    "    1: \"Layer 2 Width\",\n",
    "    2: \"Metrics Value\",\n",
    "    3: \"Metrics Type\"\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 Width</th>\n",
       "      <th>Layer 2 Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.207253</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.224294</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.198223</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.222255</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.200845</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.208710</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.218613</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.218468</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 Width  Layer 2 Width  Metrics Value         Metrics Type\n",
       "0             256            256       0.207253  Validation Accuracy\n",
       "3              16           2048       0.199680  Validation Accuracy\n",
       "6               4              8       0.224294  Validation Accuracy\n",
       "9              32           2048       0.198223  Validation Accuracy\n",
       "12             32             64       0.222255  Validation Accuracy\n",
       "15           2048             64       0.200845  Validation Accuracy\n",
       "18           2048              8       0.208710  Validation Accuracy\n",
       "21            128             16       0.218613  Validation Accuracy\n",
       "24             32            128       0.218468  Validation Accuracy\n",
       "27            512           2048       0.185843  Validation Accuracy"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy_only = results[results[\"Metrics Type\"] == \"Validation Accuracy\"]\n",
    "validation_accuracy_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
