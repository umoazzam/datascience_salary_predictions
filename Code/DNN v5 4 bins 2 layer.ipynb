{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminecjwchen/Documents/GitHub/COMS4995-AML-Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kaggle_survey_2020_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = df.drop(columns = [\"time_from_start_to_finish_seconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.dropna(subset = [\"q24\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(col_name: str, order_rules: list, data):\n",
    "    data[col_name] = pd.Categorical(data[col_name], order_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category_no_specified_order(col_name, data):\n",
    "    if sum(data[col_name].isna().astype(int)) > 0:\n",
    "        data[col_name].fillna(\"No response\", inplace = True)\n",
    "    \n",
    "    order = list(set(data[col_name]))\n",
    "    convert_to_category(col_name, order, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category_to_code(col_name: str, data, inplace = False):\n",
    "    if inplace:\n",
    "        data[col_name] = data[col_name].cat.codes + 1 # because NaN automatically becomes -1\n",
    "    else:\n",
    "        return data[col_name].cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(col_name: str, order_rules = None, data = salary_data, num_data = salary_data_as_num):\n",
    "    if order_rules:\n",
    "        convert_to_category(col_name, order_rules, data)\n",
    "    else:\n",
    "        convert_to_category_no_specified_order(col_name, data)\n",
    "    num_data[col_name] = convert_category_to_code(col_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_column_to_binary(col_name, data = salary_data):\n",
    "    data[col_name].fillna(0, inplace = True)\n",
    "    data[col_name].mask(data[col_name] != 0, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_hot_encoded_columns(columns, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col in columns:\n",
    "        one_hot_column_to_binary(col, data)\n",
    "        num_data[col] = data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_text_to_binary(col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    data[col_name] = data[col_name].notna().astype(int)\n",
    "    num_data[col_name] = data[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multiple_columns_into_one_binary(columns, new_col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col_name in columns:\n",
    "        one_hot_column_to_binary(col_name)\n",
    "        \n",
    "    data[new_col_name] = data[columns].sum(axis = 1)\n",
    "    data[new_col_name] = data[new_col_name].astype(int)\n",
    "    \n",
    "    data[new_col_name].mask(data[new_col_name] > 0, 1, inplace = True)\n",
    "    num_data[new_col_name] = data[new_col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q24 Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1: original bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q24_order = [\"$0-999\",\n",
    "             '1,000-1,999',\n",
    "             '2,000-2,999',\n",
    "             '3,000-3,999',\n",
    "             '4,000-4,999',\n",
    "             '5,000-7,499',\n",
    "             '7,500-9,999',\n",
    "             '10,000-14,999',\n",
    "             '15,000-19,999',\n",
    "             '20,000-24,999',\n",
    "             '25,000-29,999',\n",
    "             '30,000-39,999',\n",
    "             '40,000-49,999',\n",
    "             '50,000-59,999',\n",
    "              '60,000-69,999',\n",
    "              '70,000-79,999',\n",
    "              '80,000-89,999',\n",
    "              '90,000-99,999',\n",
    "            '100,000-124,999',\n",
    "            '125,000-149,999',\n",
    "            '150,000-199,999',\n",
    "             '200,000-249,999',\n",
    "             '250,000-299,999',\n",
    "              '300,000-500,000',\n",
    "              '> $500,000'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2: numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q24_mapped_to = [\n",
    "    1, #\"$0-999\",\n",
    "    1, #        '1,000-1,999',\n",
    "    1, #         '2,000-2,999',\n",
    "    1, #         '3,000-3,999',\n",
    "    1, #         '4,000-4,999',\n",
    "    1, #        '5,000-7,499',\n",
    "    1, #         '7,500-9,999',\n",
    "    2, #         '10,000-14,999',\n",
    "    2, #         '15,000-19,999',\n",
    "    2, #         '20,000-24,999',\n",
    "    2, #         '25,000-29,999',\n",
    "    2, #         '30,000-39,999',\n",
    "    2, #         '40,000-49,999',\n",
    "    2, #         '50,000-59,999',\n",
    "    2, #          '60,000-69,999',\n",
    "    2, #          '70,000-79,999',\n",
    "    2, #          '80,000-89,999',\n",
    "    2, #          '90,000-99,999',\n",
    "    3, #        '100,000-124,999',\n",
    "    3, #        '125,000-149,999',\n",
    "    3, #        '150,000-199,999',\n",
    "    3, #         '200,000-249,999',\n",
    "    3, #         '250,000-299,999',\n",
    "    3, #          '300,000-500,000',\n",
    "    4 #          '> $500,000'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q24_mapping = dict(zip(q24_order, q24_mapped_to))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        100,000-124,999\n",
       "2          15,000-19,999\n",
       "3        125,000-149,999\n",
       "8          70,000-79,999\n",
       "11         30,000-39,999\n",
       "              ...       \n",
       "20024        2,000-2,999\n",
       "20029      15,000-19,999\n",
       "20033             $0-999\n",
       "20034             $0-999\n",
       "20035             $0-999\n",
       "Name: q24, Length: 10729, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = salary_data[\"q24\"].copy()\n",
    "test_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col = test_col.replace(q24_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data[\"q24\"] = test_col\n",
    "salary_data_as_num[\"q24\"] = test_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "25-29    2350\n",
       "30-34    1979\n",
       "35-39    1467\n",
       "22-24    1424\n",
       "40-44    1042\n",
       "45-49     771\n",
       "50-54     536\n",
       "18-21     498\n",
       "60-69     309\n",
       "55-59     301\n",
       "70         52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_order = [\n",
    "    \"18-21\",\n",
    "    \"22-24\",\n",
    "    \"25-29\",\n",
    "    \"30-34\",\n",
    "    \"35-39\",\n",
    "    \"40-44\",\n",
    "    \"45-49\",\n",
    "    \"50-54\",\n",
    "    \"55-59\",\n",
    "    \"60-69\",\n",
    "    \"70\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q1\", q1_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10729 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1\n",
       "1        3   4\n",
       "2        2   5\n",
       "3        3   4\n",
       "8        2   5\n",
       "11       2   5\n",
       "...    ...  ..\n",
       "20024    1   5\n",
       "20029    2   5\n",
       "20033    1   4\n",
       "20034    1   2\n",
       "20035    1   2\n",
       "\n",
       "[10729 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"] = convert_category_to_code(\"q1\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "3     2350\n",
       "4     1979\n",
       "5     1467\n",
       "2     1424\n",
       "6     1042\n",
       "7      771\n",
       "8      536\n",
       "1      498\n",
       "10     309\n",
       "9      301\n",
       "11      52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "Man                        8872\n",
       "Woman                      1683\n",
       "Prefer not to say           131\n",
       "Prefer to self-describe      23\n",
       "Nonbinary                    20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_order = ['Man', \"Woman\", \"Nonbinary\", 'Prefer to self-describe', 'Prefer not to say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q2\", q2_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20024</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20029</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1  q2\n",
       "1        3   4   1\n",
       "2        2   5   1\n",
       "3        3   4   1\n",
       "8        2   5   1\n",
       "11       2   5   1\n",
       "...    ...  ..  ..\n",
       "20024    1   5   1\n",
       "20029    2   5   1\n",
       "20033    1   4   1\n",
       "20034    1   2   1\n",
       "20035    1   2   1\n",
       "\n",
       "[10729 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"] = convert_category_to_code(\"q2\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "1    8872\n",
       "2    1683\n",
       "5     131\n",
       "4      23\n",
       "3      20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q3\"] = convert_category_to_code(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "Master’s degree                                                      4879\n",
       "Bachelor’s degree                                                    3013\n",
       "Doctoral degree                                                      1718\n",
       "Professional degree                                                   470\n",
       "Some college/university study without earning a bachelor’s degree     385\n",
       "I prefer not to answer                                                158\n",
       "No formal education past high school                                  106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_order = [\"No formal education past high school\",\n",
    "            \"Some college/university study without earning a bachelor’s degree\",\n",
    "            \"Professional degree\",\n",
    "            \"Bachelor’s degree\",\n",
    "            \"Master’s degree\",\n",
    "            \"Doctoral degree\",\n",
    "            \"I prefer not to answer\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q4\", q4_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q4\"] = convert_category_to_code(\"q4\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "5    4879\n",
       "4    3013\n",
       "6    1718\n",
       "3     470\n",
       "2     385\n",
       "7     158\n",
       "1     106\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q5\n",
       "Data Scientist               2398\n",
       "Software Engineer            1620\n",
       "Other                        1508\n",
       "Data Analyst                 1260\n",
       "Research Scientist           1028\n",
       "Machine Learning Engineer     918\n",
       "Business Analyst              678\n",
       "Product/Project Manager       590\n",
       "Data Engineer                 369\n",
       "Statistician                  248\n",
       "DBA/Database Engineer         112\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q5\"] = convert_category_to_code(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Years Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_order = [\n",
    " 'I have never written code',\n",
    " '< 1 years',\n",
    " '1-2 years',\n",
    " '3-5 years',\n",
    " '5-10 years',\n",
    " '10-20 years',\n",
    " '20+ years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q6\", q6_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_columns = [\n",
    "     'q7_part_1',\n",
    " 'q7_part_2',\n",
    " 'q7_part_3',\n",
    " 'q7_part_4',\n",
    " 'q7_part_5',\n",
    " 'q7_part_6',\n",
    " 'q7_part_7',\n",
    " 'q7_part_8',\n",
    " 'q7_part_9',\n",
    " 'q7_part_10',\n",
    " 'q7_part_11',\n",
    " 'q7_part_12',\n",
    " 'q7_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q7_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11 Computing Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12 Specialized Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "q12_columns = [\n",
    "    'q12_part_1',\n",
    " 'q12_part_2',\n",
    " 'q12_part_3',\n",
    " 'q12_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q12_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14_columns = [\n",
    "    'q14_part_1',\n",
    " 'q14_part_2',\n",
    " 'q14_part_3',\n",
    " 'q14_part_4',\n",
    " 'q14_part_5',\n",
    " 'q14_part_6',\n",
    " 'q14_part_7',\n",
    " 'q14_part_8',\n",
    " 'q14_part_9',\n",
    " 'q14_part_10',\n",
    " 'q14_part_11',\n",
    " 'q14_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q14_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15 Years ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15_order = [\n",
    "    'I do not use machine learning methods',\n",
    "    'Under 1 year',\n",
    "    '1-2 years',\n",
    "    '2-3 years',\n",
    "    '3-4 years',\n",
    "    '4-5 years',\n",
    "    '5-10 years',\n",
    "    '10-20 years',\n",
    "    '20 or more years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q15\", q15_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17 ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17_columns = [\n",
    "    'q17_part_1',\n",
    " 'q17_part_2',\n",
    " 'q17_part_3',\n",
    " 'q17_part_4',\n",
    " 'q17_part_5',\n",
    " 'q17_part_6',\n",
    " 'q17_part_7',\n",
    " 'q17_part_8',\n",
    " 'q17_part_9',\n",
    " 'q17_part_10',\n",
    " 'q17_part_11',\n",
    " 'q17_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q17_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q20 Company Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20_order = [\n",
    "    '0-49 employees',\n",
    "    '50-249 employees',\n",
    "    '250-999 employees',\n",
    "    '1000-9,999 employees',\n",
    "    '10,000 or more employees'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q20\", q20_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q21 Datascience Workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "q21_order = [\n",
    "    '0',\n",
    "    '1-2',\n",
    "    '3-4',\n",
    "    '5-9',\n",
    "    '10-14',\n",
    "    '15-19',\n",
    "    '20'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q21\", q21_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q22 Incorporating ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'm not super sure about the proper \"order\" for this question. Feel free to change this if you find it more appropriate. Just please let the chat know in case it affects others' encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "q22_order = [\n",
    "    'I do not know',\n",
    "    'No (we do not use ML methods)',\n",
    "    'We are exploring ML methods (and may one day put a model into production)',\n",
    "    'We use ML methods for generating insights (but do not put working models into production)',\n",
    "    'We recently started using ML methods (i.e., models in production for less than 2 years)',\n",
    "    'We have well established ML methods (i.e., models in production for more than 2 years)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q22\", q22_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q30 Big Data Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q32 Business Intelligence Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q33 Automated ML Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "q33_columns = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_multiple_columns_into_one_binary(q33_columns, \"q33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q37 Data Science Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "q37_columns = [\n",
    "    'q37_part_1',\n",
    " 'q37_part_2',\n",
    " 'q37_part_3',\n",
    " 'q37_part_4',\n",
    " 'q37_part_5',\n",
    " 'q37_part_6',\n",
    " 'q37_part_7',\n",
    " 'q37_part_8',\n",
    " 'q37_part_9',\n",
    " 'q37_part_10',\n",
    " 'q37_part_11',\n",
    " 'q37_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q37_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q38 Primary Data Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q39 Media Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "q39_columns = [\n",
    "    'q39_part_1',\n",
    " 'q39_part_2',\n",
    " 'q39_part_3',\n",
    " 'q39_part_4',\n",
    " 'q39_part_5',\n",
    " 'q39_part_6',\n",
    " 'q39_part_7',\n",
    " 'q39_part_8',\n",
    " 'q39_part_9',\n",
    " 'q39_part_10',\n",
    " 'q39_part_11',\n",
    " 'q39_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q39_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropped Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dropped = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_questions = [\n",
    "    \"q8\",\n",
    "    'q9_part_1',\n",
    " 'q9_part_2',\n",
    " 'q9_part_3',\n",
    " 'q9_part_4',\n",
    " 'q9_part_5',\n",
    " 'q9_part_6',\n",
    " 'q9_part_7',\n",
    " 'q9_part_8',\n",
    " 'q9_part_9',\n",
    " 'q9_part_10',\n",
    " 'q9_part_11',\n",
    " 'q9_other',\n",
    " 'q10_part_1',\n",
    " 'q10_part_2',\n",
    " 'q10_part_3',\n",
    " 'q10_part_4',\n",
    " 'q10_part_5',\n",
    " 'q10_part_6',\n",
    " 'q10_part_7',\n",
    " 'q10_part_8',\n",
    " 'q10_part_9',\n",
    " 'q10_part_10',\n",
    " 'q10_part_11',\n",
    " 'q10_part_12',\n",
    " 'q10_part_13',\n",
    " 'q10_other',\n",
    " \"q13\",\n",
    " 'q16_part_1',\n",
    " 'q16_part_2',\n",
    " 'q16_part_3',\n",
    " 'q16_part_4',\n",
    " 'q16_part_5',\n",
    " 'q16_part_6',\n",
    " 'q16_part_7',\n",
    " 'q16_part_8',\n",
    " 'q16_part_9',\n",
    " 'q16_part_10',\n",
    " 'q16_part_11',\n",
    " 'q16_part_12',\n",
    " 'q16_part_13',\n",
    " 'q16_part_14',\n",
    " 'q16_part_15',\n",
    " 'q16_other',\n",
    " 'q18_part_1',\n",
    " 'q18_part_2',\n",
    " 'q18_part_3',\n",
    " 'q18_part_4',\n",
    " 'q18_part_5',\n",
    " 'q18_part_6',\n",
    " 'q18_other',\n",
    " 'q19_part_1',\n",
    " 'q19_part_2',\n",
    " 'q19_part_3',\n",
    " 'q19_part_4',\n",
    " 'q19_part_5',\n",
    " 'q19_other',\n",
    " 'q23_part_1',\n",
    " 'q23_part_2',\n",
    " 'q23_part_3',\n",
    " 'q23_part_4',\n",
    " 'q23_part_5',\n",
    " 'q23_part_6',\n",
    " 'q23_part_7',\n",
    " 'q23_other',\n",
    " 'q25',\n",
    " 'q26_a_part_1',\n",
    " 'q26_a_part_2',\n",
    " 'q26_a_part_3',\n",
    " 'q26_a_part_4',\n",
    " 'q26_a_part_5',\n",
    " 'q26_a_part_6',\n",
    " 'q26_a_part_7',\n",
    " 'q26_a_part_8',\n",
    " 'q26_a_part_9',\n",
    " 'q26_a_part_10',\n",
    " 'q26_a_part_11',\n",
    " 'q26_a_other',\n",
    " 'q27_a_part_1',\n",
    " 'q27_a_part_2',\n",
    " 'q27_a_part_3',\n",
    " 'q27_a_part_4',\n",
    " 'q27_a_part_5',\n",
    " 'q27_a_part_6',\n",
    " 'q27_a_part_7',\n",
    " 'q27_a_part_8',\n",
    " 'q27_a_part_9',\n",
    " 'q27_a_part_10',\n",
    " 'q27_a_part_11',\n",
    " 'q27_a_other',\n",
    " 'q28_a_part_1',\n",
    " 'q28_a_part_2',\n",
    " 'q28_a_part_3',\n",
    " 'q28_a_part_4',\n",
    " 'q28_a_part_5',\n",
    " 'q28_a_part_6',\n",
    " 'q28_a_part_7',\n",
    " 'q28_a_part_8',\n",
    " 'q28_a_part_9',\n",
    " 'q28_a_part_10',\n",
    " 'q28_a_other',\n",
    " 'q29_a_part_1',\n",
    " 'q29_a_part_2',\n",
    " 'q29_a_part_3',\n",
    " 'q29_a_part_4',\n",
    " 'q29_a_part_5',\n",
    " 'q29_a_part_6',\n",
    " 'q29_a_part_7',\n",
    " 'q29_a_part_8',\n",
    " 'q29_a_part_9',\n",
    " 'q29_a_part_10',\n",
    " 'q29_a_part_11',\n",
    " 'q29_a_part_12',\n",
    " 'q29_a_part_13',\n",
    " 'q29_a_part_14',\n",
    " 'q29_a_part_15',\n",
    " 'q29_a_part_16',\n",
    " 'q29_a_part_17',\n",
    " 'q29_a_other',\n",
    " 'q31_a_part_1',\n",
    " 'q31_a_part_2',\n",
    " 'q31_a_part_3',\n",
    " 'q31_a_part_4',\n",
    " 'q31_a_part_5',\n",
    " 'q31_a_part_6',\n",
    " 'q31_a_part_7',\n",
    " 'q31_a_part_8',\n",
    " 'q31_a_part_9',\n",
    " 'q31_a_part_10',\n",
    " 'q31_a_part_11',\n",
    " 'q31_a_part_12',\n",
    " 'q31_a_part_13',\n",
    " 'q31_a_part_14',\n",
    " 'q31_a_other',\n",
    " 'q34_a_part_1',\n",
    " 'q34_a_part_2',\n",
    " 'q34_a_part_3',\n",
    " 'q34_a_part_4',\n",
    " 'q34_a_part_5',\n",
    " 'q34_a_part_6',\n",
    " 'q34_a_part_7',\n",
    " 'q34_a_part_8',\n",
    " 'q34_a_part_9',\n",
    " 'q34_a_part_10',\n",
    " 'q34_a_part_11',\n",
    " 'q34_a_other',\n",
    " 'q35_a_part_1',\n",
    " 'q35_a_part_2',\n",
    " 'q35_a_part_3',\n",
    " 'q35_a_part_4',\n",
    " 'q35_a_part_5',\n",
    " 'q35_a_part_6',\n",
    " 'q35_a_part_7',\n",
    " 'q35_a_part_8',\n",
    " 'q35_a_part_9',\n",
    " 'q35_a_part_10',\n",
    " 'q35_a_other',\n",
    " 'q36_part_1',\n",
    " 'q36_part_2',\n",
    " 'q36_part_3',\n",
    " 'q36_part_4',\n",
    " 'q36_part_5',\n",
    " 'q36_part_6',\n",
    " 'q36_part_7',\n",
    " 'q36_part_8',\n",
    " 'q36_part_9',\n",
    " 'q36_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_b_dropped = [\n",
    "    'q26_b_part_1',\n",
    " 'q26_b_part_2',\n",
    " 'q26_b_part_3',\n",
    " 'q26_b_part_4',\n",
    " 'q26_b_part_5',\n",
    " 'q26_b_part_6',\n",
    " 'q26_b_part_7',\n",
    " 'q26_b_part_8',\n",
    " 'q26_b_part_9',\n",
    " 'q26_b_part_10',\n",
    " 'q26_b_part_11',\n",
    " 'q26_b_other',\n",
    " 'q27_b_part_1',\n",
    " 'q27_b_part_2',\n",
    " 'q27_b_part_3',\n",
    " 'q27_b_part_4',\n",
    " 'q27_b_part_5',\n",
    " 'q27_b_part_6',\n",
    " 'q27_b_part_7',\n",
    " 'q27_b_part_8',\n",
    " 'q27_b_part_9',\n",
    " 'q27_b_part_10',\n",
    " 'q27_b_part_11',\n",
    " 'q27_b_other',\n",
    " 'q28_b_part_1',\n",
    " 'q28_b_part_2',\n",
    " 'q28_b_part_3',\n",
    " 'q28_b_part_4',\n",
    " 'q28_b_part_5',\n",
    " 'q28_b_part_6',\n",
    " 'q28_b_part_7',\n",
    " 'q28_b_part_8',\n",
    " 'q28_b_part_9',\n",
    " 'q28_b_part_10',\n",
    " 'q28_b_other',\n",
    " 'q29_b_part_1',\n",
    " 'q29_b_part_2',\n",
    " 'q29_b_part_3',\n",
    " 'q29_b_part_4',\n",
    " 'q29_b_part_5',\n",
    " 'q29_b_part_6',\n",
    " 'q29_b_part_7',\n",
    " 'q29_b_part_8',\n",
    " 'q29_b_part_9',\n",
    " 'q29_b_part_10',\n",
    " 'q29_b_part_11',\n",
    " 'q29_b_part_12',\n",
    " 'q29_b_part_13',\n",
    " 'q29_b_part_14',\n",
    " 'q29_b_part_15',\n",
    " 'q29_b_part_16',\n",
    " 'q29_b_part_17',\n",
    " 'q29_b_other',\n",
    " 'q31_b_part_1',\n",
    " 'q31_b_part_2',\n",
    " 'q31_b_part_3',\n",
    " 'q31_b_part_4',\n",
    " 'q31_b_part_5',\n",
    " 'q31_b_part_6',\n",
    " 'q31_b_part_7',\n",
    " 'q31_b_part_8',\n",
    " 'q31_b_part_9',\n",
    " 'q31_b_part_10',\n",
    " 'q31_b_part_11',\n",
    " 'q31_b_part_12',\n",
    " 'q31_b_part_13',\n",
    " 'q31_b_part_14',\n",
    " 'q31_b_other',\n",
    " 'q33_b_part_1',\n",
    " 'q33_b_part_2',\n",
    " 'q33_b_part_3',\n",
    " 'q33_b_part_4',\n",
    " 'q33_b_part_5',\n",
    " 'q33_b_part_6',\n",
    " 'q33_b_part_7',\n",
    " 'q33_b_other',\n",
    " 'q34_b_part_1',\n",
    " 'q34_b_part_2',\n",
    " 'q34_b_part_3',\n",
    " 'q34_b_part_4',\n",
    " 'q34_b_part_5',\n",
    " 'q34_b_part_6',\n",
    " 'q34_b_part_7',\n",
    " 'q34_b_part_8',\n",
    " 'q34_b_part_9',\n",
    " 'q34_b_part_10',\n",
    " 'q34_b_part_11',\n",
    " 'q34_b_other',\n",
    " 'q35_b_part_1',\n",
    " 'q35_b_part_2',\n",
    " 'q35_b_part_3',\n",
    " 'q35_b_part_4',\n",
    " 'q35_b_part_5',\n",
    " 'q35_b_part_6',\n",
    " 'q35_b_part_7',\n",
    " 'q35_b_part_8',\n",
    " 'q35_b_part_9',\n",
    " 'q35_b_part_10',\n",
    " 'q35_b_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = one_hot_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = part_b_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_selected_questions = salary_data.drop(columns = dropped_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salary_data_as_num.drop(columns = [\"q24\"])\n",
    "y = salary_data_as_num[\"q24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        3\n",
       "2        2\n",
       "3        3\n",
       "8        2\n",
       "11       2\n",
       "        ..\n",
       "20024    1\n",
       "20029    2\n",
       "20033    1\n",
       "20034    1\n",
       "20035    1\n",
       "Name: q24, Length: 10729, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_test, y_dev, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 11:48:18.002810: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-29 11:48:18.002845: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-11-29 11:48:18.002859: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-11-29 11:48:18.003322: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-29 11:48:18.003747: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x_dev = tf.convert_to_tensor(x_dev.astype(\"int64\"))\n",
    "x_test = tf.convert_to_tensor(x_test.astype(\"int64\"))\n",
    "y_dev = tf.convert_to_tensor(y_dev.astype(\"int64\"))\n",
    "y_test = tf.convert_to_tensor(y_test.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    \n",
    "    def __init__(self, x_dev = x_dev, y_dev = y_dev, x_test = x_test, y_test = y_test):\n",
    "        self.x_dev = x_dev\n",
    "        self.y_dev = y_dev\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.layers = [Dense(32, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "        self.optimizer = \"adam\"\n",
    "        self.loss = \"sparse_categorical_crossentropy\"\n",
    "        self.metrics =  [\"accuracy\"]\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.epochs = 50\n",
    "        \n",
    "    def customize_first_layer(self, node_count = 32):\n",
    "        self.layers = [Dense(node_count, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "    def add_one_dense_layer(self, node_count = 32):\n",
    "        self.layers.append(Dense(node_count, activation = \"relu\"))\n",
    "        \n",
    "    def customize_middle_layers(self, layers):\n",
    "        self.layers.extend(layers)\n",
    "    \n",
    "    def customize_compile(self,\n",
    "                          optimizer = \"adam\",\n",
    "                          loss = \"sparse_categorical_crossentropy\",\n",
    "                          metrics = [\"accuracy\"]):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def customize_fit(self,\n",
    "                      batch_size = 100,\n",
    "                      epochs = 50\n",
    "                      ):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def build_compile_and_evaluate(self, metric_to_return = \"accuracy\", selection_criteria = max):\n",
    "        # final layer must be softmax and outputs 26\n",
    "        self.layers.append(Dense(26, activation = \"softmax\"))\n",
    "        \n",
    "        self.model = Sequential(self.layers)\n",
    "        self.model.compile(optimizer = self.optimizer,\n",
    "                      loss = self.loss,\n",
    "                      metrics = self.metrics)\n",
    "        fit_history = self.model.fit(self.x_dev, self.y_dev,\n",
    "                                batch_size = self.batch_size,\n",
    "                                epochs = self.epochs,\n",
    "                                validation_split = 0.2,\n",
    "                                verbose = 1\n",
    "                                )\n",
    "        self.fit_history = pd.DataFrame(fit_history.history)\n",
    "        return selection_criteria(self.fit_history[metric_to_return])\n",
    "        #return self.fit_history\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    def get_fit_history(self):\n",
    "        return self.fit_history\n",
    "        \n",
    "    def evaluate_model_with_test(self):\n",
    "        return self.model.evaluate(self.x_test, self.y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 1.7321 - accuracy: 0.3956 - val_loss: 1.0675 - val_accuracy: 0.4834\n",
      "Epoch 2/2\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9991 - accuracy: 0.5214 - val_loss: 0.9653 - val_accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5214098691940308"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = DNN()\n",
    "d.customize_fit(epochs = 2)\n",
    "d.add_one_dense_layer()\n",
    "d.build_compile_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layer Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- building model for layer width of 256 and 256\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 1.2082 - accuracy: 0.5140 - val_loss: 1.0148 - val_accuracy: 0.5166\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9008 - accuracy: 0.5810 - val_loss: 0.9584 - val_accuracy: 0.5376\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9056 - accuracy: 0.5810 - val_loss: 0.9074 - val_accuracy: 0.6034\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9351 - accuracy: 0.5881 - val_loss: 0.9232 - val_accuracy: 0.5719\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0716 - accuracy: 0.5454 - val_loss: 1.1690 - val_accuracy: 0.5055\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1331 - accuracy: 0.5580 - val_loss: 0.9356 - val_accuracy: 0.5842\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.0172 - accuracy: 0.5676 - val_loss: 1.1999 - val_accuracy: 0.5521\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.1144 - accuracy: 0.5523 - val_loss: 1.1711 - val_accuracy: 0.5259\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0732 - accuracy: 0.5147 - val_loss: 0.9446 - val_accuracy: 0.6034\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.1966 - accuracy: 0.5663 - val_loss: 1.9442 - val_accuracy: 0.4863\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.8443 - accuracy: 0.5293 - val_loss: 2.1523 - val_accuracy: 0.5911\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4633 - accuracy: 0.5427 - val_loss: 1.4295 - val_accuracy: 0.4857\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6101 - accuracy: 0.5393 - val_loss: 1.2445 - val_accuracy: 0.5795\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.8803 - accuracy: 0.5331 - val_loss: 1.5408 - val_accuracy: 0.5178\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.3749 - accuracy: 0.5312 - val_loss: 2.1503 - val_accuracy: 0.6057\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7170 - accuracy: 0.5501 - val_loss: 1.8064 - val_accuracy: 0.5009\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.4275 - accuracy: 0.5172 - val_loss: 2.6882 - val_accuracy: 0.4327\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7285 - accuracy: 0.5486 - val_loss: 1.2850 - val_accuracy: 0.5329\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.1212 - accuracy: 0.5251 - val_loss: 1.2893 - val_accuracy: 0.5952\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.5197 - accuracy: 0.5243 - val_loss: 2.1840 - val_accuracy: 0.5411\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.3724 - accuracy: 0.5242 - val_loss: 1.7085 - val_accuracy: 0.5725\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.5747 - accuracy: 0.5306 - val_loss: 1.5367 - val_accuracy: 0.5760\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.4066 - accuracy: 0.5313 - val_loss: 2.0442 - val_accuracy: 0.4554\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.9323 - accuracy: 0.5501 - val_loss: 3.4217 - val_accuracy: 0.4758\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.5065 - accuracy: 0.5315 - val_loss: 1.8049 - val_accuracy: 0.3995\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7079 - accuracy: 0.5320 - val_loss: 2.6505 - val_accuracy: 0.4572\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.2509 - accuracy: 0.5318 - val_loss: 1.8551 - val_accuracy: 0.5783\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.7215 - accuracy: 0.5564 - val_loss: 1.9596 - val_accuracy: 0.5416\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7374 - accuracy: 0.5291 - val_loss: 2.1852 - val_accuracy: 0.3821\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.7540 - accuracy: 0.5335 - val_loss: 6.3348 - val_accuracy: 0.3442\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.8586 - accuracy: 0.5248 - val_loss: 4.1524 - val_accuracy: 0.4438\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.8939 - accuracy: 0.5360 - val_loss: 1.8659 - val_accuracy: 0.5795\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8786 - accuracy: 0.5271 - val_loss: 2.1628 - val_accuracy: 0.4607\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 4.7245 - accuracy: 0.5050 - val_loss: 3.6058 - val_accuracy: 0.5224\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.4528 - accuracy: 0.5393 - val_loss: 3.2124 - val_accuracy: 0.5545\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 5.0552 - accuracy: 0.5061 - val_loss: 2.9976 - val_accuracy: 0.5783\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 4.2125 - accuracy: 0.5342 - val_loss: 3.4367 - val_accuracy: 0.4444\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9858 - accuracy: 0.5331 - val_loss: 2.5768 - val_accuracy: 0.4834\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4252 - accuracy: 0.5236 - val_loss: 5.0850 - val_accuracy: 0.4601\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.9629 - accuracy: 0.5355 - val_loss: 2.6408 - val_accuracy: 0.5265\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 4.6272 - accuracy: 0.5248 - val_loss: 5.3425 - val_accuracy: 0.4554\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.2800 - accuracy: 0.5223 - val_loss: 2.5188 - val_accuracy: 0.5859\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.1034 - accuracy: 0.5259 - val_loss: 4.7931 - val_accuracy: 0.4881\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.1659 - accuracy: 0.5272 - val_loss: 5.7474 - val_accuracy: 0.5055\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 6.0537 - accuracy: 0.5147 - val_loss: 9.4806 - val_accuracy: 0.4281\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.1145 - accuracy: 0.5111 - val_loss: 2.1698 - val_accuracy: 0.5952\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.8961 - accuracy: 0.5291 - val_loss: 3.0658 - val_accuracy: 0.5655\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.2393 - accuracy: 0.5210 - val_loss: 6.4783 - val_accuracy: 0.5579\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.3761 - accuracy: 0.5249 - val_loss: 10.3452 - val_accuracy: 0.4688\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.5261 - accuracy: 0.5267 - val_loss: 3.0735 - val_accuracy: 0.5189\n",
      "---- building model for layer width of 16 and 2048\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 18ms/step - loss: 1.0444 - accuracy: 0.5408 - val_loss: 0.9205 - val_accuracy: 0.5492\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9629 - accuracy: 0.5581 - val_loss: 0.8929 - val_accuracy: 0.5906\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9180 - accuracy: 0.5826 - val_loss: 0.8759 - val_accuracy: 0.5964\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8853 - accuracy: 0.5928 - val_loss: 0.9461 - val_accuracy: 0.5894\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9262 - accuracy: 0.5804 - val_loss: 0.8676 - val_accuracy: 0.6109\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9308 - accuracy: 0.5747 - val_loss: 1.2303 - val_accuracy: 0.4916\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0917 - accuracy: 0.5664 - val_loss: 0.9148 - val_accuracy: 0.6179\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9777 - accuracy: 0.5706 - val_loss: 1.1855 - val_accuracy: 0.5312\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.3985 - accuracy: 0.5329 - val_loss: 1.1972 - val_accuracy: 0.5574\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.3976 - accuracy: 0.5393 - val_loss: 1.1561 - val_accuracy: 0.6325\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5595 - accuracy: 0.5479 - val_loss: 1.0667 - val_accuracy: 0.5847\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2620 - accuracy: 0.5475 - val_loss: 1.2671 - val_accuracy: 0.4386\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2250 - accuracy: 0.5603 - val_loss: 2.1538 - val_accuracy: 0.5364\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.3283 - accuracy: 0.5401 - val_loss: 1.4333 - val_accuracy: 0.4834\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.2871 - accuracy: 0.5090 - val_loss: 1.8967 - val_accuracy: 0.4985\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.3956 - accuracy: 0.5484 - val_loss: 1.5026 - val_accuracy: 0.4589\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.8790 - accuracy: 0.5038 - val_loss: 1.5884 - val_accuracy: 0.5486\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.1844 - accuracy: 0.5307 - val_loss: 2.5463 - val_accuracy: 0.5807\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 1.7573 - accuracy: 0.5456 - val_loss: 1.4577 - val_accuracy: 0.5568\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.3989 - accuracy: 0.5520 - val_loss: 1.4870 - val_accuracy: 0.5207\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.8454 - accuracy: 0.5291 - val_loss: 1.7932 - val_accuracy: 0.5480\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7672 - accuracy: 0.5435 - val_loss: 1.5225 - val_accuracy: 0.5981\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0401 - accuracy: 0.5406 - val_loss: 2.1477 - val_accuracy: 0.5312\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7462 - accuracy: 0.5086 - val_loss: 2.1904 - val_accuracy: 0.5504\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6905 - accuracy: 0.5495 - val_loss: 1.3709 - val_accuracy: 0.5807\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.7024 - accuracy: 0.5473 - val_loss: 1.2713 - val_accuracy: 0.5743\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.2687 - accuracy: 0.5118 - val_loss: 2.5337 - val_accuracy: 0.5853\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.1674 - accuracy: 0.5414 - val_loss: 3.0361 - val_accuracy: 0.5061\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.2225 - accuracy: 0.5335 - val_loss: 2.1741 - val_accuracy: 0.4572\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.2895 - accuracy: 0.5440 - val_loss: 1.7142 - val_accuracy: 0.5958\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.2409 - accuracy: 0.5304 - val_loss: 3.0898 - val_accuracy: 0.4723\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.9992 - accuracy: 0.5446 - val_loss: 1.1153 - val_accuracy: 0.5970\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0291 - accuracy: 0.5409 - val_loss: 2.3560 - val_accuracy: 0.4782\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9181 - accuracy: 0.5105 - val_loss: 1.8568 - val_accuracy: 0.4653\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.6578 - accuracy: 0.5248 - val_loss: 1.7828 - val_accuracy: 0.6109\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.8105 - accuracy: 0.5288 - val_loss: 2.9593 - val_accuracy: 0.5288\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.4878 - accuracy: 0.5272 - val_loss: 3.4902 - val_accuracy: 0.5207\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.4356 - accuracy: 0.5277 - val_loss: 3.0719 - val_accuracy: 0.5766\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.6115 - accuracy: 0.5655 - val_loss: 1.4953 - val_accuracy: 0.4991\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.3916 - accuracy: 0.5309 - val_loss: 2.5773 - val_accuracy: 0.5550\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.2661 - accuracy: 0.5265 - val_loss: 1.7955 - val_accuracy: 0.5288\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.5591 - accuracy: 0.5137 - val_loss: 3.8558 - val_accuracy: 0.5166\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.0452 - accuracy: 0.5232 - val_loss: 3.2832 - val_accuracy: 0.4846\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 3.4723 - accuracy: 0.5153 - val_loss: 4.6508 - val_accuracy: 0.5149\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 3.0543 - accuracy: 0.5236 - val_loss: 6.0528 - val_accuracy: 0.5812\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.6699 - accuracy: 0.5233 - val_loss: 2.1853 - val_accuracy: 0.5702\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.6264 - accuracy: 0.5280 - val_loss: 4.4797 - val_accuracy: 0.4589\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.6925 - accuracy: 0.5159 - val_loss: 9.4626 - val_accuracy: 0.4327\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 4.5071 - accuracy: 0.5204 - val_loss: 2.9836 - val_accuracy: 0.5207\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1626 - accuracy: 0.5201 - val_loss: 2.0032 - val_accuracy: 0.4863\n",
      "---- building model for layer width of 4 and 8\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 13ms/step - loss: 3.2234 - accuracy: 0.2250 - val_loss: 2.1698 - val_accuracy: 0.4123\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6257 - accuracy: 0.4747 - val_loss: 1.3118 - val_accuracy: 0.4694\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.1901 - accuracy: 0.4968 - val_loss: 1.1156 - val_accuracy: 0.4822\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.0717 - accuracy: 0.5047 - val_loss: 1.0389 - val_accuracy: 0.4892\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0194 - accuracy: 0.5165 - val_loss: 1.0021 - val_accuracy: 0.5020\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.9931 - accuracy: 0.5198 - val_loss: 0.9811 - val_accuracy: 0.5067\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.9778 - accuracy: 0.5226 - val_loss: 0.9687 - val_accuracy: 0.5189\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9698 - accuracy: 0.5236 - val_loss: 0.9606 - val_accuracy: 0.5131\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9615 - accuracy: 0.5240 - val_loss: 0.9540 - val_accuracy: 0.5114\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9584 - accuracy: 0.5262 - val_loss: 0.9500 - val_accuracy: 0.5218\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9552 - accuracy: 0.5240 - val_loss: 0.9463 - val_accuracy: 0.5213\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9524 - accuracy: 0.5278 - val_loss: 0.9441 - val_accuracy: 0.5300\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.9492 - accuracy: 0.5293 - val_loss: 0.9408 - val_accuracy: 0.5282\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9486 - accuracy: 0.5293 - val_loss: 0.9397 - val_accuracy: 0.5341\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.9487 - accuracy: 0.5284 - val_loss: 0.9408 - val_accuracy: 0.5242\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9483 - accuracy: 0.5297 - val_loss: 0.9383 - val_accuracy: 0.5306\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.9487 - accuracy: 0.5261 - val_loss: 0.9390 - val_accuracy: 0.5329\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.9498 - accuracy: 0.5252 - val_loss: 0.9417 - val_accuracy: 0.5370\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9538 - accuracy: 0.5232 - val_loss: 0.9428 - val_accuracy: 0.5381\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.9505 - accuracy: 0.5237 - val_loss: 0.9353 - val_accuracy: 0.5422\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.9477 - accuracy: 0.5256 - val_loss: 0.9349 - val_accuracy: 0.5387\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.9460 - accuracy: 0.5224 - val_loss: 0.9308 - val_accuracy: 0.5294\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9406 - accuracy: 0.5274 - val_loss: 0.9296 - val_accuracy: 0.5381\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9405 - accuracy: 0.5233 - val_loss: 0.9264 - val_accuracy: 0.5352\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9370 - accuracy: 0.5207 - val_loss: 0.9273 - val_accuracy: 0.5393\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.9402 - accuracy: 0.5181 - val_loss: 0.9273 - val_accuracy: 0.5457\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.9397 - accuracy: 0.5255 - val_loss: 0.9269 - val_accuracy: 0.5422\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.9409 - accuracy: 0.5239 - val_loss: 0.9284 - val_accuracy: 0.5416\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9407 - accuracy: 0.5230 - val_loss: 0.9285 - val_accuracy: 0.5451\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.9392 - accuracy: 0.5339 - val_loss: 0.9289 - val_accuracy: 0.5475\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9362 - accuracy: 0.5401 - val_loss: 0.9255 - val_accuracy: 0.5457\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9307 - accuracy: 0.5472 - val_loss: 0.9231 - val_accuracy: 0.5510\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9225 - accuracy: 0.5629 - val_loss: 0.9141 - val_accuracy: 0.5789\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9127 - accuracy: 0.5814 - val_loss: 0.9040 - val_accuracy: 0.5935\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9026 - accuracy: 0.5919 - val_loss: 0.8992 - val_accuracy: 0.5894\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8948 - accuracy: 0.5957 - val_loss: 0.8929 - val_accuracy: 0.6016\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8870 - accuracy: 0.6089 - val_loss: 0.8805 - val_accuracy: 0.5941\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8785 - accuracy: 0.6052 - val_loss: 0.8775 - val_accuracy: 0.6063\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8697 - accuracy: 0.6081 - val_loss: 0.8716 - val_accuracy: 0.6139\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8629 - accuracy: 0.6200 - val_loss: 0.8622 - val_accuracy: 0.6109\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8564 - accuracy: 0.6238 - val_loss: 0.8597 - val_accuracy: 0.6220\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 0.8536 - accuracy: 0.6228 - val_loss: 0.8612 - val_accuracy: 0.5952\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8490 - accuracy: 0.6258 - val_loss: 0.8597 - val_accuracy: 0.6278\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8416 - accuracy: 0.6376 - val_loss: 0.8435 - val_accuracy: 0.6080\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8373 - accuracy: 0.6305 - val_loss: 0.8415 - val_accuracy: 0.6255\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8339 - accuracy: 0.6382 - val_loss: 0.8386 - val_accuracy: 0.6150\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8294 - accuracy: 0.6330 - val_loss: 0.8355 - val_accuracy: 0.6319\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8275 - accuracy: 0.6382 - val_loss: 0.8318 - val_accuracy: 0.6255\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8277 - accuracy: 0.6343 - val_loss: 0.8333 - val_accuracy: 0.6267\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8260 - accuracy: 0.6366 - val_loss: 0.8342 - val_accuracy: 0.6331\n",
      "---- building model for layer width of 32 and 2048\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 1.0692 - accuracy: 0.5204 - val_loss: 0.9730 - val_accuracy: 0.5160\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9355 - accuracy: 0.5536 - val_loss: 0.8700 - val_accuracy: 0.6063\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9723 - accuracy: 0.5574 - val_loss: 0.9548 - val_accuracy: 0.5754\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9507 - accuracy: 0.5654 - val_loss: 1.0119 - val_accuracy: 0.5416\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9895 - accuracy: 0.5575 - val_loss: 1.5865 - val_accuracy: 0.4549\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0438 - accuracy: 0.5728 - val_loss: 0.8682 - val_accuracy: 0.6255\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.0502 - accuracy: 0.5661 - val_loss: 0.9170 - val_accuracy: 0.5894\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.1113 - accuracy: 0.5669 - val_loss: 1.3038 - val_accuracy: 0.5597\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5139 - accuracy: 0.5424 - val_loss: 1.5489 - val_accuracy: 0.5067\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2190 - accuracy: 0.5636 - val_loss: 0.9682 - val_accuracy: 0.5795\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1419 - accuracy: 0.5728 - val_loss: 0.9879 - val_accuracy: 0.5416\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2619 - accuracy: 0.5724 - val_loss: 1.6237 - val_accuracy: 0.5096\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5143 - accuracy: 0.5303 - val_loss: 1.0173 - val_accuracy: 0.5987\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6957 - accuracy: 0.5304 - val_loss: 1.7574 - val_accuracy: 0.4974\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.3387 - accuracy: 0.5208 - val_loss: 1.3086 - val_accuracy: 0.5964\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.3367 - accuracy: 0.5650 - val_loss: 1.2288 - val_accuracy: 0.5253\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.9198 - accuracy: 0.5334 - val_loss: 2.0390 - val_accuracy: 0.4665\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.7997 - accuracy: 0.5277 - val_loss: 2.0336 - val_accuracy: 0.5597\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 3s 40ms/step - loss: 1.4822 - accuracy: 0.5609 - val_loss: 2.2154 - val_accuracy: 0.5300\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 2.4655 - accuracy: 0.5176 - val_loss: 2.0820 - val_accuracy: 0.4752\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 1.9195 - accuracy: 0.5338 - val_loss: 1.3104 - val_accuracy: 0.5725\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.6203 - accuracy: 0.5392 - val_loss: 2.8148 - val_accuracy: 0.4584\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0754 - accuracy: 0.5293 - val_loss: 1.3451 - val_accuracy: 0.5125\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5365 - accuracy: 0.5415 - val_loss: 1.4979 - val_accuracy: 0.4589\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.6622 - accuracy: 0.5387 - val_loss: 2.4488 - val_accuracy: 0.5725\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0436 - accuracy: 0.5371 - val_loss: 2.2808 - val_accuracy: 0.5579\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.7614 - accuracy: 0.5342 - val_loss: 3.2078 - val_accuracy: 0.5603\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.3323 - accuracy: 0.5379 - val_loss: 1.5189 - val_accuracy: 0.5568\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6239 - accuracy: 0.5615 - val_loss: 1.8597 - val_accuracy: 0.4426\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.9588 - accuracy: 0.5154 - val_loss: 2.9302 - val_accuracy: 0.4956\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.3051 - accuracy: 0.5285 - val_loss: 1.6534 - val_accuracy: 0.5638\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0877 - accuracy: 0.5355 - val_loss: 2.9399 - val_accuracy: 0.5125\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.9319 - accuracy: 0.5355 - val_loss: 2.6060 - val_accuracy: 0.5591\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8669 - accuracy: 0.5252 - val_loss: 2.1358 - val_accuracy: 0.4205\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.1052 - accuracy: 0.5277 - val_loss: 1.1086 - val_accuracy: 0.6226\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 2.3511 - accuracy: 0.5323 - val_loss: 2.3678 - val_accuracy: 0.5475\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.0209 - accuracy: 0.5392 - val_loss: 5.6136 - val_accuracy: 0.5743\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 4.6710 - accuracy: 0.5137 - val_loss: 3.4338 - val_accuracy: 0.4688\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9871 - accuracy: 0.5316 - val_loss: 2.0719 - val_accuracy: 0.4712\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.8094 - accuracy: 0.5198 - val_loss: 2.3724 - val_accuracy: 0.6092\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.2473 - accuracy: 0.5268 - val_loss: 2.3215 - val_accuracy: 0.4793\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 3.1452 - accuracy: 0.5294 - val_loss: 6.1886 - val_accuracy: 0.5679\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.7021 - accuracy: 0.5195 - val_loss: 3.2342 - val_accuracy: 0.5416\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4025 - accuracy: 0.5221 - val_loss: 2.3251 - val_accuracy: 0.6092\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.9108 - accuracy: 0.5304 - val_loss: 4.0863 - val_accuracy: 0.6075\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.2853 - accuracy: 0.5417 - val_loss: 3.8792 - val_accuracy: 0.4723\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 3.2792 - accuracy: 0.5274 - val_loss: 1.4812 - val_accuracy: 0.5987\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 5.7372 - accuracy: 0.5064 - val_loss: 8.5306 - val_accuracy: 0.3256\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.3642 - accuracy: 0.5146 - val_loss: 2.1743 - val_accuracy: 0.6115\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.3157 - accuracy: 0.5173 - val_loss: 2.0161 - val_accuracy: 0.5271\n",
      "---- building model for layer width of 32 and 64\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 13ms/step - loss: 2.4244 - accuracy: 0.4447 - val_loss: 1.0396 - val_accuracy: 0.4834\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9808 - accuracy: 0.5077 - val_loss: 0.9401 - val_accuracy: 0.5306\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9133 - accuracy: 0.5641 - val_loss: 0.9529 - val_accuracy: 0.5300\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8772 - accuracy: 0.5897 - val_loss: 0.8740 - val_accuracy: 0.5871\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8548 - accuracy: 0.6037 - val_loss: 0.8546 - val_accuracy: 0.6028\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8502 - accuracy: 0.6100 - val_loss: 0.8445 - val_accuracy: 0.6028\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8389 - accuracy: 0.6219 - val_loss: 0.8360 - val_accuracy: 0.6255\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8358 - accuracy: 0.6156 - val_loss: 0.8338 - val_accuracy: 0.6238\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8364 - accuracy: 0.6161 - val_loss: 0.8450 - val_accuracy: 0.6098\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8465 - accuracy: 0.6149 - val_loss: 0.8512 - val_accuracy: 0.6040\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8423 - accuracy: 0.6135 - val_loss: 0.8665 - val_accuracy: 0.6080\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.8361 - accuracy: 0.6196 - val_loss: 0.8467 - val_accuracy: 0.6086\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 0.8401 - accuracy: 0.6234 - val_loss: 0.9197 - val_accuracy: 0.5836\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8731 - accuracy: 0.6049 - val_loss: 0.8604 - val_accuracy: 0.5999\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8447 - accuracy: 0.6154 - val_loss: 0.8577 - val_accuracy: 0.6104\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8515 - accuracy: 0.6101 - val_loss: 0.8712 - val_accuracy: 0.5824\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8471 - accuracy: 0.6161 - val_loss: 0.8633 - val_accuracy: 0.6022\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8383 - accuracy: 0.6255 - val_loss: 0.8409 - val_accuracy: 0.6209\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8457 - accuracy: 0.6162 - val_loss: 0.8364 - val_accuracy: 0.6220\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8795 - accuracy: 0.6081 - val_loss: 0.8937 - val_accuracy: 0.5725\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8665 - accuracy: 0.6050 - val_loss: 0.8791 - val_accuracy: 0.5906\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9328 - accuracy: 0.5827 - val_loss: 0.9872 - val_accuracy: 0.5434\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8667 - accuracy: 0.6098 - val_loss: 0.8612 - val_accuracy: 0.5894\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8898 - accuracy: 0.6009 - val_loss: 0.8849 - val_accuracy: 0.5999\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9039 - accuracy: 0.5961 - val_loss: 1.0196 - val_accuracy: 0.5807\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9708 - accuracy: 0.5899 - val_loss: 0.9480 - val_accuracy: 0.5929\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9458 - accuracy: 0.5859 - val_loss: 0.9135 - val_accuracy: 0.5970\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9003 - accuracy: 0.5971 - val_loss: 0.9561 - val_accuracy: 0.5585\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9981 - accuracy: 0.5801 - val_loss: 0.9524 - val_accuracy: 0.5882\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1849 - accuracy: 0.5482 - val_loss: 0.9913 - val_accuracy: 0.5830\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9530 - accuracy: 0.5915 - val_loss: 0.9663 - val_accuracy: 0.5568\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9634 - accuracy: 0.5722 - val_loss: 0.9144 - val_accuracy: 0.5865\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9069 - accuracy: 0.6024 - val_loss: 0.9222 - val_accuracy: 0.5999\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9147 - accuracy: 0.6020 - val_loss: 0.8664 - val_accuracy: 0.6051\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9665 - accuracy: 0.5843 - val_loss: 1.1946 - val_accuracy: 0.5195\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0846 - accuracy: 0.5612 - val_loss: 1.0322 - val_accuracy: 0.5358\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.0585 - accuracy: 0.5654 - val_loss: 0.9584 - val_accuracy: 0.6179\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.0130 - accuracy: 0.5823 - val_loss: 0.9128 - val_accuracy: 0.6127\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.9583 - accuracy: 0.5902 - val_loss: 0.9740 - val_accuracy: 0.6022\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.9266 - accuracy: 0.5954 - val_loss: 0.9477 - val_accuracy: 0.6313\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0718 - accuracy: 0.5715 - val_loss: 1.0706 - val_accuracy: 0.5504\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9747 - accuracy: 0.5929 - val_loss: 1.0501 - val_accuracy: 0.5341\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9269 - accuracy: 0.5931 - val_loss: 0.9422 - val_accuracy: 0.6255\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0153 - accuracy: 0.5824 - val_loss: 0.9310 - val_accuracy: 0.6115\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9933 - accuracy: 0.5890 - val_loss: 1.1870 - val_accuracy: 0.5515\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0788 - accuracy: 0.5791 - val_loss: 1.0239 - val_accuracy: 0.5492\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9679 - accuracy: 0.5902 - val_loss: 1.0256 - val_accuracy: 0.5783\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.0516 - accuracy: 0.5816 - val_loss: 0.9498 - val_accuracy: 0.6016\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2290 - accuracy: 0.5610 - val_loss: 1.1262 - val_accuracy: 0.5259\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4514 - accuracy: 0.5409 - val_loss: 1.3907 - val_accuracy: 0.4910\n",
      "---- building model for layer width of 2048 and 64\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 1.1286 - accuracy: 0.5354 - val_loss: 0.8595 - val_accuracy: 0.6010\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8663 - accuracy: 0.6022 - val_loss: 0.8379 - val_accuracy: 0.6109\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9118 - accuracy: 0.5817 - val_loss: 0.9071 - val_accuracy: 0.5906\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9785 - accuracy: 0.5773 - val_loss: 0.8870 - val_accuracy: 0.6144\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0150 - accuracy: 0.5670 - val_loss: 1.0321 - val_accuracy: 0.5609\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.2661 - accuracy: 0.5494 - val_loss: 1.4542 - val_accuracy: 0.4828\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2152 - accuracy: 0.5456 - val_loss: 1.9019 - val_accuracy: 0.4630\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7959 - accuracy: 0.4991 - val_loss: 1.4621 - val_accuracy: 0.5399\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.5977 - accuracy: 0.5262 - val_loss: 1.4459 - val_accuracy: 0.4910\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 2.2086 - accuracy: 0.5135 - val_loss: 3.8356 - val_accuracy: 0.4537\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.7183 - accuracy: 0.5105 - val_loss: 2.5530 - val_accuracy: 0.4094\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.0047 - accuracy: 0.5051 - val_loss: 5.7070 - val_accuracy: 0.4846\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.6093 - accuracy: 0.5051 - val_loss: 4.1100 - val_accuracy: 0.5207\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.4160 - accuracy: 0.5153 - val_loss: 2.4113 - val_accuracy: 0.5282\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.1343 - accuracy: 0.5216 - val_loss: 7.5380 - val_accuracy: 0.4333\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.5703 - accuracy: 0.5251 - val_loss: 2.3193 - val_accuracy: 0.4939\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.5564 - accuracy: 0.5108 - val_loss: 1.9079 - val_accuracy: 0.5527\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.5202 - accuracy: 0.4862 - val_loss: 6.4622 - val_accuracy: 0.4677\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.3456 - accuracy: 0.5306 - val_loss: 6.2181 - val_accuracy: 0.4758\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.0879 - accuracy: 0.4999 - val_loss: 7.5359 - val_accuracy: 0.4211\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.4449 - accuracy: 0.5255 - val_loss: 5.3624 - val_accuracy: 0.4619\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.7779 - accuracy: 0.4978 - val_loss: 4.1986 - val_accuracy: 0.5970\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.9875 - accuracy: 0.5245 - val_loss: 1.9696 - val_accuracy: 0.5475\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 3.2886 - accuracy: 0.5224 - val_loss: 5.4222 - val_accuracy: 0.5294\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.4839 - accuracy: 0.5360 - val_loss: 8.3952 - val_accuracy: 0.4444\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.6374 - accuracy: 0.5181 - val_loss: 9.3993 - val_accuracy: 0.5090\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 7.3930 - accuracy: 0.5296 - val_loss: 8.3040 - val_accuracy: 0.4333\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 4.5311 - accuracy: 0.5431 - val_loss: 5.2204 - val_accuracy: 0.5189\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 5.8791 - accuracy: 0.5210 - val_loss: 11.5331 - val_accuracy: 0.5416\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.2108 - accuracy: 0.5243 - val_loss: 4.0443 - val_accuracy: 0.4694\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.2620 - accuracy: 0.5262 - val_loss: 5.1286 - val_accuracy: 0.4927\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 9.4670 - accuracy: 0.5119 - val_loss: 16.9045 - val_accuracy: 0.4677\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 6.2236 - accuracy: 0.5153 - val_loss: 16.2365 - val_accuracy: 0.2341\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 9.3217 - accuracy: 0.5163 - val_loss: 5.4063 - val_accuracy: 0.5783\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 6.4214 - accuracy: 0.5264 - val_loss: 5.4264 - val_accuracy: 0.4694\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 7.0516 - accuracy: 0.5240 - val_loss: 8.0694 - val_accuracy: 0.5632\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 10.2145 - accuracy: 0.5167 - val_loss: 8.9196 - val_accuracy: 0.4869\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 8.7379 - accuracy: 0.5315 - val_loss: 18.3720 - val_accuracy: 0.2172\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 10.9702 - accuracy: 0.5159 - val_loss: 13.1937 - val_accuracy: 0.4153\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 7.1354 - accuracy: 0.5272 - val_loss: 8.7014 - val_accuracy: 0.4298\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 11.8870 - accuracy: 0.5285 - val_loss: 7.8560 - val_accuracy: 0.5620\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 9.8238 - accuracy: 0.5092 - val_loss: 12.3025 - val_accuracy: 0.4881\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 9.2958 - accuracy: 0.5198 - val_loss: 4.5149 - val_accuracy: 0.5562\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 13.7514 - accuracy: 0.4999 - val_loss: 6.5610 - val_accuracy: 0.5964\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 11.4941 - accuracy: 0.5299 - val_loss: 13.3064 - val_accuracy: 0.5073\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 14.5256 - accuracy: 0.5099 - val_loss: 22.2788 - val_accuracy: 0.4170\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 20ms/step - loss: 8.4631 - accuracy: 0.5304 - val_loss: 15.8768 - val_accuracy: 0.5836\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 3s 37ms/step - loss: 12.0243 - accuracy: 0.5256 - val_loss: 5.0466 - val_accuracy: 0.5871\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 9.5572 - accuracy: 0.5258 - val_loss: 9.7738 - val_accuracy: 0.5935\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 15.9381 - accuracy: 0.5045 - val_loss: 23.8310 - val_accuracy: 0.5178\n",
      "---- building model for layer width of 2048 and 8\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 18ms/step - loss: 1.3795 - accuracy: 0.5210 - val_loss: 1.0534 - val_accuracy: 0.6121\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9864 - accuracy: 0.6107 - val_loss: 0.9741 - val_accuracy: 0.6179\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9275 - accuracy: 0.6193 - val_loss: 0.9302 - val_accuracy: 0.6168\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.9071 - accuracy: 0.6127 - val_loss: 0.8846 - val_accuracy: 0.5941\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8437 - accuracy: 0.6136 - val_loss: 0.8548 - val_accuracy: 0.6069\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8663 - accuracy: 0.6018 - val_loss: 0.8782 - val_accuracy: 0.5964\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8502 - accuracy: 0.6178 - val_loss: 0.8547 - val_accuracy: 0.6121\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8508 - accuracy: 0.6200 - val_loss: 0.8976 - val_accuracy: 0.6045\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8979 - accuracy: 0.6063 - val_loss: 0.8985 - val_accuracy: 0.5882\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9131 - accuracy: 0.5966 - val_loss: 0.9036 - val_accuracy: 0.6191\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9254 - accuracy: 0.5957 - val_loss: 1.0371 - val_accuracy: 0.5946\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9507 - accuracy: 0.5939 - val_loss: 0.8417 - val_accuracy: 0.6278\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9014 - accuracy: 0.6104 - val_loss: 0.9978 - val_accuracy: 0.5877\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0383 - accuracy: 0.5839 - val_loss: 0.9339 - val_accuracy: 0.5743\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0008 - accuracy: 0.5826 - val_loss: 0.9313 - val_accuracy: 0.6005\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9223 - accuracy: 0.5973 - val_loss: 0.9225 - val_accuracy: 0.6249\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9407 - accuracy: 0.5963 - val_loss: 1.4975 - val_accuracy: 0.5597\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0903 - accuracy: 0.5711 - val_loss: 1.0368 - val_accuracy: 0.5859\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2748 - accuracy: 0.5631 - val_loss: 1.1216 - val_accuracy: 0.5451\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2769 - accuracy: 0.5500 - val_loss: 1.1883 - val_accuracy: 0.5358\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1005 - accuracy: 0.5754 - val_loss: 1.1738 - val_accuracy: 0.6174\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.3692 - accuracy: 0.5549 - val_loss: 1.7171 - val_accuracy: 0.4589\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6547 - accuracy: 0.5419 - val_loss: 2.4365 - val_accuracy: 0.5335\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.3529 - accuracy: 0.5596 - val_loss: 1.6333 - val_accuracy: 0.5020\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1319 - accuracy: 0.5731 - val_loss: 1.5122 - val_accuracy: 0.5597\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 1.5757 - accuracy: 0.5310 - val_loss: 1.6928 - val_accuracy: 0.5527\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.2576 - accuracy: 0.5722 - val_loss: 1.4341 - val_accuracy: 0.5114\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1252 - accuracy: 0.5674 - val_loss: 1.0554 - val_accuracy: 0.5690\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.5864 - accuracy: 0.5283 - val_loss: 2.4327 - val_accuracy: 0.4828\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5934 - accuracy: 0.5567 - val_loss: 1.5086 - val_accuracy: 0.5807\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.6582 - accuracy: 0.5283 - val_loss: 2.0486 - val_accuracy: 0.5510\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.5738 - accuracy: 0.5478 - val_loss: 1.6639 - val_accuracy: 0.5154\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.2719 - accuracy: 0.5281 - val_loss: 2.0864 - val_accuracy: 0.4752\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.2772 - accuracy: 0.5679 - val_loss: 1.3207 - val_accuracy: 0.5422\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.5455 - accuracy: 0.5540 - val_loss: 2.1657 - val_accuracy: 0.5183\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.5027 - accuracy: 0.5122 - val_loss: 1.5381 - val_accuracy: 0.5347\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.8863 - accuracy: 0.5412 - val_loss: 2.0072 - val_accuracy: 0.4787\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4883 - accuracy: 0.5587 - val_loss: 1.2927 - val_accuracy: 0.6022\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.3843 - accuracy: 0.5325 - val_loss: 3.2864 - val_accuracy: 0.5288\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.9065 - accuracy: 0.5371 - val_loss: 1.6032 - val_accuracy: 0.5347\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.9655 - accuracy: 0.5433 - val_loss: 1.8461 - val_accuracy: 0.5411\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 1.8842 - accuracy: 0.5454 - val_loss: 2.1695 - val_accuracy: 0.4584\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.6667 - accuracy: 0.5255 - val_loss: 2.9053 - val_accuracy: 0.5446\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 4.8227 - accuracy: 0.5031 - val_loss: 4.7917 - val_accuracy: 0.4269\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.4788 - accuracy: 0.5517 - val_loss: 2.9854 - val_accuracy: 0.5818\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.4482 - accuracy: 0.5315 - val_loss: 1.8057 - val_accuracy: 0.5888\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.0388 - accuracy: 0.5465 - val_loss: 2.0816 - val_accuracy: 0.5399\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.1826 - accuracy: 0.5502 - val_loss: 1.7312 - val_accuracy: 0.5271\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 2.7685 - accuracy: 0.5165 - val_loss: 4.3801 - val_accuracy: 0.2632\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 2.2220 - accuracy: 0.5366 - val_loss: 2.2751 - val_accuracy: 0.4653\n",
      "---- building model for layer width of 128 and 16\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.0911 - accuracy: 0.3962 - val_loss: 1.0013 - val_accuracy: 0.5201\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9396 - accuracy: 0.5539 - val_loss: 0.9091 - val_accuracy: 0.5842\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8884 - accuracy: 0.5936 - val_loss: 0.8714 - val_accuracy: 0.6051\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8754 - accuracy: 0.6017 - val_loss: 0.8595 - val_accuracy: 0.6127\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8456 - accuracy: 0.6097 - val_loss: 0.8597 - val_accuracy: 0.6144\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8400 - accuracy: 0.6184 - val_loss: 0.8407 - val_accuracy: 0.6377\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8338 - accuracy: 0.6203 - val_loss: 0.8281 - val_accuracy: 0.6290\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 0.8282 - accuracy: 0.6264 - val_loss: 0.8371 - val_accuracy: 0.6162\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8431 - accuracy: 0.6200 - val_loss: 0.8595 - val_accuracy: 0.6156\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8305 - accuracy: 0.6309 - val_loss: 0.8522 - val_accuracy: 0.5981\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8327 - accuracy: 0.6261 - val_loss: 0.8417 - val_accuracy: 0.5970\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.8288 - accuracy: 0.6322 - val_loss: 0.9088 - val_accuracy: 0.5737\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8506 - accuracy: 0.6121 - val_loss: 0.8467 - val_accuracy: 0.6174\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8325 - accuracy: 0.6250 - val_loss: 0.8721 - val_accuracy: 0.5824\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.8407 - accuracy: 0.6280 - val_loss: 0.8517 - val_accuracy: 0.5929\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8307 - accuracy: 0.6290 - val_loss: 0.8616 - val_accuracy: 0.5842\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8345 - accuracy: 0.6244 - val_loss: 0.8665 - val_accuracy: 0.5981\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8756 - accuracy: 0.6075 - val_loss: 0.8682 - val_accuracy: 0.6040\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8670 - accuracy: 0.6021 - val_loss: 0.8260 - val_accuracy: 0.6255\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8366 - accuracy: 0.6178 - val_loss: 0.8749 - val_accuracy: 0.5801\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8420 - accuracy: 0.6206 - val_loss: 0.8366 - val_accuracy: 0.6214\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8368 - accuracy: 0.6221 - val_loss: 0.8494 - val_accuracy: 0.6331\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 0.8529 - accuracy: 0.6223 - val_loss: 0.8808 - val_accuracy: 0.5748\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8561 - accuracy: 0.6140 - val_loss: 0.8345 - val_accuracy: 0.6092\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8559 - accuracy: 0.6170 - val_loss: 0.9178 - val_accuracy: 0.5661\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8603 - accuracy: 0.6081 - val_loss: 1.0397 - val_accuracy: 0.5288\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8831 - accuracy: 0.6022 - val_loss: 0.8832 - val_accuracy: 0.6022\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8507 - accuracy: 0.6206 - val_loss: 0.8359 - val_accuracy: 0.6203\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8688 - accuracy: 0.6133 - val_loss: 0.9519 - val_accuracy: 0.5754\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9085 - accuracy: 0.5996 - val_loss: 0.9122 - val_accuracy: 0.6040\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8846 - accuracy: 0.6024 - val_loss: 0.9097 - val_accuracy: 0.6040\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9448 - accuracy: 0.5916 - val_loss: 1.2220 - val_accuracy: 0.4840\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9239 - accuracy: 0.6027 - val_loss: 0.8644 - val_accuracy: 0.5946\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8552 - accuracy: 0.6135 - val_loss: 0.9189 - val_accuracy: 0.6302\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8747 - accuracy: 0.6053 - val_loss: 0.8653 - val_accuracy: 0.6133\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.8917 - accuracy: 0.6003 - val_loss: 1.0168 - val_accuracy: 0.5405\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.9940 - accuracy: 0.5728 - val_loss: 1.2444 - val_accuracy: 0.4694\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9695 - accuracy: 0.5859 - val_loss: 0.9021 - val_accuracy: 0.5871\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8970 - accuracy: 0.6014 - val_loss: 1.0380 - val_accuracy: 0.5358\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.9200 - accuracy: 0.5954 - val_loss: 0.8886 - val_accuracy: 0.6133\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8958 - accuracy: 0.6022 - val_loss: 0.9595 - val_accuracy: 0.5655\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8927 - accuracy: 0.6070 - val_loss: 0.9562 - val_accuracy: 0.5847\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8997 - accuracy: 0.6087 - val_loss: 0.9261 - val_accuracy: 0.6092\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8896 - accuracy: 0.6101 - val_loss: 0.9404 - val_accuracy: 0.5906\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8935 - accuracy: 0.6038 - val_loss: 0.9061 - val_accuracy: 0.5713\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.9496 - accuracy: 0.5839 - val_loss: 0.8651 - val_accuracy: 0.6045\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9484 - accuracy: 0.5851 - val_loss: 1.0456 - val_accuracy: 0.5463\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.9482 - accuracy: 0.5867 - val_loss: 0.9660 - val_accuracy: 0.5381\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9573 - accuracy: 0.5899 - val_loss: 0.8767 - val_accuracy: 0.6104\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9629 - accuracy: 0.5823 - val_loss: 1.0162 - val_accuracy: 0.5719\n",
      "---- building model for layer width of 32 and 128\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 1.5585 - accuracy: 0.4659 - val_loss: 0.9501 - val_accuracy: 0.5393\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9300 - accuracy: 0.5443 - val_loss: 0.9293 - val_accuracy: 0.5649\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8991 - accuracy: 0.5789 - val_loss: 0.8878 - val_accuracy: 0.5842\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8732 - accuracy: 0.5998 - val_loss: 0.8555 - val_accuracy: 0.6174\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 0.8696 - accuracy: 0.6008 - val_loss: 0.8492 - val_accuracy: 0.6168\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8677 - accuracy: 0.6006 - val_loss: 0.8835 - val_accuracy: 0.5778\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8605 - accuracy: 0.6129 - val_loss: 0.8403 - val_accuracy: 0.6127\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.8603 - accuracy: 0.6069 - val_loss: 0.8863 - val_accuracy: 0.5795\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9070 - accuracy: 0.5797 - val_loss: 0.8553 - val_accuracy: 0.6092\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8631 - accuracy: 0.6030 - val_loss: 0.8694 - val_accuracy: 0.6022\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8791 - accuracy: 0.5976 - val_loss: 0.8908 - val_accuracy: 0.5981\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8683 - accuracy: 0.6097 - val_loss: 0.8707 - val_accuracy: 0.6104\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9150 - accuracy: 0.5770 - val_loss: 0.8781 - val_accuracy: 0.5871\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9463 - accuracy: 0.5846 - val_loss: 0.8939 - val_accuracy: 0.6121\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9036 - accuracy: 0.6020 - val_loss: 0.8871 - val_accuracy: 0.6179\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9295 - accuracy: 0.5945 - val_loss: 0.8988 - val_accuracy: 0.5708\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.8884 - accuracy: 0.5953 - val_loss: 0.8980 - val_accuracy: 0.5935\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 0.9176 - accuracy: 0.5954 - val_loss: 0.8960 - val_accuracy: 0.5719\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9656 - accuracy: 0.5766 - val_loss: 1.0822 - val_accuracy: 0.5050\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9006 - accuracy: 0.6001 - val_loss: 0.9139 - val_accuracy: 0.5906\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9765 - accuracy: 0.5803 - val_loss: 0.9310 - val_accuracy: 0.5830\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9521 - accuracy: 0.5883 - val_loss: 0.9620 - val_accuracy: 0.5574\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9750 - accuracy: 0.5843 - val_loss: 1.0103 - val_accuracy: 0.5906\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9448 - accuracy: 0.5986 - val_loss: 0.8754 - val_accuracy: 0.6028\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9297 - accuracy: 0.5848 - val_loss: 0.8447 - val_accuracy: 0.6156\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1714 - accuracy: 0.5564 - val_loss: 1.7864 - val_accuracy: 0.4281\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.0480 - accuracy: 0.5717 - val_loss: 0.9992 - val_accuracy: 0.5929\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9677 - accuracy: 0.5868 - val_loss: 0.9698 - val_accuracy: 0.5842\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.9992 - accuracy: 0.5832 - val_loss: 1.1584 - val_accuracy: 0.4933\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.0017 - accuracy: 0.5836 - val_loss: 1.0699 - val_accuracy: 0.5312\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0988 - accuracy: 0.5559 - val_loss: 1.1563 - val_accuracy: 0.5224\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.2449 - accuracy: 0.5683 - val_loss: 1.4684 - val_accuracy: 0.5282\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.2456 - accuracy: 0.5663 - val_loss: 1.5780 - val_accuracy: 0.5282\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1276 - accuracy: 0.5754 - val_loss: 1.0385 - val_accuracy: 0.6267\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.2119 - accuracy: 0.5590 - val_loss: 1.0125 - val_accuracy: 0.5836\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.2150 - accuracy: 0.5567 - val_loss: 0.9232 - val_accuracy: 0.5795\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.0050 - accuracy: 0.5836 - val_loss: 1.4082 - val_accuracy: 0.5655\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.3203 - accuracy: 0.5618 - val_loss: 0.9312 - val_accuracy: 0.5649\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 0.9579 - accuracy: 0.5778 - val_loss: 0.9125 - val_accuracy: 0.6040\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 0.9804 - accuracy: 0.5830 - val_loss: 1.1098 - val_accuracy: 0.5364\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1551 - accuracy: 0.5661 - val_loss: 1.7998 - val_accuracy: 0.4595\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 1.4865 - accuracy: 0.5481 - val_loss: 0.9185 - val_accuracy: 0.6185\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.4241 - accuracy: 0.5398 - val_loss: 1.6283 - val_accuracy: 0.5795\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.1048 - accuracy: 0.5736 - val_loss: 1.1086 - val_accuracy: 0.5661\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.2380 - accuracy: 0.5673 - val_loss: 1.5816 - val_accuracy: 0.5527\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.0880 - accuracy: 0.5810 - val_loss: 1.2713 - val_accuracy: 0.5510\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.1226 - accuracy: 0.5669 - val_loss: 1.0867 - val_accuracy: 0.6348\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 1.4838 - accuracy: 0.5437 - val_loss: 1.1237 - val_accuracy: 0.5830\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 1.1513 - accuracy: 0.5651 - val_loss: 1.4008 - val_accuracy: 0.4916\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 1.1390 - accuracy: 0.5680 - val_loss: 1.1360 - val_accuracy: 0.5125\n",
      "---- building model for layer width of 512 and 2048\n",
      "Epoch 1/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 1.9875 - accuracy: 0.4926 - val_loss: 1.1001 - val_accuracy: 0.5108\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 1.0744 - accuracy: 0.5465 - val_loss: 1.3833 - val_accuracy: 0.4747\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 1.3329 - accuracy: 0.5256 - val_loss: 2.3346 - val_accuracy: 0.5137\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.8069 - accuracy: 0.5179 - val_loss: 1.5675 - val_accuracy: 0.4257\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 1.2957 - accuracy: 0.5403 - val_loss: 1.3933 - val_accuracy: 0.4910\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.8682 - accuracy: 0.5096 - val_loss: 5.2575 - val_accuracy: 0.5026\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 2.8443 - accuracy: 0.5182 - val_loss: 3.5962 - val_accuracy: 0.3349\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 2.8151 - accuracy: 0.5181 - val_loss: 5.5613 - val_accuracy: 0.4275\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 5.5513 - accuracy: 0.5151 - val_loss: 3.6772 - val_accuracy: 0.5795\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 3.8992 - accuracy: 0.5265 - val_loss: 3.2424 - val_accuracy: 0.5143\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 4.9312 - accuracy: 0.5141 - val_loss: 1.9099 - val_accuracy: 0.5795\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 4.4015 - accuracy: 0.5138 - val_loss: 10.0372 - val_accuracy: 0.2784\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 3.9307 - accuracy: 0.5309 - val_loss: 2.1388 - val_accuracy: 0.5440\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 6.2160 - accuracy: 0.5127 - val_loss: 9.0880 - val_accuracy: 0.3221\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 5.7269 - accuracy: 0.5307 - val_loss: 2.7462 - val_accuracy: 0.5964\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 5.0301 - accuracy: 0.5357 - val_loss: 2.2185 - val_accuracy: 0.5579\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 6.6608 - accuracy: 0.5133 - val_loss: 9.6675 - val_accuracy: 0.5976\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 6.6500 - accuracy: 0.5312 - val_loss: 8.0418 - val_accuracy: 0.5230\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 6.1698 - accuracy: 0.5230 - val_loss: 6.6701 - val_accuracy: 0.4351\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 8.0697 - accuracy: 0.5280 - val_loss: 5.4507 - val_accuracy: 0.5224\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 7.8794 - accuracy: 0.5166 - val_loss: 6.0115 - val_accuracy: 0.5725\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 10.5587 - accuracy: 0.5284 - val_loss: 15.6987 - val_accuracy: 0.5137\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 7.8435 - accuracy: 0.5226 - val_loss: 15.5423 - val_accuracy: 0.3343\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 9.4657 - accuracy: 0.5170 - val_loss: 12.7482 - val_accuracy: 0.4496\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 10.1338 - accuracy: 0.5115 - val_loss: 7.4707 - val_accuracy: 0.4723\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 1s 16ms/step - loss: 15.3554 - accuracy: 0.5007 - val_loss: 10.2802 - val_accuracy: 0.5352\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 12.6296 - accuracy: 0.5166 - val_loss: 13.1725 - val_accuracy: 0.4147\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 10.8912 - accuracy: 0.5342 - val_loss: 6.3404 - val_accuracy: 0.5900\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 10.4200 - accuracy: 0.5211 - val_loss: 14.2286 - val_accuracy: 0.5579\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 13.4798 - accuracy: 0.5287 - val_loss: 26.8598 - val_accuracy: 0.4490\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 18.7895 - accuracy: 0.5125 - val_loss: 16.0166 - val_accuracy: 0.5900\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 16.8010 - accuracy: 0.5230 - val_loss: 25.6635 - val_accuracy: 0.5218\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 14.0482 - accuracy: 0.5403 - val_loss: 6.1212 - val_accuracy: 0.5673\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 16.6451 - accuracy: 0.5103 - val_loss: 24.1656 - val_accuracy: 0.5090\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 16.5791 - accuracy: 0.5165 - val_loss: 26.1209 - val_accuracy: 0.4036\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 1s 12ms/step - loss: 18.6124 - accuracy: 0.5084 - val_loss: 7.2803 - val_accuracy: 0.6226\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 14.1709 - accuracy: 0.5278 - val_loss: 14.0166 - val_accuracy: 0.5818\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 1s 10ms/step - loss: 14.8908 - accuracy: 0.5304 - val_loss: 10.2576 - val_accuracy: 0.5690\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 18.4075 - accuracy: 0.5151 - val_loss: 18.4562 - val_accuracy: 0.4112\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 22.1000 - accuracy: 0.5213 - val_loss: 16.2860 - val_accuracy: 0.6016\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 15.3434 - accuracy: 0.5342 - val_loss: 19.1951 - val_accuracy: 0.5160\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 23.5244 - accuracy: 0.5195 - val_loss: 19.3203 - val_accuracy: 0.4752\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 18.8515 - accuracy: 0.5172 - val_loss: 15.2743 - val_accuracy: 0.5801\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 21.0483 - accuracy: 0.5135 - val_loss: 30.9152 - val_accuracy: 0.4811\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 17.8338 - accuracy: 0.5195 - val_loss: 13.2115 - val_accuracy: 0.4473\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 1s 14ms/step - loss: 18.1223 - accuracy: 0.5259 - val_loss: 11.0281 - val_accuracy: 0.4956\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 1s 17ms/step - loss: 24.9413 - accuracy: 0.5067 - val_loss: 16.8878 - val_accuracy: 0.4572\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 1s 11ms/step - loss: 22.7074 - accuracy: 0.5214 - val_loss: 21.5057 - val_accuracy: 0.5731\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 1s 13ms/step - loss: 28.7923 - accuracy: 0.5082 - val_loss: 27.7631 - val_accuracy: 0.4450\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 1s 15ms/step - loss: 22.8054 - accuracy: 0.5224 - val_loss: 20.1836 - val_accuracy: 0.5480\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 Width</th>\n",
       "      <th>Layer 2 Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.588115</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>3.395284</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.515377</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.592776</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>2.216120</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.472041</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.638217</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.852717</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.615564</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.572823</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>2.184790</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.509320</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.625546</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>1.435956</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.495340</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>26.259890</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.497670</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>2.527935</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.444548</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.632246</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>1.041080</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.573159</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.612875</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>1.164549</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.512582</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.546461</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>20.431257</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.558248</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 Width  Layer 2 Width  Metrics Value         Metrics Type\n",
       "0             256            256       0.588115  Validation Accuracy\n",
       "1             256            256       3.395284            Test Loss\n",
       "2             256            256       0.515377        Test Accuracy\n",
       "3              16           2048       0.592776  Validation Accuracy\n",
       "4              16           2048       2.216120            Test Loss\n",
       "5              16           2048       0.472041        Test Accuracy\n",
       "6               4              8       0.638217  Validation Accuracy\n",
       "7               4              8       0.852717            Test Loss\n",
       "8               4              8       0.615564        Test Accuracy\n",
       "9              32           2048       0.572823  Validation Accuracy\n",
       "10             32           2048       2.184790            Test Loss\n",
       "11             32           2048       0.509320        Test Accuracy\n",
       "12             32             64       0.625546  Validation Accuracy\n",
       "13             32             64       1.435956            Test Loss\n",
       "14             32             64       0.495340        Test Accuracy\n",
       "15           2048             64       0.602243  Validation Accuracy\n",
       "16           2048             64      26.259890            Test Loss\n",
       "17           2048             64       0.497670        Test Accuracy\n",
       "18           2048              8       0.620012  Validation Accuracy\n",
       "19           2048              8       2.527935            Test Loss\n",
       "20           2048              8       0.444548        Test Accuracy\n",
       "21            128             16       0.632246  Validation Accuracy\n",
       "22            128             16       1.041080            Test Loss\n",
       "23            128             16       0.573159        Test Accuracy\n",
       "24             32            128       0.612875  Validation Accuracy\n",
       "25             32            128       1.164549            Test Loss\n",
       "26             32            128       0.512582        Test Accuracy\n",
       "27            512           2048       0.546461  Validation Accuracy\n",
       "28            512           2048      20.431257            Test Loss\n",
       "29            512           2048       0.558248        Test Accuracy"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    r1 = random.randint(2, 12)\n",
    "    r2 = random.randint(2, 12)\n",
    "    \n",
    "    l1 = 2 ** r1\n",
    "    l2 = 2 ** r2\n",
    "    \n",
    "    print(\"---- building model for layer width of \" + str(l1) + \" and \" + str(l2))\n",
    "    d = DNN()\n",
    "    d.customize_first_layer(l1)\n",
    "    d.add_one_dense_layer(l2)\n",
    "    \n",
    "    #d.customize_fit(epochs = 2) ## TODO: REMOVE\n",
    "    \n",
    "    val_acc_result = d.build_compile_and_evaluate()\n",
    "    test_loss, test_accuracy = d.evaluate_model_with_test()\n",
    "    \n",
    "    results.append((l1, l2, val_acc_result, \"Validation Accuracy\"))\n",
    "    results.append((l1, l2, test_loss, \"Test Loss\"))\n",
    "    results.append((l1, l2, test_accuracy, \"Test Accuracy\"))\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results = results.rename(columns = {\n",
    "    0: \"Layer 1 Width\",\n",
    "    1: \"Layer 2 Width\",\n",
    "    2: \"Metrics Value\",\n",
    "    3: \"Metrics Type\"\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 Width</th>\n",
       "      <th>Layer 2 Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.588115</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.592776</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.638217</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.572823</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.625546</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.602243</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.620012</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.632246</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.612875</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.546461</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 Width  Layer 2 Width  Metrics Value         Metrics Type\n",
       "0             256            256       0.588115  Validation Accuracy\n",
       "3              16           2048       0.592776  Validation Accuracy\n",
       "6               4              8       0.638217  Validation Accuracy\n",
       "9              32           2048       0.572823  Validation Accuracy\n",
       "12             32             64       0.625546  Validation Accuracy\n",
       "15           2048             64       0.602243  Validation Accuracy\n",
       "18           2048              8       0.620012  Validation Accuracy\n",
       "21            128             16       0.632246  Validation Accuracy\n",
       "24             32            128       0.612875  Validation Accuracy\n",
       "27            512           2048       0.546461  Validation Accuracy"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy_only = results[results[\"Metrics Type\"] == \"Validation Accuracy\"]\n",
    "validation_accuracy_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
