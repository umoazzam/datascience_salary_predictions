{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminecjwchen/Documents/GitHub/COMS4995-AML-Project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kaggle_survey_2020_responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = df.drop(columns = [\"time_from_start_to_finish_seconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category(col_name: str, order_rules: list, data):\n",
    "    data[col_name] = pd.Categorical(data[col_name], order_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_category_no_specified_order(col_name, data):\n",
    "    if sum(data[col_name].isna().astype(int)) > 0:\n",
    "        data[col_name].fillna(\"No response\", inplace = True)\n",
    "    \n",
    "    order = list(set(data[col_name]))\n",
    "    convert_to_category(col_name, order, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_category_to_code(col_name: str, data, inplace = False):\n",
    "    if inplace:\n",
    "        data[col_name] = data[col_name].cat.codes + 1 # because NaN automatically becomes -1\n",
    "    else:\n",
    "        return data[col_name].cat.codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(col_name: str, order_rules = None, data = salary_data, num_data = salary_data_as_num):\n",
    "    if order_rules:\n",
    "        convert_to_category(col_name, order_rules, data)\n",
    "    else:\n",
    "        convert_to_category_no_specified_order(col_name, data)\n",
    "    num_data[col_name] = convert_category_to_code(col_name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_column_to_binary(col_name, data = salary_data):\n",
    "    data[col_name].fillna(0, inplace = True)\n",
    "    data[col_name].mask(data[col_name] != 0, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_hot_encoded_columns(columns, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col in columns:\n",
    "        one_hot_column_to_binary(col, data)\n",
    "        num_data[col] = data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_text_to_binary(col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    data[col_name] = data[col_name].notna().astype(int)\n",
    "    num_data[col_name] = data[col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multiple_columns_into_one_binary(columns, new_col_name, data = salary_data, num_data = salary_data_as_num):\n",
    "    for col_name in columns:\n",
    "        one_hot_column_to_binary(col_name)\n",
    "        \n",
    "    data[new_col_name] = data[columns].sum(axis = 1)\n",
    "    data[new_col_name] = data[new_col_name].astype(int)\n",
    "    \n",
    "    data[new_col_name].mask(data[new_col_name] > 0, 1, inplace = True)\n",
    "    num_data[new_col_name] = data[new_col_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q24 Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1: original bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "q24_order = [\"$0-999\",\n",
    "             '1,000-1,999',\n",
    "             '2,000-2,999',\n",
    "             '3,000-3,999',\n",
    "             '4,000-4,999',\n",
    "             '5,000-7,499',\n",
    "             '7,500-9,999',\n",
    "             '10,000-14,999',\n",
    "             '15,000-19,999',\n",
    "             '20,000-24,999',\n",
    "             '25,000-29,999',\n",
    "             '30,000-39,999',\n",
    "             '40,000-49,999',\n",
    "             '50,000-59,999',\n",
    "              '60,000-69,999',\n",
    "              '70,000-79,999',\n",
    "              '80,000-89,999',\n",
    "              '90,000-99,999',\n",
    "            '100,000-124,999',\n",
    "            '125,000-149,999',\n",
    "            '150,000-199,999',\n",
    "             '200,000-249,999',\n",
    "             '250,000-299,999',\n",
    "              '300,000-500,000',\n",
    "              '> $500,000'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q24\", q24_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "25-29    4011\n",
       "22-24    3786\n",
       "18-21    3469\n",
       "30-34    2811\n",
       "35-39    1991\n",
       "40-44    1397\n",
       "45-49     988\n",
       "50-54     698\n",
       "55-59     411\n",
       "60-69     398\n",
       "70         76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_order = [\n",
    "    \"18-21\",\n",
    "    \"22-24\",\n",
    "    \"25-29\",\n",
    "    \"30-34\",\n",
    "    \"35-39\",\n",
    "    \"40-44\",\n",
    "    \"45-49\",\n",
    "    \"50-54\",\n",
    "    \"55-59\",\n",
    "    \"60-69\",\n",
    "    \"70\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q1\", q1_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20031</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20036 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1\n",
       "0        0   5\n",
       "1       19   4\n",
       "2        9   5\n",
       "3       20   4\n",
       "4        0   4\n",
       "...    ...  ..\n",
       "20031    0   1\n",
       "20032    0   9\n",
       "20033    1   4\n",
       "20034    1   2\n",
       "20035    1   2\n",
       "\n",
       "[20036 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"] = convert_category_to_code(\"q1\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q1\n",
       "3     4011\n",
       "2     3786\n",
       "1     3469\n",
       "4     2811\n",
       "5     1991\n",
       "6     1397\n",
       "7      988\n",
       "8      698\n",
       "9      411\n",
       "10     398\n",
       "11      76\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "Man                        15789\n",
       "Woman                       3878\n",
       "Prefer not to say            263\n",
       "Prefer to self-describe       54\n",
       "Nonbinary                     52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_order = ['Man', \"Woman\", \"Nonbinary\", 'Prefer to self-describe', 'Prefer not to say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q2\", q2_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q24</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20031</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20032</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20036 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       q24  q1  q2\n",
       "0        0   5   1\n",
       "1       19   4   1\n",
       "2        9   5   1\n",
       "3       20   4   1\n",
       "4        0   4   1\n",
       "...    ...  ..  ..\n",
       "20031    0   1   1\n",
       "20032    0   9   2\n",
       "20033    1   4   1\n",
       "20034    1   2   1\n",
       "20035    1   2   1\n",
       "\n",
       "[20036 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"] = convert_category_to_code(\"q2\", salary_data, False)\n",
    "salary_data_as_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2\n",
       "1    15789\n",
       "2     3878\n",
       "5      263\n",
       "4       54\n",
       "3       52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q3\"] = convert_category_to_code(\"q3\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "Master’s degree                                                      7859\n",
       "Bachelor’s degree                                                    6978\n",
       "Doctoral degree                                                      2302\n",
       "Some college/university study without earning a bachelor’s degree    1092\n",
       "Professional degree                                                   699\n",
       "I prefer not to answer                                                399\n",
       "No formal education past high school                                  240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_order = [\"No formal education past high school\",\n",
    "            \"Some college/university study without earning a bachelor’s degree\",\n",
    "            \"Professional degree\",\n",
    "            \"Bachelor’s degree\",\n",
    "            \"Master’s degree\",\n",
    "            \"Doctoral degree\",\n",
    "            \"I prefer not to answer\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category(\"q4\", q4_order, salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q4\"] = convert_category_to_code(\"q4\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q4\n",
       "5    7859\n",
       "4    6978\n",
       "6    2302\n",
       "2    1092\n",
       "3     699\n",
       "0     467\n",
       "7     399\n",
       "1     240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data_as_num[\"q4\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q5\n",
       "Student                      5171\n",
       "Data Scientist               2676\n",
       "Software Engineer            1968\n",
       "Other                        1737\n",
       "Currently not employed       1652\n",
       "Data Analyst                 1475\n",
       "Research Scientist           1174\n",
       "Machine Learning Engineer    1082\n",
       "Business Analyst              798\n",
       "Product/Project Manager       692\n",
       "Data Engineer                 437\n",
       "Statistician                  290\n",
       "DBA/Database Engineer         125\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data[\"q5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_category_no_specified_order(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_as_num[\"q5\"] = convert_category_to_code(\"q5\", salary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Years Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_order = [\n",
    " 'I have never written code',\n",
    " '< 1 years',\n",
    " '1-2 years',\n",
    " '3-5 years',\n",
    " '5-10 years',\n",
    " '10-20 years',\n",
    " '20+ years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q6\", q6_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_columns = [\n",
    "     'q7_part_1',\n",
    " 'q7_part_2',\n",
    " 'q7_part_3',\n",
    " 'q7_part_4',\n",
    " 'q7_part_5',\n",
    " 'q7_part_6',\n",
    " 'q7_part_7',\n",
    " 'q7_part_8',\n",
    " 'q7_part_9',\n",
    " 'q7_part_10',\n",
    " 'q7_part_11',\n",
    " 'q7_part_12',\n",
    " 'q7_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q7_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q11 Computing Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q12 Specialized Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "q12_columns = [\n",
    "    'q12_part_1',\n",
    " 'q12_part_2',\n",
    " 'q12_part_3',\n",
    " 'q12_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q12_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q14 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14_columns = [\n",
    "    'q14_part_1',\n",
    " 'q14_part_2',\n",
    " 'q14_part_3',\n",
    " 'q14_part_4',\n",
    " 'q14_part_5',\n",
    " 'q14_part_6',\n",
    " 'q14_part_7',\n",
    " 'q14_part_8',\n",
    " 'q14_part_9',\n",
    " 'q14_part_10',\n",
    " 'q14_part_11',\n",
    " 'q14_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q14_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q15 Years ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15_order = [\n",
    "    'I do not use machine learning methods',\n",
    "    'Under 1 year',\n",
    "    '1-2 years',\n",
    "    '2-3 years',\n",
    "    '3-4 years',\n",
    "    '4-5 years',\n",
    "    '5-10 years',\n",
    "    '10-20 years',\n",
    "    '20 or more years'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q15\", q15_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q17 ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17_columns = [\n",
    "    'q17_part_1',\n",
    " 'q17_part_2',\n",
    " 'q17_part_3',\n",
    " 'q17_part_4',\n",
    " 'q17_part_5',\n",
    " 'q17_part_6',\n",
    " 'q17_part_7',\n",
    " 'q17_part_8',\n",
    " 'q17_part_9',\n",
    " 'q17_part_10',\n",
    " 'q17_part_11',\n",
    " 'q17_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q17_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q20 Company Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20_order = [\n",
    "    '0-49 employees',\n",
    "    '50-249 employees',\n",
    "    '250-999 employees',\n",
    "    '1000-9,999 employees',\n",
    "    '10,000 or more employees'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q20\", q20_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q21 Datascience Workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "q21_order = [\n",
    "    '0',\n",
    "    '1-2',\n",
    "    '3-4',\n",
    "    '5-9',\n",
    "    '10-14',\n",
    "    '15-19',\n",
    "    '20'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q21\", q21_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q22 Incorporating ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i'm not super sure about the proper \"order\" for this question. Feel free to change this if you find it more appropriate. Just please let the chat know in case it affects others' encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "q22_order = [\n",
    "    'I do not know',\n",
    "    'No (we do not use ML methods)',\n",
    "    'We are exploring ML methods (and may one day put a model into production)',\n",
    "    'We use ML methods for generating insights (but do not put working models into production)',\n",
    "    'We recently started using ML methods (i.e., models in production for less than 2 years)',\n",
    "    'We have well established ML methods (i.e., models in production for more than 2 years)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q22\", q22_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q30 Big Data Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q32 Business Intelligence Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_text_to_binary(\"q32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q33 Automated ML Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "q33_columns = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_multiple_columns_into_one_binary(q33_columns, \"q33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q37 Data Science Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "q37_columns = [\n",
    "    'q37_part_1',\n",
    " 'q37_part_2',\n",
    " 'q37_part_3',\n",
    " 'q37_part_4',\n",
    " 'q37_part_5',\n",
    " 'q37_part_6',\n",
    " 'q37_part_7',\n",
    " 'q37_part_8',\n",
    " 'q37_part_9',\n",
    " 'q37_part_10',\n",
    " 'q37_part_11',\n",
    " 'q37_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q37_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q38 Primary Data Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_column(\"q38\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q39 Media Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "q39_columns = [\n",
    "    'q39_part_1',\n",
    " 'q39_part_2',\n",
    " 'q39_part_3',\n",
    " 'q39_part_4',\n",
    " 'q39_part_5',\n",
    " 'q39_part_6',\n",
    " 'q39_part_7',\n",
    " 'q39_part_8',\n",
    " 'q39_part_9',\n",
    " 'q39_part_10',\n",
    " 'q39_part_11',\n",
    " 'q39_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_one_hot_encoded_columns(q39_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropped Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_dropped = [\n",
    "    'q33_a_part_1',\n",
    " 'q33_a_part_2',\n",
    " 'q33_a_part_3',\n",
    " 'q33_a_part_4',\n",
    " 'q33_a_part_5',\n",
    " 'q33_a_part_6',\n",
    " 'q33_a_part_7',\n",
    " 'q33_a_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_questions = [\n",
    "    \"q8\",\n",
    "    'q9_part_1',\n",
    " 'q9_part_2',\n",
    " 'q9_part_3',\n",
    " 'q9_part_4',\n",
    " 'q9_part_5',\n",
    " 'q9_part_6',\n",
    " 'q9_part_7',\n",
    " 'q9_part_8',\n",
    " 'q9_part_9',\n",
    " 'q9_part_10',\n",
    " 'q9_part_11',\n",
    " 'q9_other',\n",
    " 'q10_part_1',\n",
    " 'q10_part_2',\n",
    " 'q10_part_3',\n",
    " 'q10_part_4',\n",
    " 'q10_part_5',\n",
    " 'q10_part_6',\n",
    " 'q10_part_7',\n",
    " 'q10_part_8',\n",
    " 'q10_part_9',\n",
    " 'q10_part_10',\n",
    " 'q10_part_11',\n",
    " 'q10_part_12',\n",
    " 'q10_part_13',\n",
    " 'q10_other',\n",
    " \"q13\",\n",
    " 'q16_part_1',\n",
    " 'q16_part_2',\n",
    " 'q16_part_3',\n",
    " 'q16_part_4',\n",
    " 'q16_part_5',\n",
    " 'q16_part_6',\n",
    " 'q16_part_7',\n",
    " 'q16_part_8',\n",
    " 'q16_part_9',\n",
    " 'q16_part_10',\n",
    " 'q16_part_11',\n",
    " 'q16_part_12',\n",
    " 'q16_part_13',\n",
    " 'q16_part_14',\n",
    " 'q16_part_15',\n",
    " 'q16_other',\n",
    " 'q18_part_1',\n",
    " 'q18_part_2',\n",
    " 'q18_part_3',\n",
    " 'q18_part_4',\n",
    " 'q18_part_5',\n",
    " 'q18_part_6',\n",
    " 'q18_other',\n",
    " 'q19_part_1',\n",
    " 'q19_part_2',\n",
    " 'q19_part_3',\n",
    " 'q19_part_4',\n",
    " 'q19_part_5',\n",
    " 'q19_other',\n",
    " 'q23_part_1',\n",
    " 'q23_part_2',\n",
    " 'q23_part_3',\n",
    " 'q23_part_4',\n",
    " 'q23_part_5',\n",
    " 'q23_part_6',\n",
    " 'q23_part_7',\n",
    " 'q23_other',\n",
    " 'q25',\n",
    " 'q26_a_part_1',\n",
    " 'q26_a_part_2',\n",
    " 'q26_a_part_3',\n",
    " 'q26_a_part_4',\n",
    " 'q26_a_part_5',\n",
    " 'q26_a_part_6',\n",
    " 'q26_a_part_7',\n",
    " 'q26_a_part_8',\n",
    " 'q26_a_part_9',\n",
    " 'q26_a_part_10',\n",
    " 'q26_a_part_11',\n",
    " 'q26_a_other',\n",
    " 'q27_a_part_1',\n",
    " 'q27_a_part_2',\n",
    " 'q27_a_part_3',\n",
    " 'q27_a_part_4',\n",
    " 'q27_a_part_5',\n",
    " 'q27_a_part_6',\n",
    " 'q27_a_part_7',\n",
    " 'q27_a_part_8',\n",
    " 'q27_a_part_9',\n",
    " 'q27_a_part_10',\n",
    " 'q27_a_part_11',\n",
    " 'q27_a_other',\n",
    " 'q28_a_part_1',\n",
    " 'q28_a_part_2',\n",
    " 'q28_a_part_3',\n",
    " 'q28_a_part_4',\n",
    " 'q28_a_part_5',\n",
    " 'q28_a_part_6',\n",
    " 'q28_a_part_7',\n",
    " 'q28_a_part_8',\n",
    " 'q28_a_part_9',\n",
    " 'q28_a_part_10',\n",
    " 'q28_a_other',\n",
    " 'q29_a_part_1',\n",
    " 'q29_a_part_2',\n",
    " 'q29_a_part_3',\n",
    " 'q29_a_part_4',\n",
    " 'q29_a_part_5',\n",
    " 'q29_a_part_6',\n",
    " 'q29_a_part_7',\n",
    " 'q29_a_part_8',\n",
    " 'q29_a_part_9',\n",
    " 'q29_a_part_10',\n",
    " 'q29_a_part_11',\n",
    " 'q29_a_part_12',\n",
    " 'q29_a_part_13',\n",
    " 'q29_a_part_14',\n",
    " 'q29_a_part_15',\n",
    " 'q29_a_part_16',\n",
    " 'q29_a_part_17',\n",
    " 'q29_a_other',\n",
    " 'q31_a_part_1',\n",
    " 'q31_a_part_2',\n",
    " 'q31_a_part_3',\n",
    " 'q31_a_part_4',\n",
    " 'q31_a_part_5',\n",
    " 'q31_a_part_6',\n",
    " 'q31_a_part_7',\n",
    " 'q31_a_part_8',\n",
    " 'q31_a_part_9',\n",
    " 'q31_a_part_10',\n",
    " 'q31_a_part_11',\n",
    " 'q31_a_part_12',\n",
    " 'q31_a_part_13',\n",
    " 'q31_a_part_14',\n",
    " 'q31_a_other',\n",
    " 'q34_a_part_1',\n",
    " 'q34_a_part_2',\n",
    " 'q34_a_part_3',\n",
    " 'q34_a_part_4',\n",
    " 'q34_a_part_5',\n",
    " 'q34_a_part_6',\n",
    " 'q34_a_part_7',\n",
    " 'q34_a_part_8',\n",
    " 'q34_a_part_9',\n",
    " 'q34_a_part_10',\n",
    " 'q34_a_part_11',\n",
    " 'q34_a_other',\n",
    " 'q35_a_part_1',\n",
    " 'q35_a_part_2',\n",
    " 'q35_a_part_3',\n",
    " 'q35_a_part_4',\n",
    " 'q35_a_part_5',\n",
    " 'q35_a_part_6',\n",
    " 'q35_a_part_7',\n",
    " 'q35_a_part_8',\n",
    " 'q35_a_part_9',\n",
    " 'q35_a_part_10',\n",
    " 'q35_a_other',\n",
    " 'q36_part_1',\n",
    " 'q36_part_2',\n",
    " 'q36_part_3',\n",
    " 'q36_part_4',\n",
    " 'q36_part_5',\n",
    " 'q36_part_6',\n",
    " 'q36_part_7',\n",
    " 'q36_part_8',\n",
    " 'q36_part_9',\n",
    " 'q36_other',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_b_dropped = [\n",
    "    'q26_b_part_1',\n",
    " 'q26_b_part_2',\n",
    " 'q26_b_part_3',\n",
    " 'q26_b_part_4',\n",
    " 'q26_b_part_5',\n",
    " 'q26_b_part_6',\n",
    " 'q26_b_part_7',\n",
    " 'q26_b_part_8',\n",
    " 'q26_b_part_9',\n",
    " 'q26_b_part_10',\n",
    " 'q26_b_part_11',\n",
    " 'q26_b_other',\n",
    " 'q27_b_part_1',\n",
    " 'q27_b_part_2',\n",
    " 'q27_b_part_3',\n",
    " 'q27_b_part_4',\n",
    " 'q27_b_part_5',\n",
    " 'q27_b_part_6',\n",
    " 'q27_b_part_7',\n",
    " 'q27_b_part_8',\n",
    " 'q27_b_part_9',\n",
    " 'q27_b_part_10',\n",
    " 'q27_b_part_11',\n",
    " 'q27_b_other',\n",
    " 'q28_b_part_1',\n",
    " 'q28_b_part_2',\n",
    " 'q28_b_part_3',\n",
    " 'q28_b_part_4',\n",
    " 'q28_b_part_5',\n",
    " 'q28_b_part_6',\n",
    " 'q28_b_part_7',\n",
    " 'q28_b_part_8',\n",
    " 'q28_b_part_9',\n",
    " 'q28_b_part_10',\n",
    " 'q28_b_other',\n",
    " 'q29_b_part_1',\n",
    " 'q29_b_part_2',\n",
    " 'q29_b_part_3',\n",
    " 'q29_b_part_4',\n",
    " 'q29_b_part_5',\n",
    " 'q29_b_part_6',\n",
    " 'q29_b_part_7',\n",
    " 'q29_b_part_8',\n",
    " 'q29_b_part_9',\n",
    " 'q29_b_part_10',\n",
    " 'q29_b_part_11',\n",
    " 'q29_b_part_12',\n",
    " 'q29_b_part_13',\n",
    " 'q29_b_part_14',\n",
    " 'q29_b_part_15',\n",
    " 'q29_b_part_16',\n",
    " 'q29_b_part_17',\n",
    " 'q29_b_other',\n",
    " 'q31_b_part_1',\n",
    " 'q31_b_part_2',\n",
    " 'q31_b_part_3',\n",
    " 'q31_b_part_4',\n",
    " 'q31_b_part_5',\n",
    " 'q31_b_part_6',\n",
    " 'q31_b_part_7',\n",
    " 'q31_b_part_8',\n",
    " 'q31_b_part_9',\n",
    " 'q31_b_part_10',\n",
    " 'q31_b_part_11',\n",
    " 'q31_b_part_12',\n",
    " 'q31_b_part_13',\n",
    " 'q31_b_part_14',\n",
    " 'q31_b_other',\n",
    " 'q33_b_part_1',\n",
    " 'q33_b_part_2',\n",
    " 'q33_b_part_3',\n",
    " 'q33_b_part_4',\n",
    " 'q33_b_part_5',\n",
    " 'q33_b_part_6',\n",
    " 'q33_b_part_7',\n",
    " 'q33_b_other',\n",
    " 'q34_b_part_1',\n",
    " 'q34_b_part_2',\n",
    " 'q34_b_part_3',\n",
    " 'q34_b_part_4',\n",
    " 'q34_b_part_5',\n",
    " 'q34_b_part_6',\n",
    " 'q34_b_part_7',\n",
    " 'q34_b_part_8',\n",
    " 'q34_b_part_9',\n",
    " 'q34_b_part_10',\n",
    " 'q34_b_part_11',\n",
    " 'q34_b_other',\n",
    " 'q35_b_part_1',\n",
    " 'q35_b_part_2',\n",
    " 'q35_b_part_3',\n",
    " 'q35_b_part_4',\n",
    " 'q35_b_part_5',\n",
    " 'q35_b_part_6',\n",
    " 'q35_b_part_7',\n",
    " 'q35_b_part_8',\n",
    " 'q35_b_part_9',\n",
    " 'q35_b_part_10',\n",
    " 'q35_b_other'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = one_hot_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data.drop(columns = part_b_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data_selected_questions = salary_data.drop(columns = dropped_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = salary_data_as_num.drop(columns = [\"q24\"])\n",
    "y = salary_data_as_num[\"q24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev, x_test, y_dev, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 17:28:21.195284: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-11-28 17:28:21.195326: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-11-28 17:28:21.195342: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-11-28 17:28:21.199345: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-28 17:28:21.203555: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x_dev = tf.convert_to_tensor(x_dev.astype(\"int64\"))\n",
    "x_test = tf.convert_to_tensor(x_test.astype(\"int64\"))\n",
    "y_dev = tf.convert_to_tensor(y_dev.astype(\"int64\"))\n",
    "y_test = tf.convert_to_tensor(y_test.astype(\"int64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN:\n",
    "    \n",
    "    def __init__(self, x_dev = x_dev, y_dev = y_dev, x_test = x_test, y_test = y_test):\n",
    "        self.x_dev = x_dev\n",
    "        self.y_dev = y_dev\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.layers = [Dense(32, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "        self.optimizer = \"adam\"\n",
    "        self.loss = \"sparse_categorical_crossentropy\"\n",
    "        self.metrics =  [\"accuracy\"]\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.epochs = 50\n",
    "        \n",
    "    def customize_first_layer(self, node_count = 32):\n",
    "        self.layers = [Dense(node_count, input_shape = (80, ), activation = \"relu\")]\n",
    "        \n",
    "    def add_one_dense_layer(self, node_count = 32):\n",
    "        self.layers.append(Dense(node_count, activation = \"relu\"))\n",
    "        \n",
    "    def customize_middle_layers(self, layers):\n",
    "        self.layers.extend(layers)\n",
    "    \n",
    "    def customize_compile(self,\n",
    "                          optimizer = \"adam\",\n",
    "                          loss = \"sparse_categorical_crossentropy\",\n",
    "                          metrics = [\"accuracy\"]):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def customize_fit(self,\n",
    "                      batch_size = 100,\n",
    "                      epochs = 50\n",
    "                      ):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def build_compile_and_evaluate(self, metric_to_return = \"accuracy\", selection_criteria = max):\n",
    "        # final layer must be softmax and outputs 26\n",
    "        self.layers.append(Dense(26, activation = \"softmax\"))\n",
    "        \n",
    "        self.model = Sequential(self.layers)\n",
    "        self.model.compile(optimizer = self.optimizer,\n",
    "                      loss = self.loss,\n",
    "                      metrics = self.metrics)\n",
    "        fit_history = self.model.fit(self.x_dev, self.y_dev,\n",
    "                                batch_size = self.batch_size,\n",
    "                                epochs = self.epochs,\n",
    "                                validation_split = 0.2,\n",
    "                                #verbose = 1\n",
    "                                )\n",
    "        self.fit_history = pd.DataFrame(fit_history.history)\n",
    "        return selection_criteria(self.fit_history[metric_to_return])\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        self.model.summary()\n",
    "        \n",
    "    def get_fit_history(self):\n",
    "        return self.fit_history\n",
    "        \n",
    "    def evaluate_model_with_test(self):\n",
    "        return self.model.evaluate(self.x_test, self.y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers: Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- building model for layer width of 256 and 256\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.0465 - accuracy: 0.5035 - val_loss: 1.7501 - val_accuracy: 0.5312\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7815 - accuracy: 0.5343 - val_loss: 1.7756 - val_accuracy: 0.5140\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7967 - accuracy: 0.5290 - val_loss: 1.7684 - val_accuracy: 0.5234\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8106 - accuracy: 0.5347 - val_loss: 1.8726 - val_accuracy: 0.5324\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9030 - accuracy: 0.5316 - val_loss: 2.1375 - val_accuracy: 0.5483\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 2s 16ms/step - loss: 2.1526 - accuracy: 0.5172 - val_loss: 2.3877 - val_accuracy: 0.5193\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 2.3748 - accuracy: 0.5178 - val_loss: 2.7319 - val_accuracy: 0.5181\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.8456 - accuracy: 0.5107 - val_loss: 3.1615 - val_accuracy: 0.5019\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.6314 - accuracy: 0.5006 - val_loss: 5.1896 - val_accuracy: 0.5153\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 5.6163 - accuracy: 0.4813 - val_loss: 9.3036 - val_accuracy: 0.5165\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 7.7773 - accuracy: 0.4801 - val_loss: 12.5735 - val_accuracy: 0.4099\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 14.1304 - accuracy: 0.4579 - val_loss: 14.8392 - val_accuracy: 0.4648\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 2s 16ms/step - loss: 18.4390 - accuracy: 0.4575 - val_loss: 23.4493 - val_accuracy: 0.4488\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 24.8917 - accuracy: 0.4531 - val_loss: 34.6767 - val_accuracy: 0.3631\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 33.8484 - accuracy: 0.4475 - val_loss: 25.9862 - val_accuracy: 0.4906\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 42.9938 - accuracy: 0.4453 - val_loss: 40.8614 - val_accuracy: 0.4922\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 44.1709 - accuracy: 0.4506 - val_loss: 31.8914 - val_accuracy: 0.5047\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 47.1170 - accuracy: 0.4441 - val_loss: 60.2170 - val_accuracy: 0.4158\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 61.5785 - accuracy: 0.4404 - val_loss: 58.0085 - val_accuracy: 0.4616\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 75.8637 - accuracy: 0.4341 - val_loss: 88.3667 - val_accuracy: 0.4619\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 87.9403 - accuracy: 0.4363 - val_loss: 96.7944 - val_accuracy: 0.4651\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 95.9499 - accuracy: 0.4389 - val_loss: 75.4765 - val_accuracy: 0.4479\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 103.3718 - accuracy: 0.4374 - val_loss: 124.4013 - val_accuracy: 0.4485\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 112.7254 - accuracy: 0.4414 - val_loss: 143.7632 - val_accuracy: 0.4482\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 125.3813 - accuracy: 0.4361 - val_loss: 91.7929 - val_accuracy: 0.5047\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 132.9301 - accuracy: 0.4367 - val_loss: 141.1187 - val_accuracy: 0.4283\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 173.6182 - accuracy: 0.4207 - val_loss: 160.3171 - val_accuracy: 0.4694\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 163.6487 - accuracy: 0.4380 - val_loss: 182.2490 - val_accuracy: 0.4351\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 174.7122 - accuracy: 0.4395 - val_loss: 214.8717 - val_accuracy: 0.4133\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 211.3868 - accuracy: 0.4296 - val_loss: 165.9841 - val_accuracy: 0.4663\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 236.4372 - accuracy: 0.4286 - val_loss: 217.5227 - val_accuracy: 0.4460\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 225.9719 - accuracy: 0.4307 - val_loss: 248.6979 - val_accuracy: 0.3964\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 249.9909 - accuracy: 0.4298 - val_loss: 278.4179 - val_accuracy: 0.4314\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 279.5191 - accuracy: 0.4246 - val_loss: 294.6410 - val_accuracy: 0.4651\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 296.0074 - accuracy: 0.4279 - val_loss: 213.0211 - val_accuracy: 0.4392\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 292.9906 - accuracy: 0.4307 - val_loss: 340.5450 - val_accuracy: 0.4392\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 292.3257 - accuracy: 0.4444 - val_loss: 314.6329 - val_accuracy: 0.4273\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 335.0079 - accuracy: 0.4362 - val_loss: 304.7370 - val_accuracy: 0.4741\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 362.9845 - accuracy: 0.4339 - val_loss: 336.7980 - val_accuracy: 0.4286\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 358.8051 - accuracy: 0.4325 - val_loss: 383.4793 - val_accuracy: 0.4934\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 378.5596 - accuracy: 0.4425 - val_loss: 289.5231 - val_accuracy: 0.5090\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 357.3857 - accuracy: 0.4420 - val_loss: 382.9592 - val_accuracy: 0.3977\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 446.7739 - accuracy: 0.4312 - val_loss: 598.7641 - val_accuracy: 0.3911\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 401.0485 - accuracy: 0.4408 - val_loss: 398.0581 - val_accuracy: 0.4520\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 456.0716 - accuracy: 0.4407 - val_loss: 433.9477 - val_accuracy: 0.4410\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 468.5285 - accuracy: 0.4312 - val_loss: 416.0516 - val_accuracy: 0.4860\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 478.4052 - accuracy: 0.4387 - val_loss: 507.8480 - val_accuracy: 0.4457\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 454.5641 - accuracy: 0.4458 - val_loss: 462.0973 - val_accuracy: 0.4707\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 536.6323 - accuracy: 0.4366 - val_loss: 500.3618 - val_accuracy: 0.4607\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 540.9277 - accuracy: 0.4429 - val_loss: 611.2380 - val_accuracy: 0.4654\n",
      "---- building model for layer width of 16 and 2048\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.9341 - accuracy: 0.5069 - val_loss: 1.7390 - val_accuracy: 0.5215\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7940 - accuracy: 0.5253 - val_loss: 1.7798 - val_accuracy: 0.5268\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7739 - accuracy: 0.5310 - val_loss: 1.7421 - val_accuracy: 0.5546\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7845 - accuracy: 0.5317 - val_loss: 1.8428 - val_accuracy: 0.5290\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9129 - accuracy: 0.5275 - val_loss: 1.8972 - val_accuracy: 0.5496\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.0298 - accuracy: 0.5214 - val_loss: 2.1823 - val_accuracy: 0.5228\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.3024 - accuracy: 0.5183 - val_loss: 2.6867 - val_accuracy: 0.5318\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.6916 - accuracy: 0.5126 - val_loss: 3.2436 - val_accuracy: 0.5094\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.4132 - accuracy: 0.5024 - val_loss: 3.7722 - val_accuracy: 0.4881\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 5.6539 - accuracy: 0.4895 - val_loss: 7.2888 - val_accuracy: 0.4273\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 8.9199 - accuracy: 0.4747 - val_loss: 9.0607 - val_accuracy: 0.4133\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 11.1013 - accuracy: 0.4756 - val_loss: 11.8617 - val_accuracy: 0.4878\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 13.8097 - accuracy: 0.4725 - val_loss: 14.1484 - val_accuracy: 0.4913\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 17.2709 - accuracy: 0.4682 - val_loss: 18.0293 - val_accuracy: 0.5168\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 22.3814 - accuracy: 0.4689 - val_loss: 28.4799 - val_accuracy: 0.4791\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 22.2863 - accuracy: 0.4690 - val_loss: 22.2095 - val_accuracy: 0.5056\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 32.3963 - accuracy: 0.4655 - val_loss: 42.0172 - val_accuracy: 0.4704\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 36.7598 - accuracy: 0.4665 - val_loss: 31.0654 - val_accuracy: 0.4591\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 38.5539 - accuracy: 0.4620 - val_loss: 41.6731 - val_accuracy: 0.5031\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 52.7105 - accuracy: 0.4598 - val_loss: 60.9330 - val_accuracy: 0.4785\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 61.7814 - accuracy: 0.4607 - val_loss: 56.9615 - val_accuracy: 0.4654\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 58.9696 - accuracy: 0.4608 - val_loss: 56.4003 - val_accuracy: 0.4541\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 70.6888 - accuracy: 0.4633 - val_loss: 71.1022 - val_accuracy: 0.4660\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 79.3581 - accuracy: 0.4571 - val_loss: 75.7543 - val_accuracy: 0.5041\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 88.3553 - accuracy: 0.4605 - val_loss: 91.1911 - val_accuracy: 0.4108\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 98.0047 - accuracy: 0.4562 - val_loss: 99.6598 - val_accuracy: 0.4782\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 90.0258 - accuracy: 0.4668 - val_loss: 110.4651 - val_accuracy: 0.4152\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 96.2397 - accuracy: 0.4629 - val_loss: 93.0836 - val_accuracy: 0.4866\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 116.3419 - accuracy: 0.4553 - val_loss: 116.7827 - val_accuracy: 0.4616\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 128.0316 - accuracy: 0.4582 - val_loss: 117.9836 - val_accuracy: 0.5034\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 128.5119 - accuracy: 0.4627 - val_loss: 136.5800 - val_accuracy: 0.4676\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 137.0307 - accuracy: 0.4552 - val_loss: 123.5222 - val_accuracy: 0.4267\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 142.0041 - accuracy: 0.4541 - val_loss: 132.1352 - val_accuracy: 0.4782\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 148.5526 - accuracy: 0.4637 - val_loss: 140.4525 - val_accuracy: 0.4541\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 158.0166 - accuracy: 0.4615 - val_loss: 160.9353 - val_accuracy: 0.5056\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 162.4647 - accuracy: 0.4599 - val_loss: 219.1949 - val_accuracy: 0.4320\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 184.5852 - accuracy: 0.4580 - val_loss: 150.6786 - val_accuracy: 0.4529\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 183.9929 - accuracy: 0.4568 - val_loss: 167.8613 - val_accuracy: 0.4807\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 195.0647 - accuracy: 0.4573 - val_loss: 196.0265 - val_accuracy: 0.4729\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 221.0305 - accuracy: 0.4545 - val_loss: 212.0573 - val_accuracy: 0.4984\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 220.7250 - accuracy: 0.4548 - val_loss: 250.2362 - val_accuracy: 0.4108\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 233.1411 - accuracy: 0.4526 - val_loss: 186.4961 - val_accuracy: 0.4523\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 231.7715 - accuracy: 0.4615 - val_loss: 155.5028 - val_accuracy: 0.5156\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 205.8394 - accuracy: 0.4677 - val_loss: 213.8631 - val_accuracy: 0.4417\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 241.3381 - accuracy: 0.4553 - val_loss: 177.2080 - val_accuracy: 0.4747\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 250.7540 - accuracy: 0.4570 - val_loss: 353.9783 - val_accuracy: 0.4223\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 245.6035 - accuracy: 0.4622 - val_loss: 197.0918 - val_accuracy: 0.4825\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 257.6237 - accuracy: 0.4582 - val_loss: 387.5034 - val_accuracy: 0.4523\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 300.3768 - accuracy: 0.4506 - val_loss: 317.7747 - val_accuracy: 0.4523\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 270.4584 - accuracy: 0.4640 - val_loss: 322.1146 - val_accuracy: 0.4988\n",
      "---- building model for layer width of 4 and 8\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 10ms/step - loss: 3.1857 - accuracy: 0.1677 - val_loss: 2.5373 - val_accuracy: 0.4386\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.3675 - accuracy: 0.4404 - val_loss: 2.1688 - val_accuracy: 0.4697\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.0452 - accuracy: 0.4779 - val_loss: 1.8630 - val_accuracy: 0.5019\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 1.8292 - accuracy: 0.5058 - val_loss: 1.7381 - val_accuracy: 0.5343\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7483 - accuracy: 0.5223 - val_loss: 1.6841 - val_accuracy: 0.5321\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7179 - accuracy: 0.5268 - val_loss: 1.6630 - val_accuracy: 0.5449\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.6997 - accuracy: 0.5316 - val_loss: 1.6504 - val_accuracy: 0.5459\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6924 - accuracy: 0.5351 - val_loss: 1.6431 - val_accuracy: 0.5471\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6889 - accuracy: 0.5358 - val_loss: 1.6396 - val_accuracy: 0.5459\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6870 - accuracy: 0.5354 - val_loss: 1.6401 - val_accuracy: 0.5459\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6870 - accuracy: 0.5378 - val_loss: 1.6367 - val_accuracy: 0.5465\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6870 - accuracy: 0.5381 - val_loss: 1.6345 - val_accuracy: 0.5487\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6876 - accuracy: 0.5377 - val_loss: 1.6381 - val_accuracy: 0.5490\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6856 - accuracy: 0.5390 - val_loss: 1.6371 - val_accuracy: 0.5521\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6842 - accuracy: 0.5394 - val_loss: 1.6368 - val_accuracy: 0.5471\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6798 - accuracy: 0.5399 - val_loss: 1.6292 - val_accuracy: 0.5515\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6762 - accuracy: 0.5400 - val_loss: 1.6289 - val_accuracy: 0.5533\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6727 - accuracy: 0.5391 - val_loss: 1.6255 - val_accuracy: 0.5515\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 1.6673 - accuracy: 0.5399 - val_loss: 1.6206 - val_accuracy: 0.5561\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6634 - accuracy: 0.5400 - val_loss: 1.6202 - val_accuracy: 0.5530\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6581 - accuracy: 0.5409 - val_loss: 1.6152 - val_accuracy: 0.5502\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6548 - accuracy: 0.5415 - val_loss: 1.6145 - val_accuracy: 0.5536\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 1.6505 - accuracy: 0.5413 - val_loss: 1.6099 - val_accuracy: 0.5552\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6458 - accuracy: 0.5416 - val_loss: 1.6025 - val_accuracy: 0.5552\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6419 - accuracy: 0.5428 - val_loss: 1.5992 - val_accuracy: 0.5561\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6388 - accuracy: 0.5423 - val_loss: 1.6010 - val_accuracy: 0.5621\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6335 - accuracy: 0.5428 - val_loss: 1.5980 - val_accuracy: 0.5530\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6304 - accuracy: 0.5431 - val_loss: 1.5948 - val_accuracy: 0.5558\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6271 - accuracy: 0.5431 - val_loss: 1.5916 - val_accuracy: 0.5574\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6248 - accuracy: 0.5427 - val_loss: 1.5878 - val_accuracy: 0.5571\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.6204 - accuracy: 0.5442 - val_loss: 1.5903 - val_accuracy: 0.5558\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.6204 - accuracy: 0.5431 - val_loss: 1.5832 - val_accuracy: 0.5558\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6159 - accuracy: 0.5441 - val_loss: 1.5818 - val_accuracy: 0.5536\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6139 - accuracy: 0.5434 - val_loss: 1.5782 - val_accuracy: 0.5580\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6122 - accuracy: 0.5432 - val_loss: 1.5766 - val_accuracy: 0.5549\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6082 - accuracy: 0.5447 - val_loss: 1.5826 - val_accuracy: 0.5583\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6079 - accuracy: 0.5450 - val_loss: 1.5770 - val_accuracy: 0.5590\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6060 - accuracy: 0.5468 - val_loss: 1.5807 - val_accuracy: 0.5524\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6038 - accuracy: 0.5452 - val_loss: 1.5762 - val_accuracy: 0.5558\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6112 - accuracy: 0.5454 - val_loss: 1.5848 - val_accuracy: 0.5671\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6079 - accuracy: 0.5444 - val_loss: 1.5748 - val_accuracy: 0.5618\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6048 - accuracy: 0.5462 - val_loss: 1.5785 - val_accuracy: 0.5633\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6035 - accuracy: 0.5448 - val_loss: 1.5730 - val_accuracy: 0.5596\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.5991 - accuracy: 0.5460 - val_loss: 1.5782 - val_accuracy: 0.5543\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5985 - accuracy: 0.5458 - val_loss: 1.5747 - val_accuracy: 0.5602\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.5982 - accuracy: 0.5467 - val_loss: 1.5697 - val_accuracy: 0.5621\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.5988 - accuracy: 0.5453 - val_loss: 1.5873 - val_accuracy: 0.5530\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6082 - accuracy: 0.5453 - val_loss: 1.5839 - val_accuracy: 0.5624\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6089 - accuracy: 0.5464 - val_loss: 1.5749 - val_accuracy: 0.5565\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6032 - accuracy: 0.5447 - val_loss: 1.5777 - val_accuracy: 0.5540\n",
      "---- building model for layer width of 32 and 2048\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 10ms/step - loss: 2.0006 - accuracy: 0.5037 - val_loss: 1.7174 - val_accuracy: 0.5396\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7944 - accuracy: 0.5287 - val_loss: 1.7255 - val_accuracy: 0.5502\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8122 - accuracy: 0.5299 - val_loss: 1.9027 - val_accuracy: 0.5328\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9226 - accuracy: 0.5244 - val_loss: 2.0884 - val_accuracy: 0.5221\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0856 - accuracy: 0.5213 - val_loss: 2.1393 - val_accuracy: 0.5293\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.4233 - accuracy: 0.5168 - val_loss: 3.0412 - val_accuracy: 0.4991\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.9107 - accuracy: 0.5034 - val_loss: 3.5918 - val_accuracy: 0.5153\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.9791 - accuracy: 0.4972 - val_loss: 5.0002 - val_accuracy: 0.5028\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 8.3739 - accuracy: 0.4706 - val_loss: 16.8683 - val_accuracy: 0.4997\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 11.5664 - accuracy: 0.4765 - val_loss: 13.7622 - val_accuracy: 0.4732\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 16.6061 - accuracy: 0.4675 - val_loss: 18.9485 - val_accuracy: 0.4719\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 26.6090 - accuracy: 0.4581 - val_loss: 35.7389 - val_accuracy: 0.4386\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 33.2529 - accuracy: 0.4636 - val_loss: 32.5986 - val_accuracy: 0.4464\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 39.8999 - accuracy: 0.4626 - val_loss: 38.4898 - val_accuracy: 0.4828\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 54.0889 - accuracy: 0.4576 - val_loss: 46.1455 - val_accuracy: 0.4922\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 59.4228 - accuracy: 0.4579 - val_loss: 68.1911 - val_accuracy: 0.4523\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 70.2713 - accuracy: 0.4624 - val_loss: 78.6201 - val_accuracy: 0.4629\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 82.4955 - accuracy: 0.4624 - val_loss: 87.5505 - val_accuracy: 0.4386\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 91.7460 - accuracy: 0.4608 - val_loss: 88.9818 - val_accuracy: 0.4816\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 104.1629 - accuracy: 0.4593 - val_loss: 98.5665 - val_accuracy: 0.4941\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 127.1512 - accuracy: 0.4523 - val_loss: 114.9688 - val_accuracy: 0.5246\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 140.6168 - accuracy: 0.4596 - val_loss: 132.3361 - val_accuracy: 0.4641\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 155.3096 - accuracy: 0.4603 - val_loss: 201.7815 - val_accuracy: 0.4713\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 170.8534 - accuracy: 0.4566 - val_loss: 111.6038 - val_accuracy: 0.4972\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 166.9380 - accuracy: 0.4561 - val_loss: 189.9046 - val_accuracy: 0.5131\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 216.8874 - accuracy: 0.4479 - val_loss: 247.2628 - val_accuracy: 0.4903\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 230.6824 - accuracy: 0.4560 - val_loss: 297.4742 - val_accuracy: 0.4616\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 274.3599 - accuracy: 0.4511 - val_loss: 250.5947 - val_accuracy: 0.4435\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 235.6304 - accuracy: 0.4593 - val_loss: 212.7217 - val_accuracy: 0.4666\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 251.2044 - accuracy: 0.4613 - val_loss: 222.7600 - val_accuracy: 0.4660\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 280.0658 - accuracy: 0.4543 - val_loss: 303.2373 - val_accuracy: 0.4697\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 298.5327 - accuracy: 0.4579 - val_loss: 266.6425 - val_accuracy: 0.5069\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 312.0201 - accuracy: 0.4551 - val_loss: 339.8855 - val_accuracy: 0.4619\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 314.2976 - accuracy: 0.4588 - val_loss: 341.1703 - val_accuracy: 0.4239\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 380.8499 - accuracy: 0.4525 - val_loss: 336.7255 - val_accuracy: 0.4741\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 418.8044 - accuracy: 0.4438 - val_loss: 367.9230 - val_accuracy: 0.4978\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 405.8945 - accuracy: 0.4530 - val_loss: 320.4835 - val_accuracy: 0.5047\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 413.8394 - accuracy: 0.4569 - val_loss: 538.5648 - val_accuracy: 0.4379\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 476.2755 - accuracy: 0.4519 - val_loss: 375.4641 - val_accuracy: 0.4938\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 453.1188 - accuracy: 0.4580 - val_loss: 435.9640 - val_accuracy: 0.4782\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 499.0790 - accuracy: 0.4503 - val_loss: 464.7128 - val_accuracy: 0.4501\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 550.7261 - accuracy: 0.4513 - val_loss: 494.2891 - val_accuracy: 0.4794\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 512.3420 - accuracy: 0.4560 - val_loss: 605.9498 - val_accuracy: 0.4507\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 606.2986 - accuracy: 0.4466 - val_loss: 483.5432 - val_accuracy: 0.4598\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 594.5413 - accuracy: 0.4535 - val_loss: 609.0656 - val_accuracy: 0.4086\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 621.6960 - accuracy: 0.4519 - val_loss: 646.2516 - val_accuracy: 0.4744\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 679.4117 - accuracy: 0.4535 - val_loss: 636.1486 - val_accuracy: 0.4510\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 683.4824 - accuracy: 0.4534 - val_loss: 607.6417 - val_accuracy: 0.4660\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 671.9337 - accuracy: 0.4496 - val_loss: 669.5950 - val_accuracy: 0.4888\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 641.8026 - accuracy: 0.4613 - val_loss: 832.7977 - val_accuracy: 0.4529\n",
      "---- building model for layer width of 32 and 64\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 11ms/step - loss: 2.6719 - accuracy: 0.4456 - val_loss: 1.8791 - val_accuracy: 0.5031\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 1.8375 - accuracy: 0.5132 - val_loss: 1.7185 - val_accuracy: 0.5465\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.7388 - accuracy: 0.5276 - val_loss: 1.6813 - val_accuracy: 0.5434\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7069 - accuracy: 0.5340 - val_loss: 1.6700 - val_accuracy: 0.5381\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6891 - accuracy: 0.5363 - val_loss: 1.6439 - val_accuracy: 0.5515\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6676 - accuracy: 0.5401 - val_loss: 1.6216 - val_accuracy: 0.5549\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6577 - accuracy: 0.5420 - val_loss: 1.6436 - val_accuracy: 0.5381\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6524 - accuracy: 0.5424 - val_loss: 1.6520 - val_accuracy: 0.5577\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6600 - accuracy: 0.5421 - val_loss: 1.6331 - val_accuracy: 0.5546\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6612 - accuracy: 0.5402 - val_loss: 1.6655 - val_accuracy: 0.5459\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6701 - accuracy: 0.5398 - val_loss: 1.6614 - val_accuracy: 0.5540\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6882 - accuracy: 0.5412 - val_loss: 1.6934 - val_accuracy: 0.5521\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7121 - accuracy: 0.5385 - val_loss: 1.6794 - val_accuracy: 0.5518\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7588 - accuracy: 0.5368 - val_loss: 1.7699 - val_accuracy: 0.5377\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7557 - accuracy: 0.5381 - val_loss: 1.8131 - val_accuracy: 0.5437\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7830 - accuracy: 0.5351 - val_loss: 1.8557 - val_accuracy: 0.5393\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7999 - accuracy: 0.5337 - val_loss: 1.8872 - val_accuracy: 0.5234\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8400 - accuracy: 0.5345 - val_loss: 1.7604 - val_accuracy: 0.5387\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8247 - accuracy: 0.5396 - val_loss: 1.9623 - val_accuracy: 0.5452\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8720 - accuracy: 0.5346 - val_loss: 2.1129 - val_accuracy: 0.5356\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8926 - accuracy: 0.5283 - val_loss: 1.9108 - val_accuracy: 0.5268\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9914 - accuracy: 0.5319 - val_loss: 2.2822 - val_accuracy: 0.5281\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9936 - accuracy: 0.5273 - val_loss: 2.3280 - val_accuracy: 0.5374\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0588 - accuracy: 0.5252 - val_loss: 2.5252 - val_accuracy: 0.4984\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1515 - accuracy: 0.5271 - val_loss: 2.1839 - val_accuracy: 0.5296\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.1374 - accuracy: 0.5248 - val_loss: 1.9056 - val_accuracy: 0.5271\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2107 - accuracy: 0.5219 - val_loss: 2.4903 - val_accuracy: 0.5156\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2775 - accuracy: 0.5223 - val_loss: 2.3675 - val_accuracy: 0.5262\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.4249 - accuracy: 0.5172 - val_loss: 3.4586 - val_accuracy: 0.5421\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.9122 - accuracy: 0.5121 - val_loss: 2.4247 - val_accuracy: 0.5356\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.7730 - accuracy: 0.5081 - val_loss: 2.7102 - val_accuracy: 0.5243\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.8516 - accuracy: 0.5103 - val_loss: 2.7208 - val_accuracy: 0.5505\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.5128 - accuracy: 0.5201 - val_loss: 2.6409 - val_accuracy: 0.4669\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.8060 - accuracy: 0.5077 - val_loss: 3.7714 - val_accuracy: 0.5209\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 3.7387 - accuracy: 0.5040 - val_loss: 3.8266 - val_accuracy: 0.5331\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 3.2440 - accuracy: 0.4969 - val_loss: 3.7780 - val_accuracy: 0.4934\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 4.1929 - accuracy: 0.4949 - val_loss: 4.4423 - val_accuracy: 0.4978\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 3.8982 - accuracy: 0.5025 - val_loss: 3.1206 - val_accuracy: 0.5281\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 4.7596 - accuracy: 0.4910 - val_loss: 4.4161 - val_accuracy: 0.5415\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 4.2253 - accuracy: 0.5023 - val_loss: 4.0178 - val_accuracy: 0.5290\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.4549 - accuracy: 0.4949 - val_loss: 4.2194 - val_accuracy: 0.5309\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 4.0819 - accuracy: 0.5012 - val_loss: 3.7075 - val_accuracy: 0.5025\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.1808 - accuracy: 0.4967 - val_loss: 5.2604 - val_accuracy: 0.4872\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.2337 - accuracy: 0.4961 - val_loss: 4.7007 - val_accuracy: 0.5112\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.7429 - accuracy: 0.4897 - val_loss: 6.3785 - val_accuracy: 0.5296\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.4125 - accuracy: 0.4923 - val_loss: 3.2678 - val_accuracy: 0.5337\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 6.2930 - accuracy: 0.4840 - val_loss: 5.9747 - val_accuracy: 0.4997\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 7.9541 - accuracy: 0.4821 - val_loss: 6.5509 - val_accuracy: 0.5250\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 6.3707 - accuracy: 0.4882 - val_loss: 8.5371 - val_accuracy: 0.5162\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 7.5375 - accuracy: 0.4831 - val_loss: 8.0194 - val_accuracy: 0.4663\n",
      "---- building model for layer width of 2048 and 64\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 4s 10ms/step - loss: 2.5061 - accuracy: 0.4623 - val_loss: 1.8968 - val_accuracy: 0.5312\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9693 - accuracy: 0.5166 - val_loss: 1.8233 - val_accuracy: 0.5443\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.8728 - accuracy: 0.5219 - val_loss: 1.8151 - val_accuracy: 0.5315\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9128 - accuracy: 0.5230 - val_loss: 1.9709 - val_accuracy: 0.5296\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0939 - accuracy: 0.5151 - val_loss: 2.1590 - val_accuracy: 0.5231\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1272 - accuracy: 0.5191 - val_loss: 2.2169 - val_accuracy: 0.5256\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.4225 - accuracy: 0.5129 - val_loss: 2.6830 - val_accuracy: 0.5449\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.7400 - accuracy: 0.5122 - val_loss: 3.4858 - val_accuracy: 0.5115\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.9383 - accuracy: 0.5038 - val_loss: 3.8239 - val_accuracy: 0.5262\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.5904 - accuracy: 0.4883 - val_loss: 5.4626 - val_accuracy: 0.4991\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 5.4822 - accuracy: 0.4889 - val_loss: 4.8170 - val_accuracy: 0.5518\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 6.6269 - accuracy: 0.4826 - val_loss: 6.8503 - val_accuracy: 0.4061\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 7.7049 - accuracy: 0.4774 - val_loss: 8.4217 - val_accuracy: 0.4916\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 9.0934 - accuracy: 0.4755 - val_loss: 9.3291 - val_accuracy: 0.3768\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 13.7085 - accuracy: 0.4635 - val_loss: 16.8500 - val_accuracy: 0.5178\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 14.7354 - accuracy: 0.4683 - val_loss: 18.1288 - val_accuracy: 0.4810\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 18.3136 - accuracy: 0.4553 - val_loss: 27.7821 - val_accuracy: 0.4585\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 22.4845 - accuracy: 0.4600 - val_loss: 23.1804 - val_accuracy: 0.4754\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 23.9283 - accuracy: 0.4558 - val_loss: 35.2141 - val_accuracy: 0.3047\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 26.5989 - accuracy: 0.4626 - val_loss: 31.2853 - val_accuracy: 0.4857\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 32.7205 - accuracy: 0.4573 - val_loss: 29.5719 - val_accuracy: 0.4648\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 37.5536 - accuracy: 0.4562 - val_loss: 34.2560 - val_accuracy: 0.4251\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 39.1498 - accuracy: 0.4600 - val_loss: 39.9730 - val_accuracy: 0.4507\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 47.5879 - accuracy: 0.4494 - val_loss: 48.4169 - val_accuracy: 0.4719\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 49.9013 - accuracy: 0.4534 - val_loss: 67.2735 - val_accuracy: 0.3515\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 50.3399 - accuracy: 0.4640 - val_loss: 50.6548 - val_accuracy: 0.4913\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 52.8711 - accuracy: 0.4592 - val_loss: 62.9927 - val_accuracy: 0.3971\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 63.6297 - accuracy: 0.4535 - val_loss: 61.5016 - val_accuracy: 0.4866\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 76.1234 - accuracy: 0.4553 - val_loss: 75.4025 - val_accuracy: 0.5296\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 71.8841 - accuracy: 0.4586 - val_loss: 60.6189 - val_accuracy: 0.5212\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 80.1563 - accuracy: 0.4559 - val_loss: 86.1343 - val_accuracy: 0.5016\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 87.4807 - accuracy: 0.4582 - val_loss: 83.3149 - val_accuracy: 0.4775\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 84.3631 - accuracy: 0.4618 - val_loss: 108.0397 - val_accuracy: 0.3862\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 92.2789 - accuracy: 0.4550 - val_loss: 79.5551 - val_accuracy: 0.4810\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 105.4117 - accuracy: 0.4551 - val_loss: 92.9361 - val_accuracy: 0.4841\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 99.7438 - accuracy: 0.4693 - val_loss: 85.4155 - val_accuracy: 0.4963\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 97.0165 - accuracy: 0.4704 - val_loss: 104.1197 - val_accuracy: 0.4722\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 114.3448 - accuracy: 0.4608 - val_loss: 157.1278 - val_accuracy: 0.4657\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 125.4621 - accuracy: 0.4648 - val_loss: 100.4708 - val_accuracy: 0.5084\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 109.1326 - accuracy: 0.4675 - val_loss: 145.6990 - val_accuracy: 0.3565\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 134.5509 - accuracy: 0.4548 - val_loss: 111.4285 - val_accuracy: 0.5081\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 135.6425 - accuracy: 0.4597 - val_loss: 160.8936 - val_accuracy: 0.3687\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 139.1235 - accuracy: 0.4679 - val_loss: 163.5725 - val_accuracy: 0.4588\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 141.9076 - accuracy: 0.4609 - val_loss: 139.1966 - val_accuracy: 0.5119\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 150.5724 - accuracy: 0.4684 - val_loss: 133.2305 - val_accuracy: 0.5066\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 154.5416 - accuracy: 0.4672 - val_loss: 161.2000 - val_accuracy: 0.4922\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 169.6212 - accuracy: 0.4577 - val_loss: 159.8283 - val_accuracy: 0.4541\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 160.8869 - accuracy: 0.4649 - val_loss: 153.6220 - val_accuracy: 0.4959\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 195.9633 - accuracy: 0.4555 - val_loss: 210.6871 - val_accuracy: 0.4754\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 189.1018 - accuracy: 0.4650 - val_loss: 172.5638 - val_accuracy: 0.5203\n",
      "---- building model for layer width of 2048 and 8\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 10ms/step - loss: 2.7978 - accuracy: 0.4922 - val_loss: 2.1135 - val_accuracy: 0.5502\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0033 - accuracy: 0.5323 - val_loss: 1.8100 - val_accuracy: 0.5462\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.8235 - accuracy: 0.5324 - val_loss: 1.7381 - val_accuracy: 0.5393\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7886 - accuracy: 0.5267 - val_loss: 1.7029 - val_accuracy: 0.5434\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8002 - accuracy: 0.5252 - val_loss: 1.7832 - val_accuracy: 0.5365\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9209 - accuracy: 0.5190 - val_loss: 1.9971 - val_accuracy: 0.5047\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0626 - accuracy: 0.5076 - val_loss: 2.0708 - val_accuracy: 0.5490\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0098 - accuracy: 0.5083 - val_loss: 1.8531 - val_accuracy: 0.5427\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9755 - accuracy: 0.5150 - val_loss: 2.0303 - val_accuracy: 0.5296\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0309 - accuracy: 0.5187 - val_loss: 1.8946 - val_accuracy: 0.5303\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1358 - accuracy: 0.5156 - val_loss: 2.0551 - val_accuracy: 0.5209\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1072 - accuracy: 0.5188 - val_loss: 1.9464 - val_accuracy: 0.5365\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1358 - accuracy: 0.5101 - val_loss: 1.9081 - val_accuracy: 0.5340\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0680 - accuracy: 0.5175 - val_loss: 2.0479 - val_accuracy: 0.4928\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.1045 - accuracy: 0.5144 - val_loss: 2.0143 - val_accuracy: 0.5471\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0640 - accuracy: 0.5149 - val_loss: 1.9734 - val_accuracy: 0.5328\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.1306 - accuracy: 0.5142 - val_loss: 2.3384 - val_accuracy: 0.4847\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1629 - accuracy: 0.5089 - val_loss: 2.1418 - val_accuracy: 0.5499\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.2105 - accuracy: 0.5092 - val_loss: 2.1722 - val_accuracy: 0.5256\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.2834 - accuracy: 0.5061 - val_loss: 2.3823 - val_accuracy: 0.4885\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.4394 - accuracy: 0.4940 - val_loss: 2.7208 - val_accuracy: 0.5343\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.5020 - accuracy: 0.4993 - val_loss: 2.8651 - val_accuracy: 0.4576\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.7241 - accuracy: 0.4895 - val_loss: 3.1102 - val_accuracy: 0.4713\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.8328 - accuracy: 0.4829 - val_loss: 2.8619 - val_accuracy: 0.5090\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.3257 - accuracy: 0.4817 - val_loss: 3.6785 - val_accuracy: 0.4691\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.2737 - accuracy: 0.4784 - val_loss: 4.4568 - val_accuracy: 0.4860\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.5113 - accuracy: 0.4830 - val_loss: 3.5971 - val_accuracy: 0.4726\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.5944 - accuracy: 0.4741 - val_loss: 4.7300 - val_accuracy: 0.4669\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.1290 - accuracy: 0.4745 - val_loss: 4.8108 - val_accuracy: 0.4741\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.9659 - accuracy: 0.4687 - val_loss: 4.9248 - val_accuracy: 0.4710\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 5.5258 - accuracy: 0.4676 - val_loss: 6.0744 - val_accuracy: 0.4803\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 6.3182 - accuracy: 0.4598 - val_loss: 7.7055 - val_accuracy: 0.4616\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 10.3886 - accuracy: 0.4528 - val_loss: 12.1865 - val_accuracy: 0.4226\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 11.2207 - accuracy: 0.4480 - val_loss: 12.6560 - val_accuracy: 0.4217\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 13.7356 - accuracy: 0.4549 - val_loss: 11.9772 - val_accuracy: 0.4772\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 10.0441 - accuracy: 0.4597 - val_loss: 11.8920 - val_accuracy: 0.4841\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 10.9468 - accuracy: 0.4585 - val_loss: 12.1667 - val_accuracy: 0.4969\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 15.8551 - accuracy: 0.4442 - val_loss: 18.8914 - val_accuracy: 0.4838\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 18.2504 - accuracy: 0.4471 - val_loss: 14.0673 - val_accuracy: 0.4941\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 20.3710 - accuracy: 0.4306 - val_loss: 19.7210 - val_accuracy: 0.4891\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 19.3939 - accuracy: 0.4427 - val_loss: 15.8782 - val_accuracy: 0.4885\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 20.1503 - accuracy: 0.4376 - val_loss: 25.1628 - val_accuracy: 0.4448\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 25.1746 - accuracy: 0.4360 - val_loss: 22.9036 - val_accuracy: 0.4685\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 25.9069 - accuracy: 0.4293 - val_loss: 29.2070 - val_accuracy: 0.3553\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 27.7331 - accuracy: 0.4553 - val_loss: 26.2326 - val_accuracy: 0.4548\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 26.3085 - accuracy: 0.4473 - val_loss: 29.2846 - val_accuracy: 0.4573\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 27.0709 - accuracy: 0.4464 - val_loss: 23.1203 - val_accuracy: 0.4928\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 29.6199 - accuracy: 0.4343 - val_loss: 37.7532 - val_accuracy: 0.4451\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 29.3579 - accuracy: 0.4476 - val_loss: 32.1610 - val_accuracy: 0.4591\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 37.8387 - accuracy: 0.4300 - val_loss: 46.3135 - val_accuracy: 0.4070\n",
      "---- building model for layer width of 128 and 16\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 10ms/step - loss: 2.9159 - accuracy: 0.4371 - val_loss: 2.1414 - val_accuracy: 0.4853\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0818 - accuracy: 0.4881 - val_loss: 1.9753 - val_accuracy: 0.5156\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8867 - accuracy: 0.5089 - val_loss: 1.7591 - val_accuracy: 0.5337\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8142 - accuracy: 0.5194 - val_loss: 1.7557 - val_accuracy: 0.5343\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7981 - accuracy: 0.5255 - val_loss: 1.7583 - val_accuracy: 0.5328\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7828 - accuracy: 0.5270 - val_loss: 1.7510 - val_accuracy: 0.5462\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7882 - accuracy: 0.5292 - val_loss: 1.7296 - val_accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7628 - accuracy: 0.5299 - val_loss: 1.7335 - val_accuracy: 0.5365\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7599 - accuracy: 0.5278 - val_loss: 1.7996 - val_accuracy: 0.5549\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7557 - accuracy: 0.5325 - val_loss: 1.7341 - val_accuracy: 0.5549\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7476 - accuracy: 0.5317 - val_loss: 1.7243 - val_accuracy: 0.5356\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.7477 - accuracy: 0.5306 - val_loss: 1.7195 - val_accuracy: 0.5508\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7522 - accuracy: 0.5317 - val_loss: 1.7018 - val_accuracy: 0.5424\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7587 - accuracy: 0.5326 - val_loss: 1.7210 - val_accuracy: 0.5465\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7591 - accuracy: 0.5299 - val_loss: 1.7728 - val_accuracy: 0.5552\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7531 - accuracy: 0.5321 - val_loss: 1.7492 - val_accuracy: 0.5384\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7577 - accuracy: 0.5325 - val_loss: 1.6938 - val_accuracy: 0.5502\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7508 - accuracy: 0.5314 - val_loss: 1.8068 - val_accuracy: 0.5374\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7686 - accuracy: 0.5302 - val_loss: 1.7219 - val_accuracy: 0.5480\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7530 - accuracy: 0.5327 - val_loss: 1.7898 - val_accuracy: 0.5190\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7762 - accuracy: 0.5307 - val_loss: 1.7406 - val_accuracy: 0.5533\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7916 - accuracy: 0.5289 - val_loss: 1.8168 - val_accuracy: 0.5384\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7821 - accuracy: 0.5292 - val_loss: 1.7728 - val_accuracy: 0.5512\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 1.7846 - accuracy: 0.5317 - val_loss: 1.7712 - val_accuracy: 0.5409\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.7656 - accuracy: 0.5328 - val_loss: 1.7714 - val_accuracy: 0.5390\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7847 - accuracy: 0.5295 - val_loss: 1.8066 - val_accuracy: 0.5421\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8001 - accuracy: 0.5286 - val_loss: 1.8056 - val_accuracy: 0.5265\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7828 - accuracy: 0.5321 - val_loss: 1.7538 - val_accuracy: 0.5430\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8005 - accuracy: 0.5312 - val_loss: 1.8188 - val_accuracy: 0.5474\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8054 - accuracy: 0.5289 - val_loss: 1.7831 - val_accuracy: 0.5303\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1.8197 - accuracy: 0.5296 - val_loss: 1.7890 - val_accuracy: 0.5455\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.8230 - accuracy: 0.5310 - val_loss: 1.8613 - val_accuracy: 0.5530\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.8377 - accuracy: 0.5294 - val_loss: 1.8556 - val_accuracy: 0.5331\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8528 - accuracy: 0.5278 - val_loss: 1.8802 - val_accuracy: 0.5409\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8692 - accuracy: 0.5270 - val_loss: 1.8149 - val_accuracy: 0.5290\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8550 - accuracy: 0.5271 - val_loss: 1.8040 - val_accuracy: 0.5418\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8982 - accuracy: 0.5253 - val_loss: 1.8710 - val_accuracy: 0.5299\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8608 - accuracy: 0.5296 - val_loss: 2.0454 - val_accuracy: 0.5265\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9214 - accuracy: 0.5250 - val_loss: 1.8294 - val_accuracy: 0.5334\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8893 - accuracy: 0.5275 - val_loss: 1.9500 - val_accuracy: 0.5328\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9056 - accuracy: 0.5296 - val_loss: 1.9692 - val_accuracy: 0.5493\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9661 - accuracy: 0.5262 - val_loss: 1.7995 - val_accuracy: 0.5418\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9290 - accuracy: 0.5289 - val_loss: 1.9387 - val_accuracy: 0.5465\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9970 - accuracy: 0.5228 - val_loss: 2.0350 - val_accuracy: 0.5490\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9701 - accuracy: 0.5264 - val_loss: 2.0505 - val_accuracy: 0.5284\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.9883 - accuracy: 0.5261 - val_loss: 2.0167 - val_accuracy: 0.5250\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.9766 - accuracy: 0.5227 - val_loss: 2.1274 - val_accuracy: 0.5377\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0668 - accuracy: 0.5175 - val_loss: 2.0701 - val_accuracy: 0.5293\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.0379 - accuracy: 0.5211 - val_loss: 2.3307 - val_accuracy: 0.4872\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.1226 - accuracy: 0.5185 - val_loss: 2.3373 - val_accuracy: 0.5552\n",
      "---- building model for layer width of 32 and 128\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 10ms/step - loss: 2.1479 - accuracy: 0.4841 - val_loss: 1.7445 - val_accuracy: 0.5274\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7653 - accuracy: 0.5259 - val_loss: 1.7012 - val_accuracy: 0.5231\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7327 - accuracy: 0.5356 - val_loss: 1.6779 - val_accuracy: 0.5505\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.7053 - accuracy: 0.5363 - val_loss: 1.6852 - val_accuracy: 0.5502\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.7001 - accuracy: 0.5394 - val_loss: 1.6380 - val_accuracy: 0.5462\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 1.6866 - accuracy: 0.5402 - val_loss: 1.6907 - val_accuracy: 0.5468\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.6881 - accuracy: 0.5392 - val_loss: 1.6769 - val_accuracy: 0.5590\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.6937 - accuracy: 0.5394 - val_loss: 1.6521 - val_accuracy: 0.5565\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.6850 - accuracy: 0.5393 - val_loss: 1.7193 - val_accuracy: 0.5577\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7373 - accuracy: 0.5349 - val_loss: 1.7225 - val_accuracy: 0.5536\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.7602 - accuracy: 0.5368 - val_loss: 1.7852 - val_accuracy: 0.5555\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8067 - accuracy: 0.5303 - val_loss: 1.8712 - val_accuracy: 0.5399\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8116 - accuracy: 0.5354 - val_loss: 1.8400 - val_accuracy: 0.5455\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 1.8301 - accuracy: 0.5324 - val_loss: 1.7811 - val_accuracy: 0.5427\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 1.8844 - accuracy: 0.5314 - val_loss: 1.9995 - val_accuracy: 0.5312\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1.9364 - accuracy: 0.5305 - val_loss: 2.1018 - val_accuracy: 0.5306\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.0220 - accuracy: 0.5263 - val_loss: 2.2338 - val_accuracy: 0.4878\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.0660 - accuracy: 0.5240 - val_loss: 1.9802 - val_accuracy: 0.5284\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.1497 - accuracy: 0.5232 - val_loss: 2.2098 - val_accuracy: 0.5156\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2026 - accuracy: 0.5259 - val_loss: 2.7616 - val_accuracy: 0.5552\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.2869 - accuracy: 0.5179 - val_loss: 2.6954 - val_accuracy: 0.3968\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.1869 - accuracy: 0.5209 - val_loss: 2.9794 - val_accuracy: 0.5156\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.6396 - accuracy: 0.5179 - val_loss: 2.3616 - val_accuracy: 0.5237\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 2.4825 - accuracy: 0.5153 - val_loss: 2.4649 - val_accuracy: 0.5119\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 2.6655 - accuracy: 0.5079 - val_loss: 2.8855 - val_accuracy: 0.5009\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2.7640 - accuracy: 0.5117 - val_loss: 3.3402 - val_accuracy: 0.4953\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 2.9514 - accuracy: 0.5073 - val_loss: 2.7229 - val_accuracy: 0.5003\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 2.9885 - accuracy: 0.5105 - val_loss: 3.5044 - val_accuracy: 0.4922\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.2531 - accuracy: 0.5061 - val_loss: 3.1885 - val_accuracy: 0.5340\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 3.0977 - accuracy: 0.5050 - val_loss: 3.4143 - val_accuracy: 0.4074\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.0147 - accuracy: 0.4999 - val_loss: 3.9632 - val_accuracy: 0.5106\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 3.3983 - accuracy: 0.5042 - val_loss: 4.3492 - val_accuracy: 0.4704\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 3.7764 - accuracy: 0.4999 - val_loss: 3.2967 - val_accuracy: 0.5115\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.4130 - accuracy: 0.4940 - val_loss: 4.0288 - val_accuracy: 0.5128\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.1230 - accuracy: 0.4995 - val_loss: 5.3997 - val_accuracy: 0.5187\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 4.3017 - accuracy: 0.4996 - val_loss: 5.0809 - val_accuracy: 0.4495\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 5.1317 - accuracy: 0.4871 - val_loss: 4.8587 - val_accuracy: 0.5324\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.3926 - accuracy: 0.4906 - val_loss: 6.3663 - val_accuracy: 0.4863\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 6.2967 - accuracy: 0.4782 - val_loss: 4.9534 - val_accuracy: 0.5037\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.5275 - accuracy: 0.4902 - val_loss: 6.0992 - val_accuracy: 0.4601\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.7975 - accuracy: 0.4877 - val_loss: 4.6919 - val_accuracy: 0.5056\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 5.3406 - accuracy: 0.4945 - val_loss: 4.9884 - val_accuracy: 0.5081\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 6.9200 - accuracy: 0.4835 - val_loss: 6.2254 - val_accuracy: 0.5081\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 7.2110 - accuracy: 0.4821 - val_loss: 7.0325 - val_accuracy: 0.5168\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 6.3177 - accuracy: 0.4916 - val_loss: 8.0762 - val_accuracy: 0.4570\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 7.7075 - accuracy: 0.4820 - val_loss: 7.0425 - val_accuracy: 0.4825\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 8.9169 - accuracy: 0.4773 - val_loss: 11.3301 - val_accuracy: 0.4763\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 9.3716 - accuracy: 0.4807 - val_loss: 9.2026 - val_accuracy: 0.4828\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 8ms/step - loss: 8.7930 - accuracy: 0.4784 - val_loss: 9.2769 - val_accuracy: 0.4566\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 9.6243 - accuracy: 0.4732 - val_loss: 8.3509 - val_accuracy: 0.4473\n",
      "---- building model for layer width of 512 and 2048\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 2.9711 - accuracy: 0.4920 - val_loss: 2.4005 - val_accuracy: 0.4638\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 2.3441 - accuracy: 0.5117 - val_loss: 2.6847 - val_accuracy: 0.5221\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 6.4061 - accuracy: 0.4800 - val_loss: 13.1869 - val_accuracy: 0.4386\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 20.0908 - accuracy: 0.4645 - val_loss: 34.0068 - val_accuracy: 0.4582\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 42.9222 - accuracy: 0.4621 - val_loss: 58.8317 - val_accuracy: 0.4894\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 82.5334 - accuracy: 0.4552 - val_loss: 95.6428 - val_accuracy: 0.4651\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 123.8443 - accuracy: 0.4569 - val_loss: 168.0216 - val_accuracy: 0.4186\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 168.6250 - accuracy: 0.4637 - val_loss: 213.7364 - val_accuracy: 0.4713\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 207.1640 - accuracy: 0.4619 - val_loss: 247.3903 - val_accuracy: 0.4747\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 2s 12ms/step - loss: 279.4369 - accuracy: 0.4598 - val_loss: 401.9713 - val_accuracy: 0.4398\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 328.4519 - accuracy: 0.4617 - val_loss: 470.6111 - val_accuracy: 0.4772\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 457.8808 - accuracy: 0.4567 - val_loss: 442.3614 - val_accuracy: 0.4750\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 602.1980 - accuracy: 0.4529 - val_loss: 704.2033 - val_accuracy: 0.4510\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 638.6810 - accuracy: 0.4630 - val_loss: 613.4526 - val_accuracy: 0.4785\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 689.2101 - accuracy: 0.4625 - val_loss: 710.5958 - val_accuracy: 0.4557\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 788.4559 - accuracy: 0.4641 - val_loss: 847.7568 - val_accuracy: 0.4760\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 992.5837 - accuracy: 0.4562 - val_loss: 1060.0723 - val_accuracy: 0.5084\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1142.3344 - accuracy: 0.4559 - val_loss: 1272.0492 - val_accuracy: 0.4429\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 1204.0334 - accuracy: 0.4559 - val_loss: 992.4310 - val_accuracy: 0.4881\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1381.4086 - accuracy: 0.4588 - val_loss: 1887.7932 - val_accuracy: 0.4457\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1715.0504 - accuracy: 0.4475 - val_loss: 1734.9528 - val_accuracy: 0.4538\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 1808.6062 - accuracy: 0.4547 - val_loss: 2441.8218 - val_accuracy: 0.4342\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 1956.0156 - accuracy: 0.4554 - val_loss: 2076.6108 - val_accuracy: 0.4875\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 2081.5010 - accuracy: 0.4568 - val_loss: 2343.9226 - val_accuracy: 0.4208\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 2229.3967 - accuracy: 0.4514 - val_loss: 2869.2100 - val_accuracy: 0.4410\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 2673.7639 - accuracy: 0.4535 - val_loss: 2657.4316 - val_accuracy: 0.4754\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 2608.4653 - accuracy: 0.4599 - val_loss: 2419.8262 - val_accuracy: 0.4473\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 2928.4983 - accuracy: 0.4545 - val_loss: 3292.7251 - val_accuracy: 0.4420\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 3266.8257 - accuracy: 0.4518 - val_loss: 3101.5037 - val_accuracy: 0.4807\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 3253.8503 - accuracy: 0.4576 - val_loss: 3590.0046 - val_accuracy: 0.4460\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 1s 9ms/step - loss: 3866.7927 - accuracy: 0.4501 - val_loss: 3231.5818 - val_accuracy: 0.4601\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 3907.5776 - accuracy: 0.4516 - val_loss: 4045.1829 - val_accuracy: 0.4566\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 4206.6162 - accuracy: 0.4548 - val_loss: 4115.3462 - val_accuracy: 0.4931\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 4613.0908 - accuracy: 0.4546 - val_loss: 5107.8027 - val_accuracy: 0.4638\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 4695.5278 - accuracy: 0.4520 - val_loss: 6240.8633 - val_accuracy: 0.4619\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 5311.2251 - accuracy: 0.4471 - val_loss: 4629.8604 - val_accuracy: 0.4919\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 5998.1353 - accuracy: 0.4397 - val_loss: 5499.7598 - val_accuracy: 0.4925\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 6212.5488 - accuracy: 0.4414 - val_loss: 5003.2656 - val_accuracy: 0.5016\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 6260.1050 - accuracy: 0.4416 - val_loss: 5896.4829 - val_accuracy: 0.4719\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 6622.5273 - accuracy: 0.4454 - val_loss: 6879.1753 - val_accuracy: 0.4361\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 1s 11ms/step - loss: 7692.8960 - accuracy: 0.4308 - val_loss: 8090.3955 - val_accuracy: 0.4304\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 8246.8887 - accuracy: 0.4316 - val_loss: 6491.5757 - val_accuracy: 0.4451\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 2s 16ms/step - loss: 8252.5293 - accuracy: 0.4293 - val_loss: 9050.5605 - val_accuracy: 0.4803\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 2s 14ms/step - loss: 9421.4658 - accuracy: 0.4258 - val_loss: 8530.3604 - val_accuracy: 0.4570\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 2s 13ms/step - loss: 9723.0977 - accuracy: 0.4259 - val_loss: 10054.6396 - val_accuracy: 0.4648\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 10034.7793 - accuracy: 0.4288 - val_loss: 10773.7275 - val_accuracy: 0.4242\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 11356.9277 - accuracy: 0.4203 - val_loss: 8643.7422 - val_accuracy: 0.4323\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 11640.3818 - accuracy: 0.4112 - val_loss: 13012.1631 - val_accuracy: 0.4183\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 13516.7393 - accuracy: 0.4080 - val_loss: 11543.4033 - val_accuracy: 0.4011\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 1s 10ms/step - loss: 13676.7578 - accuracy: 0.4046 - val_loss: 13349.9043 - val_accuracy: 0.4230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 Width</th>\n",
       "      <th>Layer 2 Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.534706</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>637.563354</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.459082</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.531664</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>335.528992</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.482285</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.546795</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.654783</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.535679</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.529871</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>927.871643</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.430140</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.542427</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>8.651600</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.446607</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>177.194260</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.500250</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.532444</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>51.058582</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.387226</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.532756</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>2.464714</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.530190</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.540165</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>8.818531</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.405689</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>14535.639648</td>\n",
       "      <td>Test Loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.406188</td>\n",
       "      <td>Test Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 Width  Layer 2 Width  Metrics Value         Metrics Type\n",
       "0             256            256       0.534706  Validation Accuracy\n",
       "1             256            256     637.563354            Test Loss\n",
       "2             256            256       0.459082        Test Accuracy\n",
       "3              16           2048       0.531664  Validation Accuracy\n",
       "4              16           2048     335.528992            Test Loss\n",
       "5              16           2048       0.482285        Test Accuracy\n",
       "6               4              8       0.546795  Validation Accuracy\n",
       "7               4              8       1.654783            Test Loss\n",
       "8               4              8       0.535679        Test Accuracy\n",
       "9              32           2048       0.529871  Validation Accuracy\n",
       "10             32           2048     927.871643            Test Loss\n",
       "11             32           2048       0.430140        Test Accuracy\n",
       "12             32             64       0.542427  Validation Accuracy\n",
       "13             32             64       8.651600            Test Loss\n",
       "14             32             64       0.446607        Test Accuracy\n",
       "15           2048             64       0.523007  Validation Accuracy\n",
       "16           2048             64     177.194260            Test Loss\n",
       "17           2048             64       0.500250        Test Accuracy\n",
       "18           2048              8       0.532444  Validation Accuracy\n",
       "19           2048              8      51.058582            Test Loss\n",
       "20           2048              8       0.387226        Test Accuracy\n",
       "21            128             16       0.532756  Validation Accuracy\n",
       "22            128             16       2.464714            Test Loss\n",
       "23            128             16       0.530190        Test Accuracy\n",
       "24             32            128       0.540165  Validation Accuracy\n",
       "25             32            128       8.818531            Test Loss\n",
       "26             32            128       0.405689        Test Accuracy\n",
       "27            512           2048       0.511699  Validation Accuracy\n",
       "28            512           2048   14535.639648            Test Loss\n",
       "29            512           2048       0.406188        Test Accuracy"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    r1 = random.randint(2, 12)\n",
    "    r2 = random.randint(2, 12)\n",
    "    \n",
    "    l1 = 2 ** r1\n",
    "    l2 = 2 ** r2\n",
    "    \n",
    "    print(\"---- building model for layer width of \" + str(l1) + \" and \" + str(l2))\n",
    "    d = DNN()\n",
    "    d.customize_first_layer(l1)\n",
    "    d.add_one_dense_layer(l2)\n",
    "    \n",
    "    #d.customize_fit(epochs = 2) ## TODO: REMOVE\n",
    "    \n",
    "    val_acc_result = d.build_compile_and_evaluate()\n",
    "    test_loss, test_accuracy = d.evaluate_model_with_test()\n",
    "    \n",
    "    results.append((l1, l2, val_acc_result, \"Validation Accuracy\"))\n",
    "    results.append((l1, l2, test_loss, \"Test Loss\"))\n",
    "    results.append((l1, l2, test_accuracy, \"Test Accuracy\"))\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results = results.rename(columns = {\n",
    "    0: \"Layer 1 Width\",\n",
    "    1: \"Layer 2 Width\",\n",
    "    2: \"Metrics Value\",\n",
    "    3: \"Metrics Type\"\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer 1 Width</th>\n",
       "      <th>Layer 2 Width</th>\n",
       "      <th>Metrics Value</th>\n",
       "      <th>Metrics Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>0.534706</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.531664</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.546795</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.529871</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>0.542427</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>0.523007</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.532444</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.532756</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>0.540165</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>Validation Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer 1 Width  Layer 2 Width  Metrics Value         Metrics Type\n",
       "0             256            256       0.534706  Validation Accuracy\n",
       "3              16           2048       0.531664  Validation Accuracy\n",
       "6               4              8       0.546795  Validation Accuracy\n",
       "9              32           2048       0.529871  Validation Accuracy\n",
       "12             32             64       0.542427  Validation Accuracy\n",
       "15           2048             64       0.523007  Validation Accuracy\n",
       "18           2048              8       0.532444  Validation Accuracy\n",
       "21            128             16       0.532756  Validation Accuracy\n",
       "24             32            128       0.540165  Validation Accuracy\n",
       "27            512           2048       0.511699  Validation Accuracy"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy_only = results[results[\"Metrics Type\"] == \"Validation Accuracy\"]\n",
    "validation_accuracy_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
